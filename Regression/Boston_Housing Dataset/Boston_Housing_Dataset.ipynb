{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Dataset\n",
    "Each of the 506 entries represent aggregated data about 14 features for homes from various suburbs in Boston, Massachusetts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following describes the dataset columns:\n",
    "\n",
    "CRIM - per capita crime rate by town\n",
    "\n",
    "ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "INDUS - proportion of non-retail business acres per town.\n",
    "\n",
    "CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "\n",
    "NOX - nitric oxides concentration (parts per 10 million)\n",
    "\n",
    "RM - average number of rooms per dwelling\n",
    "\n",
    "AGE - proportion of owner-occupied units built prior to 1940\n",
    "\n",
    "DIS - weighted distances to five Boston employment centres\n",
    "\n",
    "RAD - index of accessibility to radial highways\n",
    "\n",
    "TAX - full-value property-tax rate per $10,000\n",
    "\n",
    "PTRATIO - pupil-teacher ratio by town\n",
    "\n",
    "B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "\n",
    "LSTAT - % lower status of the population\n",
    "\n",
    "MEDV - Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenges:\n",
    "\n",
    "1.Missing value treatment\n",
    "\n",
    "2.Outlier treatment\n",
    "\n",
    "3.Understanding which variables drive the price of homes in Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Boston Housing Predicition.ipynb',\n",
       " 'BostonHousingData.csv',\n",
       " 'housing.csv',\n",
       " 'practice_0nline.ipynb',\n",
       " 'Practice_offline.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"BostonHousingData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>486.0</td>\n",
       "      <td>3.611874</td>\n",
       "      <td>8.720192</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.253715</td>\n",
       "      <td>3.560262</td>\n",
       "      <td>88.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>486.0</td>\n",
       "      <td>11.211934</td>\n",
       "      <td>23.388876</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>486.0</td>\n",
       "      <td>11.083992</td>\n",
       "      <td>6.835896</td>\n",
       "      <td>0.46000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>27.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>486.0</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>0.255340</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>506.0</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.38500</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.8710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>506.0</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>3.56100</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>8.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>486.0</td>\n",
       "      <td>68.518519</td>\n",
       "      <td>27.999513</td>\n",
       "      <td>2.90000</td>\n",
       "      <td>45.175000</td>\n",
       "      <td>76.800000</td>\n",
       "      <td>93.975000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>506.0</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>1.12960</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>12.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>506.0</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>506.0</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>187.00000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>711.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>506.0</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>12.60000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>22.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>506.0</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>396.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>486.0</td>\n",
       "      <td>12.715432</td>\n",
       "      <td>7.155871</td>\n",
       "      <td>1.73000</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>37.9700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDV</th>\n",
       "      <td>506.0</td>\n",
       "      <td>22.532806</td>\n",
       "      <td>9.197104</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>17.025000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count        mean         std        min         25%         50%  \\\n",
       "CRIM     486.0    3.611874    8.720192    0.00632    0.081900    0.253715   \n",
       "ZN       486.0   11.211934   23.388876    0.00000    0.000000    0.000000   \n",
       "INDUS    486.0   11.083992    6.835896    0.46000    5.190000    9.690000   \n",
       "CHAS     486.0    0.069959    0.255340    0.00000    0.000000    0.000000   \n",
       "NOX      506.0    0.554695    0.115878    0.38500    0.449000    0.538000   \n",
       "RM       506.0    6.284634    0.702617    3.56100    5.885500    6.208500   \n",
       "AGE      486.0   68.518519   27.999513    2.90000   45.175000   76.800000   \n",
       "DIS      506.0    3.795043    2.105710    1.12960    2.100175    3.207450   \n",
       "RAD      506.0    9.549407    8.707259    1.00000    4.000000    5.000000   \n",
       "TAX      506.0  408.237154  168.537116  187.00000  279.000000  330.000000   \n",
       "PTRATIO  506.0   18.455534    2.164946   12.60000   17.400000   19.050000   \n",
       "B        506.0  356.674032   91.294864    0.32000  375.377500  391.440000   \n",
       "LSTAT    486.0   12.715432    7.155871    1.73000    7.125000   11.430000   \n",
       "MEDV     506.0   22.532806    9.197104    5.00000   17.025000   21.200000   \n",
       "\n",
       "                75%       max  \n",
       "CRIM       3.560262   88.9762  \n",
       "ZN        12.500000  100.0000  \n",
       "INDUS     18.100000   27.7400  \n",
       "CHAS       0.000000    1.0000  \n",
       "NOX        0.624000    0.8710  \n",
       "RM         6.623500    8.7800  \n",
       "AGE       93.975000  100.0000  \n",
       "DIS        5.188425   12.1265  \n",
       "RAD       24.000000   24.0000  \n",
       "TAX      666.000000  711.0000  \n",
       "PTRATIO   20.200000   22.0000  \n",
       "B        396.225000  396.9000  \n",
       "LSTAT     16.955000   37.9700  \n",
       "MEDV      25.000000   50.0000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     486 non-null    float64\n",
      " 1   ZN       486 non-null    float64\n",
      " 2   INDUS    486 non-null    float64\n",
      " 3   CHAS     486 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      486 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    int64  \n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    486 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM       20\n",
      "ZN         20\n",
      "INDUS      20\n",
      "CHAS       20\n",
      "NOX         0\n",
      "RM          0\n",
      "AGE        20\n",
      "DIS         0\n",
      "RAD         0\n",
      "TAX         0\n",
      "PTRATIO     0\n",
      "B           0\n",
      "LSTAT      20\n",
      "MEDV        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# null values\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM         0\n",
      "ZN         360\n",
      "INDUS        0\n",
      "CHAS       452\n",
      "NOX          0\n",
      "RM           0\n",
      "AGE          0\n",
      "DIS          0\n",
      "RAD          0\n",
      "TAX          0\n",
      "PTRATIO      0\n",
      "B            0\n",
      "LSTAT        0\n",
      "MEDV         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# empty value\n",
    "print((df == 0.0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>10.768775</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.140000</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>10.768775</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>10.768775</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>10.768775</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.212846</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM         ZN  INDUS      CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0  0.00632  18.000000   2.31  0.067194  0.538  6.575  65.2  4.0900    1  296   \n",
       "1  0.02731  10.768775   7.07  0.067194  0.469  6.421  78.9  4.9671    2  242   \n",
       "2  0.02729  10.768775   7.07  0.067194  0.469  7.185  61.1  4.9671    2  242   \n",
       "3  0.03237  10.768775   2.18  0.067194  0.458  6.998  45.8  6.0622    3  222   \n",
       "4  0.06905  10.768775   2.18  0.067194  0.458  7.147  54.2  6.0622    3  222   \n",
       "\n",
       "   PTRATIO       B      LSTAT  MEDV  \n",
       "0     15.3  396.90   4.980000  24.0  \n",
       "1     17.8  396.90   9.140000  21.6  \n",
       "2     17.8  392.83   4.030000  34.7  \n",
       "3     18.7  394.63   2.940000  33.4  \n",
       "4     18.7  396.90  12.212846  36.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.Replacing Null value with 0.0\n",
    "# 2.Replacing 0.0 with mean\n",
    "# 3.Randomizing data\n",
    "data_df = df.replace(np.nan,0.0)              #1\n",
    "data_df = data_df.replace(0.0,data_df.mean()) #2\n",
    "#data_df = data_df.sample(frac=1)             #3\n",
    "display(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90    NaN  36.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# orignla data\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>10.768775</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>10.768775</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>10.768775</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>10.768775</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.212846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM         ZN  INDUS      CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0  0.00632  18.000000   2.31  0.067194  0.538  6.575  65.2  4.0900    1  296   \n",
       "1  0.02731  10.768775   7.07  0.067194  0.469  6.421  78.9  4.9671    2  242   \n",
       "2  0.02729  10.768775   7.07  0.067194  0.469  7.185  61.1  4.9671    2  242   \n",
       "3  0.03237  10.768775   2.18  0.067194  0.458  6.998  45.8  6.0622    3  222   \n",
       "4  0.06905  10.768775   2.18  0.067194  0.458  7.147  54.2  6.0622    3  222   \n",
       "\n",
       "   PTRATIO       B      LSTAT  \n",
       "0     15.3  396.90   4.980000  \n",
       "1     17.8  396.90   9.140000  \n",
       "2     17.8  392.83   4.030000  \n",
       "3     18.7  394.63   2.940000  \n",
       "4     18.7  396.90  12.212846  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MEDV\n",
       "0  24.0\n",
       "1  21.6\n",
       "2  34.7\n",
       "3  33.4\n",
       "4  36.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# working on updated data\n",
    "\n",
    "features = data_df.iloc[:,:-1]\n",
    "labels = data_df.iloc[:,-1:]\n",
    "display(features.head())\n",
    "display(labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting dataframe in to numpy array\n",
    "features = features.values\n",
    "labels = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n",
      "\n",
      "[[6.32000000e-03 1.80000000e+01 2.31000000e+00 ... 1.53000000e+01\n",
      "  3.96900000e+02 4.98000000e+00]\n",
      " [2.73100000e-02 1.07687747e+01 7.07000000e+00 ... 1.78000000e+01\n",
      "  3.96900000e+02 9.14000000e+00]\n",
      " [2.72900000e-02 1.07687747e+01 7.07000000e+00 ... 1.78000000e+01\n",
      "  3.92830000e+02 4.03000000e+00]\n",
      " ...\n",
      " [6.07600000e-02 1.07687747e+01 1.19300000e+01 ... 2.10000000e+01\n",
      "  3.96900000e+02 5.64000000e+00]\n",
      " [1.09590000e-01 1.07687747e+01 1.19300000e+01 ... 2.10000000e+01\n",
      "  3.93450000e+02 6.48000000e+00]\n",
      " [4.74100000e-02 1.07687747e+01 1.19300000e+01 ... 2.10000000e+01\n",
      "  3.96900000e+02 7.88000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "labels = labels.ravel() # turning column to row\n",
    "print(labels)\n",
    "print()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing data (through Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42166527 -0.04410855 -1.30831657 ... -1.45900038  0.44105193\n",
      "  -1.10120285]\n",
      " [-0.41920667 -0.41672544 -0.59713492 ... -0.30309415  0.44105193\n",
      "  -0.50746763]\n",
      " [-0.41920901 -0.41672544 -0.59713492 ... -0.30309415  0.39642699\n",
      "  -1.23679142]\n",
      " ...\n",
      " [-0.4152886  -0.41672544  0.12898751 ...  1.17646583  0.44105193\n",
      "  -1.00700447]\n",
      " [-0.40956904 -0.41672544  0.12898751 ...  1.17646583  0.4032249\n",
      "  -0.88711563]\n",
      " [-0.41685231 -0.41672544  0.12898751 ...  1.17646583  0.44105193\n",
      "  -0.68730089]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "features = scale.fit_transform(features)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Normalizing data (Manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "\n",
    "#mean = features.mean(axis=0)\n",
    "#features -= mean\n",
    "#std = features.std(axis=0)\n",
    "#features /= std\n",
    "#print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : (404, 13)\n",
      "train label : (404,)\n",
      "test : (102, 13)\n",
      "test label: (102,)\n"
     ]
    }
   ],
   "source": [
    "# split in training 80%, test 20%\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "print(\"train :\",x_train.shape)\n",
    "print(\"train label :\",y_train.shape)\n",
    "print(\"test :\",x_test.shape)\n",
    "print(\"test label:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/100\n",
      "323/323 [==============================] - 2s 5ms/sample - loss: 565.6607 - mae: 22.0828 - val_loss: 502.5291 - val_mae: 20.5040\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 0s 275us/sample - loss: 490.4125 - mae: 20.4056 - val_loss: 423.8559 - val_mae: 18.5758\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 0s 257us/sample - loss: 400.6380 - mae: 18.0936 - val_loss: 330.9981 - val_mae: 16.1670\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 0s 278us/sample - loss: 297.5001 - mae: 15.2173 - val_loss: 222.0417 - val_mae: 12.9722\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 0s 257us/sample - loss: 187.6097 - mae: 11.5890 - val_loss: 129.1451 - val_mae: 9.5900\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 0s 251us/sample - loss: 107.1876 - mae: 8.0968 - val_loss: 78.7996 - val_mae: 7.0115\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 0s 260us/sample - loss: 69.2645 - mae: 6.2776 - val_loss: 60.3999 - val_mae: 5.8692\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 0s 244us/sample - loss: 53.3360 - mae: 5.4688 - val_loss: 51.8184 - val_mae: 5.3151\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 44.7436 - mae: 4.9199 - val_loss: 43.0693 - val_mae: 4.7407\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 37.1984 - mae: 4.4357 - val_loss: 39.6237 - val_mae: 4.6033\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 33.1685 - mae: 4.1766 - val_loss: 34.7950 - val_mae: 4.1757\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 0s 229us/sample - loss: 29.8164 - mae: 3.9360 - val_loss: 33.7547 - val_mae: 4.0105\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 27.1765 - mae: 3.6772 - val_loss: 30.8177 - val_mae: 3.8032\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 0s 229us/sample - loss: 25.0138 - mae: 3.5113 - val_loss: 28.6876 - val_mae: 3.9166\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 23.0815 - mae: 3.4105 - val_loss: 26.7181 - val_mae: 3.4672\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 21.4994 - mae: 3.2227 - val_loss: 24.9153 - val_mae: 3.5484\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 20.4312 - mae: 3.1539 - val_loss: 24.6352 - val_mae: 3.2344\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 19.1576 - mae: 3.0184 - val_loss: 22.8194 - val_mae: 3.2000\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 0s 226us/sample - loss: 18.5059 - mae: 3.0064 - val_loss: 22.9824 - val_mae: 3.0594\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 17.3337 - mae: 2.9239 - val_loss: 23.6788 - val_mae: 3.0121\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 0s 229us/sample - loss: 16.4390 - mae: 2.8244 - val_loss: 23.9467 - val_mae: 3.6792\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 0s 226us/sample - loss: 16.7803 - mae: 2.9510 - val_loss: 22.5821 - val_mae: 3.0910\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 0s 236us/sample - loss: 15.5665 - mae: 2.7596 - val_loss: 20.5696 - val_mae: 3.0033\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 0s 223us/sample - loss: 15.1328 - mae: 2.7343 - val_loss: 20.1927 - val_mae: 2.9235\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 14.9594 - mae: 2.6786 - val_loss: 21.4320 - val_mae: 3.0000\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 0s 229us/sample - loss: 14.5564 - mae: 2.6545 - val_loss: 20.6028 - val_mae: 2.8883\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 0s 241us/sample - loss: 13.8438 - mae: 2.6187 - val_loss: 19.6686 - val_mae: 3.1453\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 13.6990 - mae: 2.6722 - val_loss: 18.9910 - val_mae: 2.7964\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 13.1393 - mae: 2.5101 - val_loss: 19.8921 - val_mae: 2.7913\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 0s 229us/sample - loss: 13.2340 - mae: 2.5537 - val_loss: 18.5502 - val_mae: 2.7365\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 12.5034 - mae: 2.4700 - val_loss: 19.4616 - val_mae: 2.7571\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 12.4794 - mae: 2.4549 - val_loss: 18.0601 - val_mae: 2.7051\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 0s 226us/sample - loss: 11.8866 - mae: 2.4252 - val_loss: 17.5322 - val_mae: 2.7546\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 12.0468 - mae: 2.4642 - val_loss: 18.2740 - val_mae: 2.6333\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 11.3824 - mae: 2.3555 - val_loss: 19.6137 - val_mae: 2.7152\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 11.1693 - mae: 2.3437 - val_loss: 17.8967 - val_mae: 2.7964\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 11.4276 - mae: 2.3830 - val_loss: 18.8056 - val_mae: 3.1646\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 0s 223us/sample - loss: 11.5546 - mae: 2.4208 - val_loss: 16.9350 - val_mae: 2.5513\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 10.4497 - mae: 2.2785 - val_loss: 16.4938 - val_mae: 2.7137\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 0s 241us/sample - loss: 10.7053 - mae: 2.3253 - val_loss: 17.4842 - val_mae: 2.5457\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 10.5818 - mae: 2.2759 - val_loss: 16.5429 - val_mae: 2.7100\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 10.3233 - mae: 2.2434 - val_loss: 18.3096 - val_mae: 2.6395\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 10.1007 - mae: 2.2582 - val_loss: 16.0309 - val_mae: 2.7026\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 0s 238us/sample - loss: 10.3177 - mae: 2.2414 - val_loss: 18.1220 - val_mae: 2.8502\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 10.2828 - mae: 2.2657 - val_loss: 15.7568 - val_mae: 2.4823\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 0s 235us/sample - loss: 9.7109 - mae: 2.2134 - val_loss: 17.4539 - val_mae: 2.5587\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 0s 232us/sample - loss: 9.8432 - mae: 2.2129 - val_loss: 18.0207 - val_mae: 2.7769\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 0s 241us/sample - loss: 9.7030 - mae: 2.2042 - val_loss: 15.6672 - val_mae: 2.5100\n",
      "Epoch 49/100\n",
      "323/323 [==============================] - 0s 251us/sample - loss: 9.5250 - mae: 2.2298 - val_loss: 16.3915 - val_mae: 2.5497\n",
      "Epoch 50/100\n",
      "323/323 [==============================] - 0s 217us/sample - loss: 9.5080 - mae: 2.2001 - val_loss: 16.3706 - val_mae: 2.6650\n",
      "Epoch 51/100\n",
      "323/323 [==============================] - 0s 260us/sample - loss: 9.5369 - mae: 2.2493 - val_loss: 15.6436 - val_mae: 2.6558\n",
      "Epoch 52/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 9.0411 - mae: 2.1871 - val_loss: 16.2077 - val_mae: 2.4533\n",
      "Epoch 53/100\n",
      "323/323 [==============================] - 0s 214us/sample - loss: 8.9589 - mae: 2.1240 - val_loss: 15.6443 - val_mae: 2.6332\n",
      "Epoch 54/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 8.9867 - mae: 2.1633 - val_loss: 16.6151 - val_mae: 2.5156\n",
      "Epoch 55/100\n",
      "323/323 [==============================] - 0s 206us/sample - loss: 9.8718 - mae: 2.1925 - val_loss: 16.8883 - val_mae: 2.5045\n",
      "Epoch 56/100\n",
      "323/323 [==============================] - 0s 210us/sample - loss: 8.5119 - mae: 2.1143 - val_loss: 18.1686 - val_mae: 2.7110\n",
      "Epoch 57/100\n",
      "323/323 [==============================] - 0s 217us/sample - loss: 8.8466 - mae: 2.1390 - val_loss: 17.6415 - val_mae: 3.0885\n",
      "Epoch 58/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 9.0611 - mae: 2.1290 - val_loss: 15.9658 - val_mae: 2.4965\n",
      "Epoch 59/100\n",
      "323/323 [==============================] - 0s 210us/sample - loss: 8.4797 - mae: 2.0885 - val_loss: 16.7139 - val_mae: 2.4845\n",
      "Epoch 60/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 8.5276 - mae: 2.0729 - val_loss: 15.5316 - val_mae: 2.4956\n",
      "Epoch 61/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 8.1563 - mae: 2.0523 - val_loss: 16.6295 - val_mae: 2.8522\n",
      "Epoch 62/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 8.3275 - mae: 2.0736 - val_loss: 15.3469 - val_mae: 2.6223\n",
      "Epoch 63/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 8.4444 - mae: 2.1305 - val_loss: 16.4252 - val_mae: 2.5141\n",
      "Epoch 64/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 7.8463 - mae: 2.0272 - val_loss: 18.8588 - val_mae: 2.8341\n",
      "Epoch 65/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 8.3160 - mae: 2.0682 - val_loss: 16.4857 - val_mae: 2.4881\n",
      "Epoch 66/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 7.9280 - mae: 2.0055 - val_loss: 18.0517 - val_mae: 2.6454\n",
      "Epoch 67/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 8.0186 - mae: 2.0294 - val_loss: 18.4462 - val_mae: 2.7776\n",
      "Epoch 68/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 8.0348 - mae: 2.0487 - val_loss: 17.4342 - val_mae: 2.5901\n",
      "Epoch 69/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 7.8802 - mae: 2.0297 - val_loss: 16.8796 - val_mae: 2.4889\n",
      "Epoch 70/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 7.8392 - mae: 2.0141 - val_loss: 20.3669 - val_mae: 2.7667\n",
      "Epoch 71/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 8.0293 - mae: 2.0585 - val_loss: 15.0898 - val_mae: 2.4218\n",
      "Epoch 72/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 7.4036 - mae: 1.9413 - val_loss: 15.5158 - val_mae: 2.5036\n",
      "Epoch 73/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 7.2990 - mae: 1.9467 - val_loss: 16.0191 - val_mae: 2.4328\n",
      "Epoch 74/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 7.4188 - mae: 1.9681 - val_loss: 20.8362 - val_mae: 2.8588\n",
      "Epoch 75/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 7.6309 - mae: 1.9933 - val_loss: 15.2445 - val_mae: 2.5123\n",
      "Epoch 76/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 7.2582 - mae: 1.9551 - val_loss: 17.6632 - val_mae: 2.6022\n",
      "Epoch 77/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 7.5450 - mae: 1.9656 - val_loss: 15.7537 - val_mae: 2.3650\n",
      "Epoch 78/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 6.8699 - mae: 1.8764 - val_loss: 17.1166 - val_mae: 2.9105\n",
      "Epoch 79/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 7.6785 - mae: 2.0103 - val_loss: 15.5963 - val_mae: 2.6413\n",
      "Epoch 80/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 6.9824 - mae: 1.9312 - val_loss: 15.1089 - val_mae: 2.6139\n",
      "Epoch 81/100\n",
      "323/323 [==============================] - 0s 217us/sample - loss: 6.8017 - mae: 1.9088 - val_loss: 15.6664 - val_mae: 2.3962\n",
      "Epoch 82/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 6.5590 - mae: 1.8773 - val_loss: 16.7567 - val_mae: 2.4425\n",
      "Epoch 83/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 6.8025 - mae: 1.9044 - val_loss: 16.4180 - val_mae: 2.4302\n",
      "Epoch 84/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 6.9464 - mae: 1.9294 - val_loss: 16.4783 - val_mae: 2.5214\n",
      "Epoch 85/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 6.9903 - mae: 1.9470 - val_loss: 15.5743 - val_mae: 2.6639\n",
      "Epoch 86/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 6.6838 - mae: 1.9216 - val_loss: 20.7971 - val_mae: 2.9377\n",
      "Epoch 87/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 6.8954 - mae: 1.9333 - val_loss: 15.9089 - val_mae: 2.4452\n",
      "Epoch 88/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 6.8851 - mae: 1.9311 - val_loss: 15.6282 - val_mae: 2.6133\n",
      "Epoch 89/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 6.4815 - mae: 1.8824 - val_loss: 16.1003 - val_mae: 2.6083\n",
      "Epoch 90/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 6.5497 - mae: 1.8553 - val_loss: 15.3917 - val_mae: 2.5984\n",
      "Epoch 91/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 6.2296 - mae: 1.8238 - val_loss: 15.3346 - val_mae: 2.6018\n",
      "Epoch 92/100\n",
      "323/323 [==============================] - 0s 214us/sample - loss: 6.4185 - mae: 1.8628 - val_loss: 15.1610 - val_mae: 2.5183\n",
      "Epoch 93/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 6.4440 - mae: 1.8902 - val_loss: 14.8728 - val_mae: 2.5175\n",
      "Epoch 94/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 6.3984 - mae: 1.9081 - val_loss: 14.7571 - val_mae: 2.5096\n",
      "Epoch 95/100\n",
      "323/323 [==============================] - 0s 201us/sample - loss: 6.4098 - mae: 1.8601 - val_loss: 18.7280 - val_mae: 2.6788\n",
      "Epoch 96/100\n",
      "323/323 [==============================] - 0s 210us/sample - loss: 6.4767 - mae: 1.8768 - val_loss: 17.7447 - val_mae: 2.7063\n",
      "Epoch 97/100\n",
      "323/323 [==============================] - 0s 204us/sample - loss: 6.0238 - mae: 1.8375 - val_loss: 15.0664 - val_mae: 2.4314\n",
      "Epoch 98/100\n",
      "323/323 [==============================] - 0s 207us/sample - loss: 6.1051 - mae: 1.8184 - val_loss: 17.8339 - val_mae: 2.6238\n",
      "Epoch 99/100\n",
      "323/323 [==============================] - 0s 210us/sample - loss: 5.7426 - mae: 1.7606 - val_loss: 14.7701 - val_mae: 2.5100\n",
      "Epoch 100/100\n",
      "323/323 [==============================] - 0s 211us/sample - loss: 6.1693 - mae: 1.8006 - val_loss: 16.1106 - val_mae: 2.7623\n"
     ]
    }
   ],
   "source": [
    "input_shape = 13\n",
    "\n",
    "models = tf.keras.Sequential\n",
    "layers = tf.keras.layers\n",
    "\n",
    "model = models([layers.Dense(64,activation=\"relu\",input_shape=(input_shape,)),\n",
    "                layers.Dense(32,activation=\"relu\"),\n",
    "                layers.Dense(16,activation=\"relu\"),\n",
    "                layers.Dense(1)])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", # adam\n",
    "             loss=\"mse\",\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=100,validation_split=(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/1 - 0s - loss: 19.2351 - mae: 2.7786\n",
      "\n",
      "loss:  12.090548982807235\n",
      "MSE:   2.7785602\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(x_test,y_test,verbose=2)\n",
    "print()\n",
    "print(\"loss: \",evaluation[0])\n",
    "print(\"MSE:  \",evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "acc = history.history['mae']\n",
    "val_acc = history.history['val_mae']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation mae')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('mae')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_model2(epochs,drop):\n",
    "    print()\n",
    "    models = tf.keras.models.Sequential\n",
    "    layers = tf.keras.layers\n",
    "\n",
    "    model2 = models([layers.Dense(64,input_shape = (input_shape,)),\n",
    "                     layers.Dropout(drop),\n",
    "                     layers.Dense(64,activation=\"relu\"),\n",
    "                     layers.Dense(64,activation=\"relu\"),\n",
    "                     layers.Dropout(drop),\n",
    "                     layers.Dense(1)])\n",
    "    \n",
    "    model2.compile(optimizer=\"adam\", # rmsprop # adam # \n",
    "             loss=\"mse\", # binary_crossentropy\n",
    "              metrics=[\"mae\"])\n",
    "    \n",
    "    history = model.fit(x_train,y_train,epochs=epochs,validation_split=(0.2))\n",
    "    \n",
    "    evaluation = model.evaluate(x_test,y_test,verbose=2)\n",
    "    print()\n",
    "    print(\"loss: \",evaluation[0])\n",
    "    print(\"MSE:  \",evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/100\n",
      "364/364 [==============================] - 0s 261us/sample - loss: 6.2328 - mae: 1.8855 - val_loss: 15.0125 - val_mae: 2.3341\n",
      "Epoch 2/100\n",
      "364/364 [==============================] - 0s 258us/sample - loss: 6.2674 - mae: 1.8884 - val_loss: 13.2850 - val_mae: 2.2944\n",
      "Epoch 3/100\n",
      "364/364 [==============================] - 0s 253us/sample - loss: 5.8066 - mae: 1.8370 - val_loss: 13.2414 - val_mae: 2.3408\n",
      "Epoch 4/100\n",
      "364/364 [==============================] - 0s 255us/sample - loss: 5.9895 - mae: 1.8482 - val_loss: 13.3092 - val_mae: 2.2542\n",
      "Epoch 5/100\n",
      "364/364 [==============================] - 0s 272us/sample - loss: 5.7603 - mae: 1.8306 - val_loss: 13.5341 - val_mae: 2.4683\n",
      "Epoch 6/100\n",
      "364/364 [==============================] - 0s 255us/sample - loss: 5.5581 - mae: 1.7866 - val_loss: 13.9528 - val_mae: 2.4497\n",
      "Epoch 7/100\n",
      "364/364 [==============================] - 0s 222us/sample - loss: 5.5877 - mae: 1.8214 - val_loss: 13.4142 - val_mae: 2.2805\n",
      "Epoch 8/100\n",
      "364/364 [==============================] - 0s 231us/sample - loss: 5.6448 - mae: 1.8318 - val_loss: 15.2631 - val_mae: 2.5047\n",
      "Epoch 9/100\n",
      "364/364 [==============================] - 0s 247us/sample - loss: 5.4909 - mae: 1.8112 - val_loss: 13.5394 - val_mae: 2.2372\n",
      "Epoch 10/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 5.6136 - mae: 1.7994 - val_loss: 13.2866 - val_mae: 2.3022\n",
      "Epoch 11/100\n",
      "364/364 [==============================] - 0s 225us/sample - loss: 5.0451 - mae: 1.7136 - val_loss: 13.9771 - val_mae: 2.3692\n",
      "Epoch 12/100\n",
      "364/364 [==============================] - 0s 242us/sample - loss: 5.2220 - mae: 1.7556 - val_loss: 13.2113 - val_mae: 2.3001\n",
      "Epoch 13/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 5.3547 - mae: 1.7592 - val_loss: 13.4059 - val_mae: 2.3224\n",
      "Epoch 14/100\n",
      "364/364 [==============================] - 0s 236us/sample - loss: 5.1967 - mae: 1.7588 - val_loss: 13.4180 - val_mae: 2.3874\n",
      "Epoch 15/100\n",
      "364/364 [==============================] - 0s 244us/sample - loss: 5.2440 - mae: 1.7798 - val_loss: 13.6422 - val_mae: 2.3081\n",
      "Epoch 16/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 5.1425 - mae: 1.7472 - val_loss: 13.1143 - val_mae: 2.2818\n",
      "Epoch 17/100\n",
      "364/364 [==============================] - 0s 253us/sample - loss: 5.0406 - mae: 1.6990 - val_loss: 13.0303 - val_mae: 2.2735\n",
      "Epoch 18/100\n",
      "364/364 [==============================] - 0s 244us/sample - loss: 4.9498 - mae: 1.7169 - val_loss: 12.8755 - val_mae: 2.3927\n",
      "Epoch 19/100\n",
      "364/364 [==============================] - 0s 228us/sample - loss: 5.0458 - mae: 1.7514 - val_loss: 12.8379 - val_mae: 2.2666\n",
      "Epoch 20/100\n",
      "364/364 [==============================] - 0s 244us/sample - loss: 5.1001 - mae: 1.7680 - val_loss: 12.8180 - val_mae: 2.4128\n",
      "Epoch 21/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 4.7100 - mae: 1.6515 - val_loss: 13.6130 - val_mae: 2.3131\n",
      "Epoch 22/100\n",
      "364/364 [==============================] - 0s 242us/sample - loss: 4.7879 - mae: 1.7037 - val_loss: 13.0464 - val_mae: 2.4226\n",
      "Epoch 23/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 4.7948 - mae: 1.6848 - val_loss: 14.9907 - val_mae: 2.4109\n",
      "Epoch 24/100\n",
      "364/364 [==============================] - 0s 236us/sample - loss: 4.4979 - mae: 1.6188 - val_loss: 13.9805 - val_mae: 2.6283\n",
      "Epoch 25/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 4.9056 - mae: 1.6735 - val_loss: 12.7837 - val_mae: 2.2783\n",
      "Epoch 26/100\n",
      "364/364 [==============================] - 0s 236us/sample - loss: 4.7603 - mae: 1.6854 - val_loss: 12.7219 - val_mae: 2.3049\n",
      "Epoch 27/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 4.5171 - mae: 1.6351 - val_loss: 12.9752 - val_mae: 2.2326\n",
      "Epoch 28/100\n",
      "364/364 [==============================] - 0s 228us/sample - loss: 4.3873 - mae: 1.6145 - val_loss: 13.9968 - val_mae: 2.2972\n",
      "Epoch 29/100\n",
      "364/364 [==============================] - 0s 236us/sample - loss: 4.2713 - mae: 1.5912 - val_loss: 13.2880 - val_mae: 2.2860\n",
      "Epoch 30/100\n",
      "364/364 [==============================] - 0s 236us/sample - loss: 4.2715 - mae: 1.5832 - val_loss: 13.7883 - val_mae: 2.3301\n",
      "Epoch 31/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 4.2828 - mae: 1.6055 - val_loss: 13.9881 - val_mae: 2.4138\n",
      "Epoch 32/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 4.2295 - mae: 1.5726 - val_loss: 13.1751 - val_mae: 2.3091\n",
      "Epoch 33/100\n",
      "364/364 [==============================] - 0s 258us/sample - loss: 4.4788 - mae: 1.6432 - val_loss: 13.5096 - val_mae: 2.2656\n",
      "Epoch 34/100\n",
      "364/364 [==============================] - 0s 244us/sample - loss: 4.1589 - mae: 1.5759 - val_loss: 13.2321 - val_mae: 2.4435\n",
      "Epoch 35/100\n",
      "364/364 [==============================] - 0s 255us/sample - loss: 4.3185 - mae: 1.5819 - val_loss: 13.0240 - val_mae: 2.3656\n",
      "Epoch 36/100\n",
      "364/364 [==============================] - 0s 253us/sample - loss: 4.0652 - mae: 1.5541 - val_loss: 12.8700 - val_mae: 2.3053\n",
      "Epoch 37/100\n",
      "364/364 [==============================] - 0s 258us/sample - loss: 4.2658 - mae: 1.6103 - val_loss: 12.9356 - val_mae: 2.2332\n",
      "Epoch 38/100\n",
      "364/364 [==============================] - 0s 233us/sample - loss: 4.1609 - mae: 1.5623 - val_loss: 12.9705 - val_mae: 2.3121\n",
      "Epoch 39/100\n",
      "364/364 [==============================] - 0s 244us/sample - loss: 4.0279 - mae: 1.5559 - val_loss: 12.8668 - val_mae: 2.2709\n",
      "Epoch 40/100\n",
      "364/364 [==============================] - 0s 247us/sample - loss: 3.9152 - mae: 1.5077 - val_loss: 13.5744 - val_mae: 2.2820\n",
      "Epoch 41/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 3.7297 - mae: 1.4788 - val_loss: 14.4897 - val_mae: 2.3869\n",
      "Epoch 42/100\n",
      "364/364 [==============================] - 0s 236us/sample - loss: 4.1816 - mae: 1.5867 - val_loss: 15.5172 - val_mae: 2.6851\n",
      "Epoch 43/100\n",
      "364/364 [==============================] - 0s 242us/sample - loss: 3.7753 - mae: 1.4724 - val_loss: 13.7850 - val_mae: 2.3763\n",
      "Epoch 44/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 4.1001 - mae: 1.5555 - val_loss: 13.3503 - val_mae: 2.2963\n",
      "Epoch 45/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 3.7918 - mae: 1.5074 - val_loss: 13.8887 - val_mae: 2.4138\n",
      "Epoch 46/100\n",
      "364/364 [==============================] - 0s 253us/sample - loss: 3.9103 - mae: 1.5368 - val_loss: 13.4096 - val_mae: 2.3146\n",
      "Epoch 47/100\n",
      "364/364 [==============================] - 0s 244us/sample - loss: 3.7962 - mae: 1.5489 - val_loss: 13.6947 - val_mae: 2.4516\n",
      "Epoch 48/100\n",
      "364/364 [==============================] - 0s 244us/sample - loss: 3.7481 - mae: 1.4686 - val_loss: 14.9681 - val_mae: 2.4041\n",
      "Epoch 49/100\n",
      "364/364 [==============================] - 0s 250us/sample - loss: 3.9672 - mae: 1.5223 - val_loss: 14.3553 - val_mae: 2.3515\n",
      "Epoch 50/100\n",
      "364/364 [==============================] - 0s 242us/sample - loss: 3.5798 - mae: 1.4757 - val_loss: 12.7530 - val_mae: 2.3028\n",
      "Epoch 51/100\n",
      "364/364 [==============================] - 0s 244us/sample - loss: 3.8316 - mae: 1.5324 - val_loss: 15.5300 - val_mae: 2.5744\n",
      "Epoch 52/100\n",
      "364/364 [==============================] - 0s 250us/sample - loss: 3.7350 - mae: 1.4984 - val_loss: 17.7941 - val_mae: 2.8431\n",
      "Epoch 53/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 3.5314 - mae: 1.4466 - val_loss: 13.1645 - val_mae: 2.3009\n",
      "Epoch 54/100\n",
      "364/364 [==============================] - 0s 242us/sample - loss: 3.5855 - mae: 1.4882 - val_loss: 15.4931 - val_mae: 2.6618\n",
      "Epoch 55/100\n",
      "364/364 [==============================] - 0s 228us/sample - loss: 3.7474 - mae: 1.4910 - val_loss: 13.2545 - val_mae: 2.3335\n",
      "Epoch 56/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 3.6405 - mae: 1.4717 - val_loss: 13.2545 - val_mae: 2.4576\n",
      "Epoch 57/100\n",
      "364/364 [==============================] - 0s 244us/sample - loss: 3.6487 - mae: 1.4612 - val_loss: 13.0621 - val_mae: 2.2626\n",
      "Epoch 58/100\n",
      "364/364 [==============================] - 0s 250us/sample - loss: 3.5030 - mae: 1.4265 - val_loss: 13.6628 - val_mae: 2.3689\n",
      "Epoch 59/100\n",
      "364/364 [==============================] - 0s 250us/sample - loss: 3.4405 - mae: 1.4279 - val_loss: 14.9386 - val_mae: 2.4028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 3.4706 - mae: 1.4317 - val_loss: 13.9082 - val_mae: 2.4243\n",
      "Epoch 61/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 3.4256 - mae: 1.4209 - val_loss: 12.9973 - val_mae: 2.2996\n",
      "Epoch 62/100\n",
      "364/364 [==============================] - 0s 236us/sample - loss: 3.7806 - mae: 1.5024 - val_loss: 14.0736 - val_mae: 2.3810\n",
      "Epoch 63/100\n",
      "364/364 [==============================] - 0s 269us/sample - loss: 3.3731 - mae: 1.3978 - val_loss: 13.3128 - val_mae: 2.2899\n",
      "Epoch 64/100\n",
      "364/364 [==============================] - 0s 250us/sample - loss: 3.4101 - mae: 1.4029 - val_loss: 14.4412 - val_mae: 2.4013\n",
      "Epoch 65/100\n",
      "364/364 [==============================] - 0s 233us/sample - loss: 3.1107 - mae: 1.3735 - val_loss: 13.7018 - val_mae: 2.3367\n",
      "Epoch 66/100\n",
      "364/364 [==============================] - 0s 264us/sample - loss: 3.5230 - mae: 1.4408 - val_loss: 14.2509 - val_mae: 2.3713\n",
      "Epoch 67/100\n",
      "364/364 [==============================] - 0s 266us/sample - loss: 3.6605 - mae: 1.4602 - val_loss: 13.6412 - val_mae: 2.5092\n",
      "Epoch 68/100\n",
      "364/364 [==============================] - 0s 253us/sample - loss: 3.3326 - mae: 1.4223 - val_loss: 14.1122 - val_mae: 2.3610\n",
      "Epoch 69/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 3.2772 - mae: 1.3761 - val_loss: 14.5242 - val_mae: 2.3833\n",
      "Epoch 70/100\n",
      "364/364 [==============================] - 0s 244us/sample - loss: 3.3280 - mae: 1.4199 - val_loss: 13.5014 - val_mae: 2.4161\n",
      "Epoch 71/100\n",
      "364/364 [==============================] - 0s 247us/sample - loss: 3.2263 - mae: 1.3736 - val_loss: 14.2418 - val_mae: 2.4839\n",
      "Epoch 72/100\n",
      "364/364 [==============================] - 0s 236us/sample - loss: 3.2990 - mae: 1.3888 - val_loss: 13.3378 - val_mae: 2.4236\n",
      "Epoch 73/100\n",
      "364/364 [==============================] - 0s 255us/sample - loss: 3.2735 - mae: 1.3981 - val_loss: 13.3602 - val_mae: 2.4250\n",
      "Epoch 74/100\n",
      "364/364 [==============================] - 0s 247us/sample - loss: 3.1402 - mae: 1.3661 - val_loss: 13.6858 - val_mae: 2.2937\n",
      "Epoch 75/100\n",
      "364/364 [==============================] - 0s 244us/sample - loss: 3.1715 - mae: 1.3669 - val_loss: 13.3027 - val_mae: 2.2992\n",
      "Epoch 76/100\n",
      "364/364 [==============================] - 0s 229us/sample - loss: 3.2133 - mae: 1.3786 - val_loss: 13.3075 - val_mae: 2.4502\n",
      "Epoch 77/100\n",
      "364/364 [==============================] - 0s 220us/sample - loss: 3.3197 - mae: 1.3623 - val_loss: 16.3328 - val_mae: 2.5298\n",
      "Epoch 78/100\n",
      "364/364 [==============================] - 0s 236us/sample - loss: 3.1366 - mae: 1.3395 - val_loss: 13.5816 - val_mae: 2.3348\n",
      "Epoch 79/100\n",
      "364/364 [==============================] - 0s 236us/sample - loss: 3.2452 - mae: 1.4144 - val_loss: 14.6794 - val_mae: 2.4861\n",
      "Epoch 80/100\n",
      "364/364 [==============================] - 0s 253us/sample - loss: 3.1504 - mae: 1.3991 - val_loss: 14.4877 - val_mae: 2.4477\n",
      "Epoch 81/100\n",
      "364/364 [==============================] - 0s 231us/sample - loss: 3.2051 - mae: 1.3766 - val_loss: 13.8728 - val_mae: 2.3453\n",
      "Epoch 82/100\n",
      "364/364 [==============================] - 0s 231us/sample - loss: 2.9069 - mae: 1.3245 - val_loss: 13.4339 - val_mae: 2.4161\n",
      "Epoch 83/100\n",
      "364/364 [==============================] - 0s 239us/sample - loss: 3.2178 - mae: 1.3443 - val_loss: 13.8153 - val_mae: 2.3691\n",
      "Epoch 84/100\n",
      "364/364 [==============================] - 0s 220us/sample - loss: 3.1519 - mae: 1.3777 - val_loss: 13.8963 - val_mae: 2.4458\n",
      "Epoch 85/100\n",
      "364/364 [==============================] - 0s 228us/sample - loss: 3.3268 - mae: 1.3962 - val_loss: 13.1906 - val_mae: 2.4056\n",
      "Epoch 86/100\n",
      "364/364 [==============================] - 0s 217us/sample - loss: 2.8774 - mae: 1.3077 - val_loss: 14.4014 - val_mae: 2.4540\n",
      "Epoch 87/100\n",
      "364/364 [==============================] - 0s 258us/sample - loss: 3.0105 - mae: 1.3050 - val_loss: 13.1474 - val_mae: 2.3939\n",
      "Epoch 88/100\n",
      "364/364 [==============================] - 0s 211us/sample - loss: 3.1727 - mae: 1.3875 - val_loss: 14.2701 - val_mae: 2.4870\n",
      "Epoch 89/100\n",
      "364/364 [==============================] - 0s 236us/sample - loss: 3.0046 - mae: 1.2983 - val_loss: 13.3936 - val_mae: 2.3380\n",
      "Epoch 90/100\n",
      "364/364 [==============================] - 0s 264us/sample - loss: 2.9962 - mae: 1.3496 - val_loss: 13.7872 - val_mae: 2.5554\n",
      "Epoch 91/100\n",
      "364/364 [==============================] - 0s 233us/sample - loss: 2.7754 - mae: 1.2866 - val_loss: 16.8383 - val_mae: 2.7738\n",
      "Epoch 92/100\n",
      "364/364 [==============================] - 0s 214us/sample - loss: 3.0195 - mae: 1.3074 - val_loss: 17.4156 - val_mae: 2.7181\n",
      "Epoch 93/100\n",
      "364/364 [==============================] - 0s 220us/sample - loss: 3.0418 - mae: 1.3567 - val_loss: 13.9468 - val_mae: 2.5909\n",
      "Epoch 94/100\n",
      "364/364 [==============================] - 0s 253us/sample - loss: 3.0452 - mae: 1.3342 - val_loss: 14.4800 - val_mae: 2.4371\n",
      "Epoch 95/100\n",
      "364/364 [==============================] - 0s 206us/sample - loss: 2.9683 - mae: 1.3069 - val_loss: 13.0497 - val_mae: 2.3088\n",
      "Epoch 96/100\n",
      "364/364 [==============================] - ETA: 0s - loss: 2.5028 - mae: 1.130 - 0s 198us/sample - loss: 2.6857 - mae: 1.2482 - val_loss: 13.5498 - val_mae: 2.4889\n",
      "Epoch 97/100\n",
      "364/364 [==============================] - 0s 195us/sample - loss: 2.8828 - mae: 1.2878 - val_loss: 13.1548 - val_mae: 2.3400\n",
      "Epoch 98/100\n",
      "364/364 [==============================] - 0s 200us/sample - loss: 2.7242 - mae: 1.2831 - val_loss: 13.7565 - val_mae: 2.3897\n",
      "Epoch 99/100\n",
      "364/364 [==============================] - 0s 206us/sample - loss: 2.9858 - mae: 1.3453 - val_loss: 13.4381 - val_mae: 2.4353\n",
      "Epoch 100/100\n",
      "364/364 [==============================] - 0s 258us/sample - loss: 2.9478 - mae: 1.3260 - val_loss: 13.7369 - val_mae: 2.4916\n",
      "51/1 - 0s - loss: 14.3281 - mae: 2.6949\n",
      "\n",
      "loss:  11.697480220420688\n",
      "MSE:   2.6949348\n"
     ]
    }
   ],
   "source": [
    "epochs = 100 #500\n",
    "drop   = 0.03\n",
    "fold = 4\n",
    "tuning_model2(epochs,drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 13)\n",
      "(455,)\n",
      "(51, 13)\n",
      "(51,)\n"
     ]
    }
   ],
   "source": [
    "# Spliting in 90%, 10%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = 13\n",
    "\n",
    "models = tf.keras.Sequential\n",
    "layers = tf.keras.layers\n",
    "\n",
    "model1 = models([layers.Dense(64,activation=\"relu\",input_shape=(input_shape,)),\n",
    "                 layers.Dropout(drop),\n",
    "                 layers.Dense(64,activation=\"relu\"),\n",
    "                 layers.Dense(64,activation=\"relu\"),\n",
    "                 layers.Dropout(drop),\n",
    "                 layers.Dense(1)])\n",
    "\n",
    "model1.compile(optimizer=\"rmsprop\", # adam #rmsprop\n",
    "             loss=\"mse\",\n",
    "             metrics=[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold #  0\n",
      "Train on 342 samples\n",
      "Epoch 1/3\n",
      "342/342 [==============================] - 2s 6ms/sample - loss: 152.2834 - mae: 8.5514\n",
      "Epoch 2/3\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 25.8090 - mae: 3.5330\n",
      "Epoch 3/3\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 22.4931 - mae: 3.2686\n",
      "processing fold #  1\n",
      "Train on 342 samples\n",
      "Epoch 1/3\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 18.8700 - mae: 2.9576\n",
      "Epoch 2/3\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 16.6353 - mae: 2.7987\n",
      "Epoch 3/3\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 15.5041 - mae: 2.7018\n",
      "processing fold #  2\n",
      "Train on 342 samples\n",
      "Epoch 1/3\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 17.9711 - mae: 2.9445\n",
      "Epoch 2/3\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 16.1588 - mae: 2.8463\n",
      "Epoch 3/3\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 17.1966 - mae: 2.8952\n",
      "processing fold #  3\n",
      "Train on 342 samples\n",
      "Epoch 1/3\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 14.7924 - mae: 2.6339\n",
      "Epoch 2/3\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 14.5112 - mae: 2.7274\n",
      "Epoch 3/3\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 14.3857 - mae: 2.5561\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(x_train) // 4\n",
    "num_epochs = 3 #500\n",
    "drop   = 0.03\n",
    "all_scores = []\n",
    "all_mae_histories = []\n",
    "\n",
    "for i in range(k):\n",
    "  print('processing fold # ', i)\n",
    "  # prepare the validation data: data from partition # k\n",
    "  val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  \n",
    "  # prepare the training data: data from data - k\n",
    "  partial_train_data = np.concatenate(                    \n",
    "      [x_train[:i * num_val_samples],\n",
    "      x_train[(i + 1 ) * num_val_samples:]],\n",
    "  axis = 0)\n",
    "  partial_train_targets = np.concatenate(\n",
    "      [y_train[:i * num_val_samples],\n",
    "      y_train[(i + 1 ) * num_val_samples:]],\n",
    "  axis = 0)\n",
    "  # Build the Keras Models (already commpiled)\n",
    "  #model = build_model()\n",
    "  # Train the model (in silence mode, verbose = 0)\n",
    "  model1.fit(partial_train_data, partial_train_targets, epochs = num_epochs, batch_size = 1, verbose = 1)\n",
    "  # Evaluate the model on the validation data\n",
    "  val_mse, val_mae = model1.evaluate(val_data, val_targets, verbose = 0)\n",
    "  all_scores.append(val_mae)\n",
    "\n",
    "  mae_history = history.history['val_mae']\n",
    "  all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.4443822, 2.9352527, 2.176864, 2.5903218]\n",
      "\n",
      "2.786705\n"
     ]
    }
   ],
   "source": [
    "print(all_scores)\n",
    "print()\n",
    "print(np.mean(all_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(average_mae_history) + 1 ), average_mae_history)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter tuning K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_model3(epochs,drop,fold):\n",
    "    print()\n",
    "    models = tf.keras.models.Sequential\n",
    "    layers = tf.keras.layers\n",
    "\n",
    "    model2 = models([layers.Dense(64,input_shape = (input_shape,)),\n",
    "                     layers.Dropout(drop),\n",
    "                     layers.Dense(64,activation=\"relu\"),\n",
    "                     layers.Dense(64,activation=\"relu\"),\n",
    "                     layers.Dropout(drop),\n",
    "                     layers.Dense(1)])\n",
    "    \n",
    "    model2.compile(optimizer=\"adam\", # rmsprop # adam # \n",
    "             loss=\"mse\", # binary_crossentropy\n",
    "              metrics=[\"mae\"])\n",
    "    \n",
    "    k = fold\n",
    "    num_val_samples = len(x_train) // 4\n",
    "    #num_epochs = 500\n",
    "    all_scores = []\n",
    "    all_mae_histories = []\n",
    "\n",
    "    for i in range(k):\n",
    "      print('processing fold # ', i)\n",
    "      # prepare the validation data: data from partition # k\n",
    "      val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "      val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "      # prepare the training data: data from data - k\n",
    "      partial_train_data = np.concatenate(                    \n",
    "          [x_train[:i * num_val_samples],\n",
    "          x_train[(i + 1 ) * num_val_samples:]],\n",
    "      axis = 0)\n",
    "      partial_train_targets = np.concatenate(\n",
    "          [y_train[:i * num_val_samples],\n",
    "          y_train[(i + 1 ) * num_val_samples:]],\n",
    "      axis = 0)\n",
    "      # Build the Keras Models (already commpiled)\n",
    "      # model = build_model()\n",
    "      # Train the model (in silence mode, verbose = 0)\n",
    "      model2.fit(partial_train_data, partial_train_targets, epochs = epochs, batch_size = 1, verbose = 1)\n",
    "      # Evaluate the model on the validation data\n",
    "      val_mse, val_mae = model2.evaluate(val_data, val_targets, verbose = 0)\n",
    "      all_scores.append(val_mae)\n",
    "\n",
    "      mae_history = history.history['val_mae']\n",
    "      all_mae_histories.append(mae_history)\n",
    "    \n",
    "    print(all_scores)\n",
    "    print()\n",
    "    print(\"mae :\",np.mean(all_scores))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "processing fold #  0\n",
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 2s 5ms/sample - loss: 149.9662 - mae: 8.6194\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 28.0146 - mae: 3.7556\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 20.2148 - mae: 3.3175\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 18.8737 - mae: 3.1692\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 20.1904 - mae: 3.3245\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 18.8621 - mae: 3.1694\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 16.6526 - mae: 2.9000\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 17.2068 - mae: 2.9836\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 15.0440 - mae: 2.7936\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 16.1683 - mae: 2.9530\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 14.7254 - mae: 2.7508\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 14.2364 - mae: 2.7416\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 14.2648 - mae: 2.7435\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 13.3712 - mae: 2.7011\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 15.3946 - mae: 2.7513\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 13.9323 - mae: 2.6564\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 12.0708 - mae: 2.5125\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 12.9950 - mae: 2.6766\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 11.4958 - mae: 2.4666\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 10.8059 - mae: 2.3946\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 12.0317 - mae: 2.4954\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 11.5040 - mae: 2.4171\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 11.3895 - mae: 2.3684\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 10.7509 - mae: 2.4245\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 11.0154 - mae: 2.3827\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 11.9922 - mae: 2.4599\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 10.3779 - mae: 2.4642\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 10.2756 - mae: 2.3612\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 10.1733 - mae: 2.4169\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 9.9019 - mae: 2.2856\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 9.9236 - mae: 2.2848\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 9.2344 - mae: 2.2240\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 9.6937 - mae: 2.2526\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 9.9727 - mae: 2.3681\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 8.1480 - mae: 2.1366\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 9.2746 - mae: 2.2663\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 9.3628 - mae: 2.2666\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 9.5327 - mae: 2.2517\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 7.8431 - mae: 2.1317\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 7.7052 - mae: 2.1085\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 9.7576 - mae: 2.3202\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 9.0669 - mae: 2.2094\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 9.1271 - mae: 2.0964\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 7.5494 - mae: 1.9777\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 7.5978 - mae: 2.0523\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 8.8036 - mae: 2.0882\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 8.6365 - mae: 2.1346\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 6.8670 - mae: 1.9108\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 6.5285 - mae: 1.9656\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 7.6873 - mae: 2.0030\n",
      "processing fold #  1\n",
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 13.4576 - mae: 2.6333\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 9.6148 - mae: 2.3361\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 8.6432 - mae: 2.1841\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 7.3682 - mae: 2.0447\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 8.2790 - mae: 2.1322\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 7.0301 - mae: 2.0379\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 7.7798 - mae: 2.0752\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 8.6460 - mae: 2.1545\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 7.6689 - mae: 2.1018\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 6.9439 - mae: 2.0314\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 7.5284 - mae: 1.9857\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 7.8416 - mae: 2.1205\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 7.4313 - mae: 1.9467\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.7522 - mae: 1.9463\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.8578 - mae: 1.9241\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 8.0084 - mae: 2.1549\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 7.5183 - mae: 2.0176\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.4121 - mae: 1.8594\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.8341 - mae: 1.8422\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 7.1416 - mae: 1.9949\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.7677 - mae: 1.9612\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 8.0164 - mae: 2.1250\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.8264 - mae: 1.8095\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.5103 - mae: 1.9260\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.8318 - mae: 1.8801\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.6319 - mae: 1.9563\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.3743 - mae: 1.7886\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 8.2186 - mae: 2.0390\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 5.8538 - mae: 1.8219\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 5.8747 - mae: 1.8181\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 6.0369 - mae: 1.7982\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 7.4419 - mae: 2.0158\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 5.0813 - mae: 1.7162\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.5963 - mae: 1.7856\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.6417 - mae: 1.9263\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 7.2599 - mae: 1.9203\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 5.4868 - mae: 1.7880\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 6.5489 - mae: 1.9067\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.9073 - mae: 1.8159\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.0106 - mae: 1.8723\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 6.1697 - mae: 1.8400\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.4989 - mae: 1.7683\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.7975 - mae: 1.9027\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.4244 - mae: 1.7189\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.0796 - mae: 1.7061\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.0053 - mae: 1.7618\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.6764 - mae: 1.6558\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 5.1170 - mae: 1.7531\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 5.0688 - mae: 1.7233\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 5.4236 - mae: 1.8014\n",
      "processing fold #  2\n",
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 11.0501 - mae: 2.4463\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 7.4892 - mae: 2.0558\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 7.1642 - mae: 1.9733\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 6.8893 - mae: 1.9734\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 6.5232 - mae: 1.8232\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.8436 - mae: 1.9599\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.9948 - mae: 1.8302 0s - loss: 3\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.2894 - mae: 1.8651\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.8813 - mae: 1.8238\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 5.7127 - mae: 1.7945\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.5158 - mae: 1.7950\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.3475 - mae: 1.6947\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.5186 - mae: 1.5894\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.6973 - mae: 1.9107\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.2793 - mae: 1.7529\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.4091 - mae: 1.8683\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 7.5855 - mae: 1.8302\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.8787 - mae: 1.6261\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.4593 - mae: 1.7318\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.9794 - mae: 1.8006\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.7850 - mae: 1.8422\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.8324 - mae: 1.7394\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.0807 - mae: 1.6977\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.9475 - mae: 1.6327\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.9235 - mae: 1.6964\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.9418 - mae: 1.6646\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.2990 - mae: 1.5358\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.1639 - mae: 1.7000 0s - loss: 5\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.4752 - mae: 1.6694\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.4055 - mae: 1.6166\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.6811 - mae: 1.6353\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.7791 - mae: 1.5046\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.6021 - mae: 1.5508\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.9609 - mae: 1.7509\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.6936 - mae: 1.7466\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.7167 - mae: 1.7978\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.1720 - mae: 1.6329\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.1218 - mae: 1.5547\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.4809 - mae: 1.7187\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.9828 - mae: 1.5396\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.5237 - mae: 1.6636\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.7549 - mae: 1.6326\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.3298 - mae: 1.5233\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.6398 - mae: 1.6470\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.0004 - mae: 1.5030\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.1049 - mae: 1.5458\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.2467 - mae: 1.5624\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 4.9024 - mae: 1.6858\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.1477 - mae: 1.7016\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.1434 - mae: 1.6119\n",
      "processing fold #  3\n",
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 6.8213 - mae: 1.9431\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 6.3229 - mae: 1.9119\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.6031 - mae: 1.4909\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.0480 - mae: 1.6984\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.2805 - mae: 1.5803\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.3482 - mae: 1.7712\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.1380 - mae: 1.5477\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.1273 - mae: 1.5687\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 5.1090 - mae: 1.6992\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.3288 - mae: 1.7549\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.8368 - mae: 1.5278\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.9703 - mae: 1.6779\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.4267 - mae: 1.5859\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.3725 - mae: 1.3860\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.1939 - mae: 1.5894\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.4231 - mae: 1.5688\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.5607 - mae: 1.5544\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.1904 - mae: 1.5286\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.6803 - mae: 1.6268\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 3.5318 - mae: 1.4554\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.6529 - mae: 1.4509\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 4.3579 - mae: 1.5932\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.0302 - mae: 1.6417\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.5807 - mae: 1.4061\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 5.2918 - mae: 1.7062\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.8011 - mae: 1.4979\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.9344 - mae: 1.4833\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 3.5045 - mae: 1.4064\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 3.7084 - mae: 1.4723\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 3.5363 - mae: 1.4343\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 5.0804 - mae: 1.6318\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 3.7988 - mae: 1.4929\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 5.1550 - mae: 1.6624\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.0470 - mae: 1.5325\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 3.8102 - mae: 1.4713\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 3.4791 - mae: 1.4286\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.8106 - mae: 1.4514\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.6834 - mae: 1.4711\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 3.6887 - mae: 1.5285\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.6249 - mae: 1.6052\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.5779 - mae: 1.4159\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.4468 - mae: 1.5358\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.6279 - mae: 1.4599\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.6263 - mae: 1.4170\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.1056 - mae: 1.2907\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.8192 - mae: 1.4257\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.5945 - mae: 1.3866\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 3.8998 - mae: 1.4294\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 2.9211 - mae: 1.2671\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 4.1323 - mae: 1.4972\n",
      "[2.5020976, 2.791351, 2.211483, 2.0072403]\n",
      "\n",
      "mae : 2.378043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 50 #500\n",
    "drop   = 0.03\n",
    "fold = 4\n",
    "tuning_model3(epochs,drop,fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
