{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete Compressive Strength Data Set\n",
    " Concrete is the most important material in civil engineering. The concrete compressive strength is a highly nonlinear function of age and ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'best-of-8-regression-models-to-predict-strength.ipynb',\n",
       " 'compresive_strength_concrete.csv',\n",
       " 'compresive_strength_concrete.ipynb',\n",
       " 'compresive_strength_concrete_final.ipynb',\n",
       " 'compresive_strength_concrete_final2.ipynb',\n",
       " 'practice.ipynb',\n",
       " 'Untitled.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                         540.0   \n",
       "1                                         540.0   \n",
       "2                                         332.5   \n",
       "3                                         332.5   \n",
       "4                                         198.6   \n",
       "...                                         ...   \n",
       "1025                                      276.4   \n",
       "1026                                      322.2   \n",
       "1027                                      148.5   \n",
       "1028                                      159.1   \n",
       "1029                                      260.9   \n",
       "\n",
       "      Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                                   0.0       \n",
       "1                                                   0.0       \n",
       "2                                                 142.5       \n",
       "3                                                 142.5       \n",
       "4                                                 132.4       \n",
       "...                                                 ...       \n",
       "1025                                              116.0       \n",
       "1026                                                0.0       \n",
       "1027                                              139.4       \n",
       "1028                                              186.7       \n",
       "1029                                              100.5       \n",
       "\n",
       "      Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "...                                          ...   \n",
       "1025                                        90.3   \n",
       "1026                                       115.6   \n",
       "1027                                       108.6   \n",
       "1028                                         0.0   \n",
       "1029                                        78.3   \n",
       "\n",
       "      Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                         162.0   \n",
       "1                                         162.0   \n",
       "2                                         228.0   \n",
       "3                                         228.0   \n",
       "4                                         192.0   \n",
       "...                                         ...   \n",
       "1025                                      179.6   \n",
       "1026                                      196.0   \n",
       "1027                                      192.7   \n",
       "1028                                      175.6   \n",
       "1029                                      200.6   \n",
       "\n",
       "      Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                                   2.5     \n",
       "1                                                   2.5     \n",
       "2                                                   0.0     \n",
       "3                                                   0.0     \n",
       "4                                                   0.0     \n",
       "...                                                 ...     \n",
       "1025                                                8.9     \n",
       "1026                                               10.4     \n",
       "1027                                                6.1     \n",
       "1028                                               11.3     \n",
       "1029                                                8.6     \n",
       "\n",
       "      Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                                1040.0      \n",
       "1                                                1055.0      \n",
       "2                                                 932.0      \n",
       "3                                                 932.0      \n",
       "4                                                 978.4      \n",
       "...                                                 ...      \n",
       "1025                                              870.1      \n",
       "1026                                              817.9      \n",
       "1027                                              892.4      \n",
       "1028                                              989.6      \n",
       "1029                                              864.5      \n",
       "\n",
       "      Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \\\n",
       "0                                                 676.0         28   \n",
       "1                                                 676.0         28   \n",
       "2                                                 594.0        270   \n",
       "3                                                 594.0        365   \n",
       "4                                                 825.5        360   \n",
       "...                                                 ...        ...   \n",
       "1025                                              768.3         28   \n",
       "1026                                              813.4         28   \n",
       "1027                                              780.0         28   \n",
       "1028                                              788.9         28   \n",
       "1029                                              761.5         28   \n",
       "\n",
       "      Concrete compressive strength(MPa, megapascals)   \n",
       "0                                                79.99  \n",
       "1                                                61.89  \n",
       "2                                                40.27  \n",
       "3                                                41.05  \n",
       "4                                                44.30  \n",
       "...                                                ...  \n",
       "1025                                             44.28  \n",
       "1026                                             31.18  \n",
       "1027                                             23.70  \n",
       "1028                                             32.77  \n",
       "1029                                             32.40  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"compresive_strength_concrete.csv\")\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>281.167864</td>\n",
       "      <td>104.506364</td>\n",
       "      <td>102.00</td>\n",
       "      <td>192.375</td>\n",
       "      <td>272.900</td>\n",
       "      <td>350.000</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>142.950</td>\n",
       "      <td>359.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>118.300</td>\n",
       "      <td>200.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>121.80</td>\n",
       "      <td>164.900</td>\n",
       "      <td>185.000</td>\n",
       "      <td>192.000</td>\n",
       "      <td>247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.400</td>\n",
       "      <td>10.200</td>\n",
       "      <td>32.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>801.00</td>\n",
       "      <td>932.000</td>\n",
       "      <td>968.000</td>\n",
       "      <td>1029.400</td>\n",
       "      <td>1145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>594.00</td>\n",
       "      <td>730.950</td>\n",
       "      <td>779.500</td>\n",
       "      <td>824.000</td>\n",
       "      <td>992.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age (day)</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>35.817961</td>\n",
       "      <td>16.705742</td>\n",
       "      <td>2.33</td>\n",
       "      <td>23.710</td>\n",
       "      <td>34.445</td>\n",
       "      <td>46.135</td>\n",
       "      <td>82.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     count        mean  \\\n",
       "Cement (component 1)(kg in a m^3 mixture)           1030.0  281.167864   \n",
       "Blast Furnace Slag (component 2)(kg in a m^3 mi...  1030.0   73.895825   \n",
       "Fly Ash (component 3)(kg in a m^3 mixture)          1030.0   54.188350   \n",
       "Water  (component 4)(kg in a m^3 mixture)           1030.0  181.567282   \n",
       "Superplasticizer (component 5)(kg in a m^3 mixt...  1030.0    6.204660   \n",
       "Coarse Aggregate  (component 6)(kg in a m^3 mix...  1030.0  972.918932   \n",
       "Fine Aggregate (component 7)(kg in a m^3 mixture)   1030.0  773.580485   \n",
       "Age (day)                                           1030.0   45.662136   \n",
       "Concrete compressive strength(MPa, megapascals)     1030.0   35.817961   \n",
       "\n",
       "                                                           std     min  \\\n",
       "Cement (component 1)(kg in a m^3 mixture)           104.506364  102.00   \n",
       "Blast Furnace Slag (component 2)(kg in a m^3 mi...   86.279342    0.00   \n",
       "Fly Ash (component 3)(kg in a m^3 mixture)           63.997004    0.00   \n",
       "Water  (component 4)(kg in a m^3 mixture)            21.354219  121.80   \n",
       "Superplasticizer (component 5)(kg in a m^3 mixt...    5.973841    0.00   \n",
       "Coarse Aggregate  (component 6)(kg in a m^3 mix...   77.753954  801.00   \n",
       "Fine Aggregate (component 7)(kg in a m^3 mixture)    80.175980  594.00   \n",
       "Age (day)                                            63.169912    1.00   \n",
       "Concrete compressive strength(MPa, megapascals)      16.705742    2.33   \n",
       "\n",
       "                                                        25%      50%  \\\n",
       "Cement (component 1)(kg in a m^3 mixture)           192.375  272.900   \n",
       "Blast Furnace Slag (component 2)(kg in a m^3 mi...    0.000   22.000   \n",
       "Fly Ash (component 3)(kg in a m^3 mixture)            0.000    0.000   \n",
       "Water  (component 4)(kg in a m^3 mixture)           164.900  185.000   \n",
       "Superplasticizer (component 5)(kg in a m^3 mixt...    0.000    6.400   \n",
       "Coarse Aggregate  (component 6)(kg in a m^3 mix...  932.000  968.000   \n",
       "Fine Aggregate (component 7)(kg in a m^3 mixture)   730.950  779.500   \n",
       "Age (day)                                             7.000   28.000   \n",
       "Concrete compressive strength(MPa, megapascals)      23.710   34.445   \n",
       "\n",
       "                                                         75%     max  \n",
       "Cement (component 1)(kg in a m^3 mixture)            350.000   540.0  \n",
       "Blast Furnace Slag (component 2)(kg in a m^3 mi...   142.950   359.4  \n",
       "Fly Ash (component 3)(kg in a m^3 mixture)           118.300   200.1  \n",
       "Water  (component 4)(kg in a m^3 mixture)            192.000   247.0  \n",
       "Superplasticizer (component 5)(kg in a m^3 mixt...    10.200    32.2  \n",
       "Coarse Aggregate  (component 6)(kg in a m^3 mix...  1029.400  1145.0  \n",
       "Fine Aggregate (component 7)(kg in a m^3 mixture)    824.000   992.6  \n",
       "Age (day)                                             56.000   365.0  \n",
       "Concrete compressive strength(MPa, megapascals)       46.135    82.6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Cement (component 1)(kg in a m^3 mixture)              1030 non-null   float64\n",
      " 1   Blast Furnace Slag (component 2)(kg in a m^3 mixture)  1030 non-null   float64\n",
      " 2   Fly Ash (component 3)(kg in a m^3 mixture)             1030 non-null   float64\n",
      " 3   Water  (component 4)(kg in a m^3 mixture)              1030 non-null   float64\n",
      " 4   Superplasticizer (component 5)(kg in a m^3 mixture)    1030 non-null   float64\n",
      " 5   Coarse Aggregate  (component 6)(kg in a m^3 mixture)   1030 non-null   float64\n",
      " 6   Fine Aggregate (component 7)(kg in a m^3 mixture)      1030 non-null   float64\n",
      " 7   Age (day)                                              1030 non-null   int64  \n",
      " 8   Concrete compressive strength(MPa, megapascals)        1030 non-null   float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 72.5 KB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cement (component 1)(kg in a m^3 mixture)',\n",
       "       'Blast Furnace Slag (component 2)(kg in a m^3 mixture)',\n",
       "       'Fly Ash (component 3)(kg in a m^3 mixture)',\n",
       "       'Water  (component 4)(kg in a m^3 mixture)',\n",
       "       'Superplasticizer (component 5)(kg in a m^3 mixture)',\n",
       "       'Coarse Aggregate  (component 6)(kg in a m^3 mixture)',\n",
       "       'Fine Aggregate (component 7)(kg in a m^3 mixture)', 'Age (day)',\n",
       "       'Concrete compressive strength(MPa, megapascals) '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Concrete compressive strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Concrete compressive strength  \n",
       "0            1040.0           676.0   28                          79.99  \n",
       "1            1055.0           676.0   28                          61.89  \n",
       "2             932.0           594.0  270                          40.27  \n",
       "3             932.0           594.0  365                          41.05  \n",
       "4             978.4           825.5  360                          44.30  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing column names for no reason\n",
    "#data.columns = [col[:col.find(\"(\")].strip() for col in data.columns]\n",
    "a = []\n",
    "for col in data_df.columns:\n",
    "    b = (col[:col.find(\"(\")].strip())\n",
    "    a.append(b)\n",
    "data_df.columns = a\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing 0 with mean\n",
    "\n",
    "#data_df = data_df.replace(np.nan,0.0)\n",
    "#data_df = data_df.replace(0.0,data_df.mean())\n",
    "#data_df = data_df.sample(frac=1)\n",
    "#data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows : 1030\n",
      "\n",
      "50%  515.0\n",
      "30%  309.0\n",
      "20%  206.0\n",
      "\n",
      "Total  1030\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Rows :\",len(data_df))\n",
    "print()\n",
    "print(\"50% \",1030*.5)\n",
    "print(\"30% \",1030*.3)\n",
    "print(\"20% \",1030*.2)\n",
    "print()\n",
    "print(\"Total \",515+309+206)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[79.99 61.89 40.27 ... 23.7  32.77 32.4 ]\n"
     ]
    }
   ],
   "source": [
    "Samples = data_df.iloc[:,:-1]\n",
    "Labels = data_df.iloc[:,-1:]\n",
    "Samples = Samples.values\n",
    "Labels = Labels.values\n",
    "Labels = Labels.ravel()\n",
    "print()\n",
    "print(Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing data(scaling data) Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.68491213, -0.84750875, -0.84750875, ...,  2.10382035,\n",
       "         1.07085517, -0.76804989],\n",
       "       [ 0.68491213, -0.84750875, -0.84750875, ...,  2.1463876 ,\n",
       "         1.07085517, -0.76804989],\n",
       "       [ 0.09606522, -0.44311991, -0.84750875, ...,  1.79733617,\n",
       "         0.83815422, -0.08129831],\n",
       "       ...,\n",
       "       [-0.42609301, -0.45191714, -0.53932188, ...,  1.68495864,\n",
       "         1.36598808, -0.76804989],\n",
       "       [-0.39601215, -0.31768842, -0.84750875, ...,  1.9607944 ,\n",
       "         1.39124464, -0.76804989],\n",
       "       [-0.10712244, -0.5623082 , -0.62530772, ...,  1.60578356,\n",
       "         1.31348847, -0.76804989]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean = Samples.mean()\n",
    "std = Samples.std()\n",
    "Samples -= mean\n",
    "Samples /= std\n",
    "display(Samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalizing data(scaling data) through library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "#scale = StandardScaler()\n",
    "#Samples = scale.fit_transform(Samples)\n",
    "#print(Samples.shape)\n",
    "#print()\n",
    "#Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data in 50%, 30%, 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(515, 8)\n",
      "(515,)\n",
      "(309, 8)\n",
      "(309,)\n",
      "(206, 8)\n",
      "(206,)\n"
     ]
    }
   ],
   "source": [
    "# use this method for split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(Samples, Labels, test_size=0.3, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.285)#, random_state=1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Spliting data in 50%, 30%, 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or manual split\n",
    "#x_train = Samples[:515]\n",
    "#x_test = Samples[515:824]\n",
    "#x_val = Samples[824:]\n",
    "#y_train = Labels[:515]\n",
    "#y_test = Labels[515:824]\n",
    "#y_val = Labels[824:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 515 samples, validate on 206 samples\n",
      "Epoch 1/1000\n",
      "515/515 [==============================] - 2s 4ms/sample - loss: 1380.7327 - mae: 33.2413 - val_loss: 1204.8818 - val_mae: 29.7791\n",
      "Epoch 2/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 1034.4786 - mae: 27.5759 - val_loss: 840.2067 - val_mae: 23.4289\n",
      "Epoch 3/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 655.2579 - mae: 20.7659 - val_loss: 509.7878 - val_mae: 17.7340\n",
      "Epoch 4/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 389.5611 - mae: 15.8816 - val_loss: 351.7763 - val_mae: 15.1373\n",
      "Epoch 5/1000\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 301.1897 - mae: 14.1055 - val_loss: 331.2570 - val_mae: 14.8251\n",
      "Epoch 6/1000\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 289.5338 - mae: 13.9182 - val_loss: 325.5081 - val_mae: 14.6627\n",
      "Epoch 7/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 284.8376 - mae: 13.8046 - val_loss: 324.7899 - val_mae: 14.7232\n",
      "Epoch 8/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 280.0033 - mae: 13.6638 - val_loss: 320.7023 - val_mae: 14.6153\n",
      "Epoch 9/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 274.9572 - mae: 13.5877 - val_loss: 316.2332 - val_mae: 14.3843\n",
      "Epoch 10/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 273.6250 - mae: 13.5064 - val_loss: 313.0940 - val_mae: 14.4237\n",
      "Epoch 11/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 266.9879 - mae: 13.3732 - val_loss: 315.4393 - val_mae: 14.5145\n",
      "Epoch 12/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 264.8073 - mae: 13.3257 - val_loss: 303.9031 - val_mae: 14.1831\n",
      "Epoch 13/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 259.7459 - mae: 13.2311 - val_loss: 303.8123 - val_mae: 14.0486\n",
      "Epoch 14/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 255.2601 - mae: 13.0364 - val_loss: 295.7173 - val_mae: 13.8671\n",
      "Epoch 15/1000\n",
      "515/515 [==============================] - 1s 1ms/sample - loss: 251.3793 - mae: 13.0287 - val_loss: 288.0814 - val_mae: 13.7416\n",
      "Epoch 16/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 246.3123 - mae: 12.8691 - val_loss: 282.9073 - val_mae: 13.6107\n",
      "Epoch 17/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 241.2710 - mae: 12.7651 - val_loss: 280.2228 - val_mae: 13.4797\n",
      "Epoch 18/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 236.3765 - mae: 12.6425 - val_loss: 273.8629 - val_mae: 13.3507\n",
      "Epoch 19/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 232.1243 - mae: 12.5819 - val_loss: 269.9280 - val_mae: 13.3173\n",
      "Epoch 20/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 228.6834 - mae: 12.4503 - val_loss: 271.0483 - val_mae: 13.1982\n",
      "Epoch 21/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 223.0550 - mae: 12.3145 - val_loss: 261.6963 - val_mae: 13.1330\n",
      "Epoch 22/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 219.6339 - mae: 12.2494 - val_loss: 259.8068 - val_mae: 13.0966\n",
      "Epoch 23/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 216.6489 - mae: 12.1823 - val_loss: 257.4888 - val_mae: 13.0327\n",
      "Epoch 24/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 214.4602 - mae: 12.1227 - val_loss: 253.0438 - val_mae: 12.7688\n",
      "Epoch 25/1000\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 209.9525 - mae: 12.0218 - val_loss: 254.1325 - val_mae: 12.9528\n",
      "Epoch 26/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 208.2896 - mae: 11.9576 - val_loss: 246.9616 - val_mae: 12.6100\n",
      "Epoch 27/1000\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 204.1578 - mae: 11.9133 - val_loss: 245.7654 - val_mae: 12.7078\n",
      "Epoch 28/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 200.0192 - mae: 11.8107 - val_loss: 248.5910 - val_mae: 12.7906\n",
      "Epoch 29/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 197.2551 - mae: 11.6187 - val_loss: 248.7204 - val_mae: 12.5421\n",
      "Epoch 30/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 193.1308 - mae: 11.5734 - val_loss: 256.3701 - val_mae: 12.7200\n",
      "Epoch 31/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 196.4749 - mae: 11.6670 - val_loss: 232.7514 - val_mae: 12.2969\n",
      "Epoch 32/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 191.4228 - mae: 11.4947 - val_loss: 232.4148 - val_mae: 12.2037\n",
      "Epoch 33/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 188.5429 - mae: 11.4411 - val_loss: 228.0466 - val_mae: 12.1438\n",
      "Epoch 34/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 186.6275 - mae: 11.3633 - val_loss: 240.2769 - val_mae: 12.5969\n",
      "Epoch 35/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 186.6842 - mae: 11.4331 - val_loss: 227.9903 - val_mae: 12.2179\n",
      "Epoch 36/1000\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 181.9810 - mae: 11.2534 - val_loss: 222.7972 - val_mae: 12.0355\n",
      "Epoch 37/1000\n",
      "515/515 [==============================] - 0s 316us/sample - loss: 181.5478 - mae: 11.2309 - val_loss: 226.5024 - val_mae: 12.2060\n",
      "Epoch 38/1000\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 179.9604 - mae: 11.2026 - val_loss: 221.4244 - val_mae: 12.0463\n",
      "Epoch 39/1000\n",
      "515/515 [==============================] - 0s 309us/sample - loss: 177.9270 - mae: 11.1231 - val_loss: 216.4718 - val_mae: 11.8023\n",
      "Epoch 40/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 174.3970 - mae: 11.0091 - val_loss: 216.8048 - val_mae: 11.7202\n",
      "Epoch 41/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 173.2098 - mae: 10.9888 - val_loss: 212.7824 - val_mae: 11.6846\n",
      "Epoch 42/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 170.9162 - mae: 10.8994 - val_loss: 213.9096 - val_mae: 11.6059\n",
      "Epoch 43/1000\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 167.4000 - mae: 10.7494 - val_loss: 208.3243 - val_mae: 11.6289\n",
      "Epoch 44/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 165.6672 - mae: 10.7440 - val_loss: 214.9344 - val_mae: 11.9165\n",
      "Epoch 45/1000\n",
      "515/515 [==============================] - 0s 278us/sample - loss: 162.6520 - mae: 10.6114 - val_loss: 206.3287 - val_mae: 11.4392\n",
      "Epoch 46/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 161.5767 - mae: 10.5189 - val_loss: 221.0478 - val_mae: 12.1208\n",
      "Epoch 47/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 161.0266 - mae: 10.6015 - val_loss: 202.4843 - val_mae: 11.5098\n",
      "Epoch 48/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 157.0157 - mae: 10.4057 - val_loss: 197.6925 - val_mae: 11.2816\n",
      "Epoch 49/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 155.1435 - mae: 10.2775 - val_loss: 200.2794 - val_mae: 11.2388\n",
      "Epoch 50/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 153.6867 - mae: 10.3129 - val_loss: 192.7520 - val_mae: 11.0997\n",
      "Epoch 51/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 150.7254 - mae: 10.1465 - val_loss: 199.4713 - val_mae: 11.4926\n",
      "Epoch 52/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 149.9644 - mae: 10.1441 - val_loss: 196.9028 - val_mae: 11.1602\n",
      "Epoch 53/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 146.5924 - mae: 9.9975 - val_loss: 186.5648 - val_mae: 10.9888\n",
      "Epoch 54/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 145.8963 - mae: 9.9534 - val_loss: 186.4705 - val_mae: 10.8758\n",
      "Epoch 55/1000\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 142.0329 - mae: 9.8469 - val_loss: 189.7087 - val_mae: 10.9610\n",
      "Epoch 56/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 141.3111 - mae: 9.8346 - val_loss: 190.2363 - val_mae: 11.2530\n",
      "Epoch 57/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 140.2868 - mae: 9.8197 - val_loss: 180.8102 - val_mae: 10.8783\n",
      "Epoch 58/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 136.5218 - mae: 9.6604 - val_loss: 175.9295 - val_mae: 10.6611\n",
      "Epoch 59/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 136.9258 - mae: 9.6731 - val_loss: 172.6500 - val_mae: 10.5316\n",
      "Epoch 60/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 134.6204 - mae: 9.5655 - val_loss: 173.8759 - val_mae: 10.4829\n",
      "Epoch 61/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 131.0219 - mae: 9.4693 - val_loss: 168.0052 - val_mae: 10.3700\n",
      "Epoch 62/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 133.2837 - mae: 9.4720 - val_loss: 167.1651 - val_mae: 10.3795\n",
      "Epoch 63/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 128.9834 - mae: 9.3320 - val_loss: 165.8595 - val_mae: 10.2411\n",
      "Epoch 64/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 126.3647 - mae: 9.2569 - val_loss: 180.5825 - val_mae: 10.8428\n",
      "Epoch 65/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 128.1201 - mae: 9.3076 - val_loss: 177.7479 - val_mae: 10.7403\n",
      "Epoch 66/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 126.0296 - mae: 9.2565 - val_loss: 160.3802 - val_mae: 10.0611\n",
      "Epoch 67/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 122.6412 - mae: 9.0970 - val_loss: 155.8830 - val_mae: 9.9242\n",
      "Epoch 68/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 122.0995 - mae: 8.9973 - val_loss: 153.2795 - val_mae: 9.8611\n",
      "Epoch 69/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 119.2288 - mae: 8.8947 - val_loss: 157.4686 - val_mae: 10.0410\n",
      "Epoch 70/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 115.7404 - mae: 8.7499 - val_loss: 158.6019 - val_mae: 10.1876\n",
      "Epoch 71/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 117.0301 - mae: 8.7584 - val_loss: 155.3052 - val_mae: 10.0530\n",
      "Epoch 72/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 114.2744 - mae: 8.7023 - val_loss: 143.4527 - val_mae: 9.5222\n",
      "Epoch 73/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 113.2111 - mae: 8.6242 - val_loss: 185.3490 - val_mae: 11.1450\n",
      "Epoch 74/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 115.0389 - mae: 8.7242 - val_loss: 146.2761 - val_mae: 9.7123\n",
      "Epoch 75/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 111.5285 - mae: 8.5009 - val_loss: 160.1598 - val_mae: 10.2470\n",
      "Epoch 76/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 111.9922 - mae: 8.5795 - val_loss: 143.6672 - val_mae: 9.5870\n",
      "Epoch 77/1000\n",
      "515/515 [==============================] - 0s 260us/sample - loss: 109.9197 - mae: 8.4076 - val_loss: 138.5185 - val_mae: 9.3764\n",
      "Epoch 78/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 108.4596 - mae: 8.3724 - val_loss: 143.6121 - val_mae: 9.5769\n",
      "Epoch 79/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 110.2254 - mae: 8.2739 - val_loss: 139.8670 - val_mae: 9.4525\n",
      "Epoch 80/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 108.0527 - mae: 8.3171 - val_loss: 137.6671 - val_mae: 9.3711\n",
      "Epoch 81/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 108.1033 - mae: 8.3404 - val_loss: 135.6587 - val_mae: 9.2826\n",
      "Epoch 82/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 107.3498 - mae: 8.2355 - val_loss: 141.0656 - val_mae: 9.5307\n",
      "Epoch 83/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 106.6922 - mae: 8.1930 - val_loss: 130.8262 - val_mae: 9.1068\n",
      "Epoch 84/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 106.0074 - mae: 8.1965 - val_loss: 133.4681 - val_mae: 9.2608\n",
      "Epoch 85/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 104.3820 - mae: 8.0492 - val_loss: 147.8237 - val_mae: 9.8661\n",
      "Epoch 86/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 104.7751 - mae: 8.1533 - val_loss: 173.5055 - val_mae: 10.7084\n",
      "Epoch 87/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 106.3697 - mae: 8.2681 - val_loss: 148.1890 - val_mae: 9.8668\n",
      "Epoch 88/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 105.6766 - mae: 8.1593 - val_loss: 126.0138 - val_mae: 8.9616\n",
      "Epoch 89/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 104.0236 - mae: 8.1003 - val_loss: 127.1726 - val_mae: 9.0046\n",
      "Epoch 90/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 104.4878 - mae: 8.0658 - val_loss: 143.6824 - val_mae: 9.7046\n",
      "Epoch 91/1000\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 104.7151 - mae: 8.0574 - val_loss: 126.2730 - val_mae: 8.9796\n",
      "Epoch 92/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 104.1491 - mae: 8.0784 - val_loss: 146.5193 - val_mae: 9.7607\n",
      "Epoch 93/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 103.4869 - mae: 8.0827 - val_loss: 155.7000 - val_mae: 10.1408\n",
      "Epoch 94/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 105.7166 - mae: 8.1016 - val_loss: 124.0681 - val_mae: 8.8952\n",
      "Epoch 95/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 104.1864 - mae: 8.0389 - val_loss: 126.2110 - val_mae: 8.9746\n",
      "Epoch 96/1000\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 101.3548 - mae: 7.9705 - val_loss: 139.0374 - val_mae: 9.4928\n",
      "Epoch 97/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 102.7819 - mae: 7.9654 - val_loss: 152.7376 - val_mae: 9.9987\n",
      "Epoch 98/1000\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 103.2113 - mae: 8.1334 - val_loss: 130.1970 - val_mae: 9.1696\n",
      "Epoch 99/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 101.4726 - mae: 7.9324 - val_loss: 124.8879 - val_mae: 8.9257\n",
      "Epoch 100/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 101.8189 - mae: 7.9966 - val_loss: 127.5723 - val_mae: 9.0375\n",
      "Epoch 101/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 100.3148 - mae: 7.9451 - val_loss: 131.6212 - val_mae: 9.2492\n",
      "Epoch 102/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 101.7354 - mae: 7.9685 - val_loss: 121.1362 - val_mae: 8.8051\n",
      "Epoch 103/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 100.5472 - mae: 7.8886 - val_loss: 141.2014 - val_mae: 9.5601\n",
      "Epoch 104/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 102.3477 - mae: 7.9919 - val_loss: 125.5398 - val_mae: 9.0194\n",
      "Epoch 105/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 101.1538 - mae: 7.9114 - val_loss: 125.4757 - val_mae: 8.9512\n",
      "Epoch 106/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 98.6133 - mae: 7.8608 - val_loss: 147.0316 - val_mae: 9.7897\n",
      "Epoch 107/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 102.1906 - mae: 7.9796 - val_loss: 156.9547 - val_mae: 10.0590\n",
      "Epoch 108/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 102.0839 - mae: 7.9827 - val_loss: 134.5731 - val_mae: 9.2989\n",
      "Epoch 109/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 100.1807 - mae: 7.9087 - val_loss: 120.6648 - val_mae: 8.8218\n",
      "Epoch 110/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 100.5358 - mae: 7.8306 - val_loss: 145.2762 - val_mae: 9.6417\n",
      "Epoch 111/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 100.5647 - mae: 7.8892 - val_loss: 135.7294 - val_mae: 9.3332\n",
      "Epoch 112/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 101.3237 - mae: 7.9065 - val_loss: 118.5221 - val_mae: 8.7069\n",
      "Epoch 113/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 98.2295 - mae: 7.7618 - val_loss: 135.3262 - val_mae: 9.3491\n",
      "Epoch 114/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 0s 204us/sample - loss: 99.7841 - mae: 7.8433 - val_loss: 123.8750 - val_mae: 8.9353\n",
      "Epoch 115/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 99.2487 - mae: 7.8316 - val_loss: 126.4169 - val_mae: 8.9744\n",
      "Epoch 116/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 98.2500 - mae: 7.7003 - val_loss: 117.1513 - val_mae: 8.6350\n",
      "Epoch 117/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 99.4514 - mae: 7.7861 - val_loss: 117.0400 - val_mae: 8.6557\n",
      "Epoch 118/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 97.8874 - mae: 7.7859 - val_loss: 129.8819 - val_mae: 9.1844\n",
      "Epoch 119/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 97.9563 - mae: 7.7216 - val_loss: 116.4226 - val_mae: 8.6267\n",
      "Epoch 120/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 97.0285 - mae: 7.6701 - val_loss: 116.0083 - val_mae: 8.6059\n",
      "Epoch 121/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 100.1258 - mae: 7.8110 - val_loss: 115.9734 - val_mae: 8.6140\n",
      "Epoch 122/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 96.8727 - mae: 7.6229 - val_loss: 198.1244 - val_mae: 11.4647\n",
      "Epoch 123/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 102.4151 - mae: 7.8917 - val_loss: 134.9877 - val_mae: 9.2525\n",
      "Epoch 124/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 98.5133 - mae: 7.8165 - val_loss: 114.9519 - val_mae: 8.5737\n",
      "Epoch 125/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 96.4903 - mae: 7.7051 - val_loss: 114.7627 - val_mae: 8.5472\n",
      "Epoch 126/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 100.5946 - mae: 7.8049 - val_loss: 140.6782 - val_mae: 9.4594\n",
      "Epoch 127/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 97.8021 - mae: 7.7679 - val_loss: 114.2688 - val_mae: 8.5410\n",
      "Epoch 128/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 95.7250 - mae: 7.6201 - val_loss: 113.6426 - val_mae: 8.5146\n",
      "Epoch 129/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 97.3264 - mae: 7.7233 - val_loss: 116.4413 - val_mae: 8.6107\n",
      "Epoch 130/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 96.6183 - mae: 7.6674 - val_loss: 131.6919 - val_mae: 9.1326\n",
      "Epoch 131/1000\n",
      "515/515 [==============================] - 0s 186us/sample - loss: 95.7950 - mae: 7.7321 - val_loss: 136.9584 - val_mae: 9.3189\n",
      "Epoch 132/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 97.5983 - mae: 7.5996 - val_loss: 113.3461 - val_mae: 8.5012\n",
      "Epoch 133/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 96.0062 - mae: 7.5976 - val_loss: 111.0241 - val_mae: 8.4004\n",
      "Epoch 134/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 93.8729 - mae: 7.5367 - val_loss: 158.2108 - val_mae: 10.1335\n",
      "Epoch 135/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 95.3084 - mae: 7.6575 - val_loss: 134.4381 - val_mae: 9.3745\n",
      "Epoch 136/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 97.0218 - mae: 7.6108 - val_loss: 111.2176 - val_mae: 8.4039\n",
      "Epoch 137/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 94.0157 - mae: 7.5763 - val_loss: 153.3873 - val_mae: 10.0809\n",
      "Epoch 138/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 98.1965 - mae: 7.6762 - val_loss: 111.9957 - val_mae: 8.4373\n",
      "Epoch 139/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 92.2425 - mae: 7.4396 - val_loss: 118.8240 - val_mae: 8.7394\n",
      "Epoch 140/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 93.5656 - mae: 7.4380 - val_loss: 110.1121 - val_mae: 8.3605\n",
      "Epoch 141/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 94.3450 - mae: 7.5000 - val_loss: 133.0654 - val_mae: 9.3391\n",
      "Epoch 142/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 95.4938 - mae: 7.5896 - val_loss: 116.8524 - val_mae: 8.6668\n",
      "Epoch 143/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 93.0090 - mae: 7.4300 - val_loss: 147.3023 - val_mae: 9.7119\n",
      "Epoch 144/1000\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 92.3126 - mae: 7.5011 - val_loss: 114.8591 - val_mae: 8.5746\n",
      "Epoch 145/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 93.2595 - mae: 7.4884 - val_loss: 106.8717 - val_mae: 8.2055\n",
      "Epoch 146/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 90.5528 - mae: 7.3545 - val_loss: 118.3588 - val_mae: 8.6560\n",
      "Epoch 147/1000\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 91.7575 - mae: 7.3835 - val_loss: 106.7674 - val_mae: 8.1725\n",
      "Epoch 148/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 90.6275 - mae: 7.3475 - val_loss: 109.9093 - val_mae: 8.3288\n",
      "Epoch 149/1000\n",
      "515/515 [==============================] - 0s 205us/sample - loss: 90.0906 - mae: 7.3584 - val_loss: 107.0218 - val_mae: 8.2072\n",
      "Epoch 150/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 89.5517 - mae: 7.3096 - val_loss: 129.9117 - val_mae: 9.1044\n",
      "Epoch 151/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 90.3758 - mae: 7.4108 - val_loss: 118.3091 - val_mae: 8.7262\n",
      "Epoch 152/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 90.4062 - mae: 7.3241 - val_loss: 118.2288 - val_mae: 8.6944\n",
      "Epoch 153/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 88.5982 - mae: 7.2409 - val_loss: 114.8665 - val_mae: 8.6099\n",
      "Epoch 154/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 88.9167 - mae: 7.2312 - val_loss: 175.4982 - val_mae: 10.8148\n",
      "Epoch 155/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 90.3322 - mae: 7.3851 - val_loss: 130.1238 - val_mae: 9.1011\n",
      "Epoch 156/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 86.8426 - mae: 7.2804 - val_loss: 104.7899 - val_mae: 8.1144\n",
      "Epoch 157/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 86.8536 - mae: 7.2137 - val_loss: 103.7208 - val_mae: 8.1009\n",
      "Epoch 158/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 84.9388 - mae: 7.0627 - val_loss: 107.9181 - val_mae: 8.3348\n",
      "Epoch 159/1000\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 85.5632 - mae: 7.1646 - val_loss: 127.6752 - val_mae: 9.0020\n",
      "Epoch 160/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 86.9936 - mae: 7.2228 - val_loss: 131.2656 - val_mae: 9.1200\n",
      "Epoch 161/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 84.9351 - mae: 7.1601 - val_loss: 136.9038 - val_mae: 9.3682\n",
      "Epoch 162/1000\n",
      "515/515 [==============================] - 0s 187us/sample - loss: 86.1978 - mae: 7.2287 - val_loss: 110.0796 - val_mae: 8.3810\n",
      "Epoch 163/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 84.3192 - mae: 7.0450 - val_loss: 110.4917 - val_mae: 8.4120\n",
      "Epoch 164/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 81.8256 - mae: 6.9455 - val_loss: 120.6663 - val_mae: 8.7227\n",
      "Epoch 165/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 81.8677 - mae: 7.0133 - val_loss: 125.4763 - val_mae: 9.0373\n",
      "Epoch 166/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 84.2566 - mae: 7.0229 - val_loss: 104.4773 - val_mae: 8.1413\n",
      "Epoch 167/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 80.4299 - mae: 6.8833 - val_loss: 97.3869 - val_mae: 7.8179\n",
      "Epoch 168/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 83.2295 - mae: 7.0147 - val_loss: 98.7120 - val_mae: 7.8167\n",
      "Epoch 169/1000\n",
      "515/515 [==============================] - 0s 197us/sample - loss: 81.2517 - mae: 6.9706 - val_loss: 126.5097 - val_mae: 8.9261\n",
      "Epoch 170/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 81.9814 - mae: 6.9163 - val_loss: 126.1204 - val_mae: 8.8693\n",
      "Epoch 171/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 81.7830 - mae: 6.9672 - val_loss: 106.9270 - val_mae: 8.1350\n",
      "Epoch 172/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 79.8203 - mae: 6.8735 - val_loss: 93.0170 - val_mae: 7.6480\n",
      "Epoch 173/1000\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 78.9396 - mae: 6.8397 - val_loss: 105.4583 - val_mae: 8.2470\n",
      "Epoch 174/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 78.7732 - mae: 6.8154 - val_loss: 103.4712 - val_mae: 8.1882\n",
      "Epoch 175/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 78.7387 - mae: 6.8025 - val_loss: 113.2049 - val_mae: 8.6516\n",
      "Epoch 176/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 77.6179 - mae: 6.7625 - val_loss: 122.2809 - val_mae: 8.6803\n",
      "Epoch 177/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 78.2901 - mae: 6.7964 - val_loss: 155.6265 - val_mae: 9.9763\n",
      "Epoch 178/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 80.7023 - mae: 6.9271 - val_loss: 96.9498 - val_mae: 7.6664\n",
      "Epoch 179/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 76.4230 - mae: 6.6831 - val_loss: 91.2589 - val_mae: 7.5935\n",
      "Epoch 180/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 76.6046 - mae: 6.6848 - val_loss: 96.9997 - val_mae: 7.6983\n",
      "Epoch 181/1000\n",
      "515/515 [==============================] - 0s 197us/sample - loss: 76.2595 - mae: 6.7009 - val_loss: 92.8476 - val_mae: 7.5212\n",
      "Epoch 182/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 72.4738 - mae: 6.5128 - val_loss: 89.2094 - val_mae: 7.4997\n",
      "Epoch 183/1000\n",
      "515/515 [==============================] - 0s 211us/sample - loss: 74.4790 - mae: 6.6692 - val_loss: 106.6910 - val_mae: 8.3939\n",
      "Epoch 184/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 74.8418 - mae: 6.6176 - val_loss: 101.0547 - val_mae: 7.8235\n",
      "Epoch 185/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 73.6069 - mae: 6.4852 - val_loss: 87.7328 - val_mae: 7.2743\n",
      "Epoch 186/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 72.3936 - mae: 6.4772 - val_loss: 139.1187 - val_mae: 9.7140\n",
      "Epoch 187/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 74.4376 - mae: 6.5910 - val_loss: 98.6698 - val_mae: 7.7208\n",
      "Epoch 188/1000\n",
      "515/515 [==============================] - 0s 193us/sample - loss: 73.2594 - mae: 6.5352 - val_loss: 95.4753 - val_mae: 7.5575\n",
      "Epoch 189/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 73.0250 - mae: 6.5575 - val_loss: 82.6288 - val_mae: 7.1294\n",
      "Epoch 190/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 72.0935 - mae: 6.5558 - val_loss: 131.8547 - val_mae: 9.0900\n",
      "Epoch 191/1000\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 71.6746 - mae: 6.5435 - val_loss: 121.9612 - val_mae: 9.1160\n",
      "Epoch 192/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 73.7742 - mae: 6.5825 - val_loss: 119.5713 - val_mae: 8.5968\n",
      "Epoch 193/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 71.5091 - mae: 6.4659 - val_loss: 85.9223 - val_mae: 7.4232\n",
      "Epoch 194/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 70.5252 - mae: 6.4411 - val_loss: 82.1097 - val_mae: 7.0595\n",
      "Epoch 195/1000\n",
      "515/515 [==============================] - 0s 189us/sample - loss: 67.8435 - mae: 6.2528 - val_loss: 88.7560 - val_mae: 7.5925\n",
      "Epoch 196/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 69.7355 - mae: 6.3509 - val_loss: 90.1749 - val_mae: 7.3337\n",
      "Epoch 197/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 67.7659 - mae: 6.3059 - val_loss: 82.2244 - val_mae: 6.9761\n",
      "Epoch 198/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 69.5226 - mae: 6.2963 - val_loss: 81.4029 - val_mae: 7.1848\n",
      "Epoch 199/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 70.0160 - mae: 6.3972 - val_loss: 77.1401 - val_mae: 6.8715\n",
      "Epoch 200/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 68.6828 - mae: 6.2863 - val_loss: 160.3749 - val_mae: 10.2640\n",
      "Epoch 201/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 69.8833 - mae: 6.3691 - val_loss: 82.3619 - val_mae: 6.9236\n",
      "Epoch 202/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 69.6831 - mae: 6.3044 - val_loss: 79.8556 - val_mae: 7.1413\n",
      "Epoch 203/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 67.1150 - mae: 6.2424 - val_loss: 78.6445 - val_mae: 7.0590\n",
      "Epoch 204/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 68.4339 - mae: 6.2698 - val_loss: 75.9143 - val_mae: 6.7800\n",
      "Epoch 205/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 67.7913 - mae: 6.3411 - val_loss: 82.3319 - val_mae: 6.9099\n",
      "Epoch 206/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 66.5887 - mae: 6.1834 - val_loss: 77.9686 - val_mae: 6.7265\n",
      "Epoch 207/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 66.1104 - mae: 6.1580 - val_loss: 164.6503 - val_mae: 10.5451\n",
      "Epoch 208/1000\n",
      "515/515 [==============================] - 0s 186us/sample - loss: 70.6257 - mae: 6.4921 - val_loss: 96.0587 - val_mae: 7.5760\n",
      "Epoch 209/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 67.7696 - mae: 6.3298 - val_loss: 75.3639 - val_mae: 6.8733\n",
      "Epoch 210/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 65.3591 - mae: 6.1339 - val_loss: 86.0350 - val_mae: 7.1153\n",
      "Epoch 211/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 66.9081 - mae: 6.2327 - val_loss: 103.3125 - val_mae: 8.4290\n",
      "Epoch 212/1000\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 63.9737 - mae: 6.0809 - val_loss: 86.8981 - val_mae: 7.0511\n",
      "Epoch 213/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 66.4400 - mae: 6.2480 - val_loss: 89.7813 - val_mae: 7.1776\n",
      "Epoch 214/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 64.2456 - mae: 6.0376 - val_loss: 118.4635 - val_mae: 9.0815\n",
      "Epoch 215/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 66.8790 - mae: 6.1707 - val_loss: 76.7546 - val_mae: 7.0205\n",
      "Epoch 216/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 62.8581 - mae: 6.0335 - val_loss: 144.6189 - val_mae: 10.0405\n",
      "Epoch 217/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 67.7961 - mae: 6.2591 - val_loss: 76.9711 - val_mae: 7.0191\n",
      "Epoch 218/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 64.3604 - mae: 6.0842 - val_loss: 101.9018 - val_mae: 8.3112\n",
      "Epoch 219/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 63.4028 - mae: 6.0485 - val_loss: 96.7091 - val_mae: 8.0811\n",
      "Epoch 220/1000\n",
      "515/515 [==============================] - 0s 216us/sample - loss: 64.9483 - mae: 6.1321 - val_loss: 74.5067 - val_mae: 6.8525\n",
      "Epoch 221/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 62.4954 - mae: 6.0359 - val_loss: 91.7169 - val_mae: 7.4015\n",
      "Epoch 222/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 67.0354 - mae: 6.2158 - val_loss: 95.4145 - val_mae: 8.0195\n",
      "Epoch 223/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 62.1238 - mae: 5.9181 - val_loss: 72.7885 - val_mae: 6.6482\n",
      "Epoch 224/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 62.3303 - mae: 5.9127 - val_loss: 94.0117 - val_mae: 7.4174\n",
      "Epoch 225/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 64.3999 - mae: 6.1353 - val_loss: 75.9121 - val_mae: 6.6823\n",
      "Epoch 226/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 63.9966 - mae: 6.1138 - val_loss: 68.4376 - val_mae: 6.3723\n",
      "Epoch 227/1000\n",
      "515/515 [==============================] - 0s 203us/sample - loss: 62.7196 - mae: 5.9674 - val_loss: 86.4110 - val_mae: 7.5749\n",
      "Epoch 228/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 0s 192us/sample - loss: 59.5587 - mae: 5.8699 - val_loss: 102.4436 - val_mae: 7.8344\n",
      "Epoch 229/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 64.2531 - mae: 6.0610 - val_loss: 82.9337 - val_mae: 7.4702\n",
      "Epoch 230/1000\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 61.1490 - mae: 6.0128 - val_loss: 111.8401 - val_mae: 8.3099\n",
      "Epoch 231/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 64.2186 - mae: 6.0919 - val_loss: 109.3883 - val_mae: 8.2983\n",
      "Epoch 232/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 60.6630 - mae: 5.9364 - val_loss: 71.2623 - val_mae: 6.4065\n",
      "Epoch 233/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 61.6416 - mae: 5.8726 - val_loss: 106.5361 - val_mae: 8.1296\n",
      "Epoch 234/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 61.1274 - mae: 5.9006 - val_loss: 111.0481 - val_mae: 8.2046\n",
      "Epoch 235/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 63.4508 - mae: 6.0294 - val_loss: 70.5948 - val_mae: 6.7076\n",
      "Epoch 236/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 62.1608 - mae: 5.9941 - val_loss: 79.2110 - val_mae: 6.7546\n",
      "Epoch 237/1000\n",
      "515/515 [==============================] - 0s 191us/sample - loss: 60.2587 - mae: 5.8443 - val_loss: 77.2263 - val_mae: 6.9983\n",
      "Epoch 238/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 60.4891 - mae: 5.8915 - val_loss: 78.1936 - val_mae: 6.7532\n",
      "Epoch 239/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 62.9491 - mae: 6.0316 - val_loss: 65.6343 - val_mae: 6.1351\n",
      "Epoch 240/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 60.9098 - mae: 5.8489 - val_loss: 91.3787 - val_mae: 7.2890\n",
      "Epoch 241/1000\n",
      "515/515 [==============================] - 0s 186us/sample - loss: 59.2534 - mae: 5.8168 - val_loss: 86.0724 - val_mae: 7.0041\n",
      "Epoch 242/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 59.2198 - mae: 5.8159 - val_loss: 66.2590 - val_mae: 6.3153\n",
      "Epoch 243/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 59.5482 - mae: 5.8251 - val_loss: 66.7914 - val_mae: 6.3853\n",
      "Epoch 244/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 60.9329 - mae: 5.9168 - val_loss: 91.6946 - val_mae: 7.9840\n",
      "Epoch 245/1000\n",
      "515/515 [==============================] - 0s 191us/sample - loss: 58.8234 - mae: 5.8975 - val_loss: 72.0336 - val_mae: 6.3663\n",
      "Epoch 246/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 57.2474 - mae: 5.6500 - val_loss: 89.6469 - val_mae: 7.9233\n",
      "Epoch 247/1000\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 60.2725 - mae: 5.8874 - val_loss: 168.4251 - val_mae: 10.9705\n",
      "Epoch 248/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 62.8443 - mae: 5.9365 - val_loss: 98.3808 - val_mae: 7.7714\n",
      "Epoch 249/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 56.7996 - mae: 5.8023 - val_loss: 76.3624 - val_mae: 7.1477\n",
      "Epoch 250/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 60.7829 - mae: 5.9459 - val_loss: 63.8025 - val_mae: 5.9830\n",
      "Epoch 251/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 54.8848 - mae: 5.6215 - val_loss: 192.7223 - val_mae: 11.8518\n",
      "Epoch 252/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 64.7289 - mae: 6.1055 - val_loss: 75.1958 - val_mae: 7.0314\n",
      "Epoch 253/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 56.2778 - mae: 5.5933 - val_loss: 66.8147 - val_mae: 6.5326\n",
      "Epoch 254/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 57.1156 - mae: 5.7231 - val_loss: 62.8744 - val_mae: 6.1710\n",
      "Epoch 255/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 57.1849 - mae: 5.8075 - val_loss: 64.0666 - val_mae: 5.9715\n",
      "Epoch 256/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 57.1399 - mae: 5.7200 - val_loss: 65.2727 - val_mae: 6.4031\n",
      "Epoch 257/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 55.0429 - mae: 5.5727 - val_loss: 131.9881 - val_mae: 9.3738\n",
      "Epoch 258/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 60.5372 - mae: 5.8855 - val_loss: 61.2687 - val_mae: 5.8831\n",
      "Epoch 259/1000\n",
      "515/515 [==============================] - 0s 226us/sample - loss: 58.3226 - mae: 5.7737 - val_loss: 64.7844 - val_mae: 5.9756\n",
      "Epoch 260/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 58.1872 - mae: 5.7437 - val_loss: 60.3106 - val_mae: 5.9891\n",
      "Epoch 261/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 56.7750 - mae: 5.6773 - val_loss: 63.4981 - val_mae: 6.1256\n",
      "Epoch 262/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 57.8955 - mae: 5.7520 - val_loss: 150.0045 - val_mae: 10.1687\n",
      "Epoch 263/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 57.9841 - mae: 5.7362 - val_loss: 67.2792 - val_mae: 6.0216\n",
      "Epoch 264/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 55.5826 - mae: 5.7012 - val_loss: 115.3051 - val_mae: 8.5774\n",
      "Epoch 265/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 58.2557 - mae: 5.7416 - val_loss: 80.8831 - val_mae: 6.8509\n",
      "Epoch 266/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 57.6629 - mae: 5.8341 - val_loss: 79.6794 - val_mae: 7.3902\n",
      "Epoch 267/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 54.8506 - mae: 5.5616 - val_loss: 63.2098 - val_mae: 5.9241\n",
      "Epoch 268/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 55.3103 - mae: 5.6517 - val_loss: 62.7769 - val_mae: 6.2906\n",
      "Epoch 269/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 55.4836 - mae: 5.6437 - val_loss: 69.5362 - val_mae: 6.6782\n",
      "Epoch 270/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 56.9317 - mae: 5.7609 - val_loss: 95.1276 - val_mae: 8.0815\n",
      "Epoch 271/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 55.9366 - mae: 5.5670 - val_loss: 92.9304 - val_mae: 8.0212\n",
      "Epoch 272/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 53.8127 - mae: 5.4976 - val_loss: 60.2055 - val_mae: 6.0157\n",
      "Epoch 273/1000\n",
      "515/515 [==============================] - 0s 197us/sample - loss: 54.0231 - mae: 5.5999 - val_loss: 97.3335 - val_mae: 8.2658\n",
      "Epoch 274/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 56.3665 - mae: 5.6467 - val_loss: 118.8709 - val_mae: 9.1809\n",
      "Epoch 275/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 57.3252 - mae: 5.6809 - val_loss: 56.7164 - val_mae: 5.6526\n",
      "Epoch 276/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 56.4624 - mae: 5.7097 - val_loss: 94.6948 - val_mae: 8.1873\n",
      "Epoch 277/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 54.7522 - mae: 5.6674 - val_loss: 69.3902 - val_mae: 6.7040\n",
      "Epoch 278/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 53.9827 - mae: 5.5813 - val_loss: 59.0594 - val_mae: 5.7290\n",
      "Epoch 279/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 55.1735 - mae: 5.6186 - val_loss: 60.9998 - val_mae: 5.8032\n",
      "Epoch 280/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 51.6074 - mae: 5.3948 - val_loss: 97.5537 - val_mae: 7.5944\n",
      "Epoch 281/1000\n",
      "515/515 [==============================] - 0s 191us/sample - loss: 53.9092 - mae: 5.5490 - val_loss: 73.9446 - val_mae: 6.4672\n",
      "Epoch 282/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 56.8763 - mae: 5.7770 - val_loss: 119.1708 - val_mae: 8.8149\n",
      "Epoch 283/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 54.5036 - mae: 5.5766 - val_loss: 56.1634 - val_mae: 5.7616\n",
      "Epoch 284/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 50.3270 - mae: 5.2965 - val_loss: 61.5793 - val_mae: 5.8244\n",
      "Epoch 285/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 55.3032 - mae: 5.6912 - val_loss: 58.0768 - val_mae: 5.6215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 55.0486 - mae: 5.6292 - val_loss: 58.8273 - val_mae: 5.6020\n",
      "Epoch 287/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 52.6402 - mae: 5.4379 - val_loss: 62.8972 - val_mae: 5.9194\n",
      "Epoch 288/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 55.1471 - mae: 5.5599 - val_loss: 58.1943 - val_mae: 5.9329\n",
      "Epoch 289/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 53.2933 - mae: 5.4937 - val_loss: 63.9884 - val_mae: 5.8511\n",
      "Epoch 290/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 52.7118 - mae: 5.5605 - val_loss: 62.9710 - val_mae: 5.7961\n",
      "Epoch 291/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 55.8818 - mae: 5.6275 - val_loss: 77.5272 - val_mae: 7.2805\n",
      "Epoch 292/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 54.4662 - mae: 5.5843 - val_loss: 65.2042 - val_mae: 6.0735\n",
      "Epoch 293/1000\n",
      "515/515 [==============================] - 0s 195us/sample - loss: 50.2720 - mae: 5.3297 - val_loss: 57.0545 - val_mae: 5.6442\n",
      "Epoch 294/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 54.6386 - mae: 5.5740 - val_loss: 84.1883 - val_mae: 7.5333\n",
      "Epoch 295/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 53.3267 - mae: 5.5063 - val_loss: 60.5787 - val_mae: 6.1623\n",
      "Epoch 296/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 54.9688 - mae: 5.5461 - val_loss: 75.5871 - val_mae: 6.5121\n",
      "Epoch 297/1000\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 51.2720 - mae: 5.4612 - val_loss: 76.0394 - val_mae: 6.6384\n",
      "Epoch 298/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 50.4302 - mae: 5.3625 - val_loss: 56.7794 - val_mae: 5.8122\n",
      "Epoch 299/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 52.4303 - mae: 5.4952 - val_loss: 55.0300 - val_mae: 5.7032\n",
      "Epoch 300/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 54.9754 - mae: 5.5566 - val_loss: 80.8930 - val_mae: 7.3756\n",
      "Epoch 301/1000\n",
      "515/515 [==============================] - 0s 238us/sample - loss: 50.7377 - mae: 5.3740 - val_loss: 72.4196 - val_mae: 6.2909\n",
      "Epoch 302/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 54.9784 - mae: 5.6321 - val_loss: 88.6757 - val_mae: 7.2590\n",
      "Epoch 303/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 53.0610 - mae: 5.5445 - val_loss: 55.7516 - val_mae: 5.4809\n",
      "Epoch 304/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 52.5919 - mae: 5.5030 - val_loss: 122.9529 - val_mae: 9.1028\n",
      "Epoch 305/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 50.8183 - mae: 5.4049 - val_loss: 87.4127 - val_mae: 7.8956\n",
      "Epoch 306/1000\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 51.4386 - mae: 5.4286 - val_loss: 59.5997 - val_mae: 5.9997\n",
      "Epoch 307/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 50.7102 - mae: 5.4723 - val_loss: 89.9516 - val_mae: 8.0333\n",
      "Epoch 308/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 50.9243 - mae: 5.4505 - val_loss: 54.7396 - val_mae: 5.5375\n",
      "Epoch 309/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 47.4265 - mae: 5.2085 - val_loss: 54.7573 - val_mae: 5.5382\n",
      "Epoch 310/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 49.5578 - mae: 5.3809 - val_loss: 61.3944 - val_mae: 6.1902\n",
      "Epoch 311/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 51.1843 - mae: 5.3718 - val_loss: 58.7220 - val_mae: 5.8161\n",
      "Epoch 312/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 49.8196 - mae: 5.4495 - val_loss: 53.6165 - val_mae: 5.4657\n",
      "Epoch 313/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 51.5113 - mae: 5.3997 - val_loss: 63.2548 - val_mae: 6.4178\n",
      "Epoch 314/1000\n",
      "515/515 [==============================] - 0s 197us/sample - loss: 51.3488 - mae: 5.4561 - val_loss: 63.0178 - val_mae: 5.8478\n",
      "Epoch 315/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 49.3626 - mae: 5.3457 - val_loss: 112.8876 - val_mae: 8.6997\n",
      "Epoch 316/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 49.6766 - mae: 5.3181 - val_loss: 65.3778 - val_mae: 6.5920\n",
      "Epoch 317/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 50.4826 - mae: 5.4220 - val_loss: 73.1746 - val_mae: 6.5896\n",
      "Epoch 318/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 49.1753 - mae: 5.3205 - val_loss: 160.3443 - val_mae: 10.7612\n",
      "Epoch 319/1000\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 52.8498 - mae: 5.4625 - val_loss: 63.3613 - val_mae: 6.4927\n",
      "Epoch 320/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 51.1057 - mae: 5.5214 - val_loss: 65.6833 - val_mae: 5.9999\n",
      "Epoch 321/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 46.0526 - mae: 5.1727 - val_loss: 73.8607 - val_mae: 6.5099\n",
      "Epoch 322/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 50.1372 - mae: 5.3983 - val_loss: 56.2058 - val_mae: 5.7785\n",
      "Epoch 323/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 49.9355 - mae: 5.4627 - val_loss: 58.7585 - val_mae: 5.6129\n",
      "Epoch 324/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 46.8070 - mae: 5.1275 - val_loss: 59.3406 - val_mae: 6.1465\n",
      "Epoch 325/1000\n",
      "515/515 [==============================] - 0s 275us/sample - loss: 49.8761 - mae: 5.4057 - val_loss: 54.9177 - val_mae: 5.4227\n",
      "Epoch 326/1000\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 46.2717 - mae: 5.2163 - val_loss: 84.5236 - val_mae: 7.2421\n",
      "Epoch 327/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 48.1659 - mae: 5.3220 - val_loss: 77.1633 - val_mae: 7.1936\n",
      "Epoch 328/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 48.0981 - mae: 5.2310 - val_loss: 58.2598 - val_mae: 6.1591\n",
      "Epoch 329/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 45.2126 - mae: 5.0926 - val_loss: 53.6421 - val_mae: 5.4582\n",
      "Epoch 330/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 49.9302 - mae: 5.4970 - val_loss: 83.3765 - val_mae: 7.0678\n",
      "Epoch 331/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 48.7651 - mae: 5.2998 - val_loss: 175.0864 - val_mae: 11.2970\n",
      "Epoch 332/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 54.2120 - mae: 5.5364 - val_loss: 79.3024 - val_mae: 6.9622\n",
      "Epoch 333/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 45.5236 - mae: 5.0943 - val_loss: 53.8466 - val_mae: 5.3966\n",
      "Epoch 334/1000\n",
      "515/515 [==============================] - 0s 278us/sample - loss: 50.7112 - mae: 5.4130 - val_loss: 62.5600 - val_mae: 6.2729\n",
      "Epoch 335/1000\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 48.2784 - mae: 5.2810 - val_loss: 54.0474 - val_mae: 5.3375\n",
      "Epoch 336/1000\n",
      "515/515 [==============================] - 0s 255us/sample - loss: 48.6375 - mae: 5.3468 - val_loss: 102.8844 - val_mae: 8.5475\n",
      "Epoch 337/1000\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 47.3830 - mae: 5.2253 - val_loss: 54.5964 - val_mae: 5.5696\n",
      "Epoch 338/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 49.8988 - mae: 5.4010 - val_loss: 51.8870 - val_mae: 5.3965\n",
      "Epoch 339/1000\n",
      "515/515 [==============================] - 0s 244us/sample - loss: 45.4778 - mae: 5.1630 - val_loss: 76.6316 - val_mae: 6.9689\n",
      "Epoch 340/1000\n",
      "515/515 [==============================] - 0s 266us/sample - loss: 50.3311 - mae: 5.3283 - val_loss: 73.6287 - val_mae: 6.3644\n",
      "Epoch 341/1000\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 50.5755 - mae: 5.4234 - val_loss: 110.9887 - val_mae: 8.6272\n",
      "Epoch 342/1000\n",
      "515/515 [==============================] - 0s 279us/sample - loss: 49.8311 - mae: 5.2790 - val_loss: 58.2747 - val_mae: 6.0170\n",
      "Epoch 343/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 45.9758 - mae: 5.1421 - val_loss: 84.5674 - val_mae: 6.9994\n",
      "Epoch 344/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 45.8067 - mae: 5.2341 - val_loss: 55.4857 - val_mae: 5.4044\n",
      "Epoch 345/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 49.0554 - mae: 5.4014 - val_loss: 50.7520 - val_mae: 5.4125\n",
      "Epoch 346/1000\n",
      "515/515 [==============================] - 0s 236us/sample - loss: 44.9630 - mae: 5.0862 - val_loss: 51.1920 - val_mae: 5.2744\n",
      "Epoch 347/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 46.2474 - mae: 5.2132 - val_loss: 89.2616 - val_mae: 7.4989\n",
      "Epoch 348/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 49.6146 - mae: 5.3938 - val_loss: 91.3637 - val_mae: 7.6006\n",
      "Epoch 349/1000\n",
      "515/515 [==============================] - 0s 266us/sample - loss: 48.3084 - mae: 5.3385 - val_loss: 147.1099 - val_mae: 10.1723\n",
      "Epoch 350/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 50.0366 - mae: 5.2696 - val_loss: 53.7520 - val_mae: 5.5854\n",
      "Epoch 351/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 43.9137 - mae: 5.0230 - val_loss: 54.0195 - val_mae: 5.4635\n",
      "Epoch 352/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 48.9719 - mae: 5.2875 - val_loss: 161.3749 - val_mae: 10.9012\n",
      "Epoch 353/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 51.9220 - mae: 5.4452 - val_loss: 83.2334 - val_mae: 7.6541\n",
      "Epoch 354/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 46.4521 - mae: 5.1367 - val_loss: 50.7749 - val_mae: 5.4084\n",
      "Epoch 355/1000\n",
      "515/515 [==============================] - 0s 189us/sample - loss: 45.2985 - mae: 5.1453 - val_loss: 54.7930 - val_mae: 5.7827\n",
      "Epoch 356/1000\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 45.4234 - mae: 5.2069 - val_loss: 49.0578 - val_mae: 5.2812\n",
      "Epoch 357/1000\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 47.4723 - mae: 5.2839 - val_loss: 49.2153 - val_mae: 5.3581\n",
      "Epoch 358/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 44.7136 - mae: 5.0191 - val_loss: 81.5792 - val_mae: 6.9909\n",
      "Epoch 359/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 44.3275 - mae: 4.9819 - val_loss: 85.1348 - val_mae: 7.2433\n",
      "Epoch 360/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 47.2850 - mae: 5.2249 - val_loss: 56.1765 - val_mae: 6.0564\n",
      "Epoch 361/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 44.5130 - mae: 5.1284 - val_loss: 50.4482 - val_mae: 5.2465\n",
      "Epoch 362/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 49.3169 - mae: 5.3480 - val_loss: 50.3051 - val_mae: 5.2005\n",
      "Epoch 363/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 44.3844 - mae: 5.0911 - val_loss: 62.8210 - val_mae: 5.9204\n",
      "Epoch 364/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 45.5430 - mae: 5.1897 - val_loss: 58.2314 - val_mae: 5.4790\n",
      "Epoch 365/1000\n",
      "515/515 [==============================] - 0s 193us/sample - loss: 43.7211 - mae: 4.9948 - val_loss: 91.9717 - val_mae: 8.1163\n",
      "Epoch 366/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 46.9049 - mae: 5.2689 - val_loss: 84.5136 - val_mae: 7.2378\n",
      "Epoch 367/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 46.6623 - mae: 5.2488 - val_loss: 103.5140 - val_mae: 8.5402\n",
      "Epoch 368/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 45.4896 - mae: 5.0910 - val_loss: 58.1829 - val_mae: 5.5975\n",
      "Epoch 369/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 51.1904 - mae: 5.4562 - val_loss: 53.4276 - val_mae: 5.7801\n",
      "Epoch 370/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 43.0482 - mae: 4.9486 - val_loss: 67.3523 - val_mae: 6.8764\n",
      "Epoch 371/1000\n",
      "515/515 [==============================] - 0s 260us/sample - loss: 45.1252 - mae: 5.2478 - val_loss: 52.2814 - val_mae: 5.2248\n",
      "Epoch 372/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 44.6085 - mae: 5.0332 - val_loss: 58.2340 - val_mae: 6.0149\n",
      "Epoch 373/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 44.5764 - mae: 5.0231 - val_loss: 82.2487 - val_mae: 7.0744\n",
      "Epoch 374/1000\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 42.2406 - mae: 4.9089 - val_loss: 84.0971 - val_mae: 7.1685\n",
      "Epoch 375/1000\n",
      "515/515 [==============================] - 0s 329us/sample - loss: 50.3686 - mae: 5.3933 - val_loss: 48.7468 - val_mae: 5.1729\n",
      "Epoch 376/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 43.9161 - mae: 5.0910 - val_loss: 163.8063 - val_mae: 10.8678\n",
      "Epoch 377/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 50.8463 - mae: 5.3477 - val_loss: 69.7678 - val_mae: 6.9174\n",
      "Epoch 378/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 44.4903 - mae: 5.1400 - val_loss: 91.8187 - val_mae: 7.9125\n",
      "Epoch 379/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 45.7877 - mae: 5.1115 - val_loss: 54.5953 - val_mae: 5.8864\n",
      "Epoch 380/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 46.0190 - mae: 5.2372 - val_loss: 49.9084 - val_mae: 5.4525\n",
      "Epoch 381/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 44.3635 - mae: 5.0287 - val_loss: 47.8981 - val_mae: 5.2648\n",
      "Epoch 382/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 42.8009 - mae: 4.9541 - val_loss: 78.7951 - val_mae: 6.8434\n",
      "Epoch 383/1000\n",
      "515/515 [==============================] - 0s 189us/sample - loss: 44.6198 - mae: 5.1163 - val_loss: 53.5943 - val_mae: 5.8271\n",
      "Epoch 384/1000\n",
      "515/515 [==============================] - ETA: 0s - loss: 39.5486 - mae: 4.83 - 0s 270us/sample - loss: 44.9111 - mae: 5.0477 - val_loss: 88.4797 - val_mae: 7.3094\n",
      "Epoch 385/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 41.1090 - mae: 4.9048 - val_loss: 123.0286 - val_mae: 9.5387\n",
      "Epoch 386/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 47.2023 - mae: 5.1859 - val_loss: 80.9170 - val_mae: 7.5124\n",
      "Epoch 387/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 48.0338 - mae: 5.3856 - val_loss: 50.3993 - val_mae: 5.1418\n",
      "Epoch 388/1000\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 40.2112 - mae: 4.7719 - val_loss: 71.5078 - val_mae: 6.2046\n",
      "Epoch 389/1000\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 45.5295 - mae: 5.0808 - val_loss: 84.0098 - val_mae: 7.6522\n",
      "Epoch 390/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 44.1942 - mae: 5.0406 - val_loss: 47.8471 - val_mae: 5.2951\n",
      "Epoch 391/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 44.7909 - mae: 4.9560 - val_loss: 52.6151 - val_mae: 5.5841\n",
      "Epoch 392/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 44.2630 - mae: 5.0111 - val_loss: 91.1852 - val_mae: 7.4377\n",
      "Epoch 393/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 44.1240 - mae: 5.0214 - val_loss: 49.8365 - val_mae: 5.4381\n",
      "Epoch 394/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 43.1263 - mae: 5.0402 - val_loss: 51.5459 - val_mae: 5.1563\n",
      "Epoch 395/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 42.0970 - mae: 4.9367 - val_loss: 49.2058 - val_mae: 5.0786\n",
      "Epoch 396/1000\n",
      "515/515 [==============================] - 0s 331us/sample - loss: 40.3283 - mae: 4.9212 - val_loss: 59.7390 - val_mae: 6.1477\n",
      "Epoch 397/1000\n",
      "515/515 [==============================] - 0s 274us/sample - loss: 44.6795 - mae: 5.0540 - val_loss: 71.4205 - val_mae: 7.0679\n",
      "Epoch 398/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 40.6255 - mae: 4.8273 - val_loss: 51.3334 - val_mae: 5.2126\n",
      "Epoch 399/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 44.6351 - mae: 5.0820 - val_loss: 114.9244 - val_mae: 9.1417\n",
      "Epoch 400/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 0s 330us/sample - loss: 42.8199 - mae: 5.0054 - val_loss: 47.7032 - val_mae: 5.2097\n",
      "Epoch 401/1000\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 43.5481 - mae: 5.0340 - val_loss: 62.9081 - val_mae: 6.4798\n",
      "Epoch 402/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 44.0037 - mae: 5.0499 - val_loss: 60.1774 - val_mae: 6.2769\n",
      "Epoch 403/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 42.3196 - mae: 4.9307 - val_loss: 51.2323 - val_mae: 5.5458\n",
      "Epoch 404/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 41.5270 - mae: 4.9147 - val_loss: 49.0193 - val_mae: 5.5272\n",
      "Epoch 405/1000\n",
      "515/515 [==============================] - 0s 283us/sample - loss: 45.7527 - mae: 5.0503 - val_loss: 64.0877 - val_mae: 6.5533\n",
      "Epoch 406/1000\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 43.3457 - mae: 4.9095 - val_loss: 47.8325 - val_mae: 5.0849\n",
      "Epoch 407/1000\n",
      "515/515 [==============================] - 0s 277us/sample - loss: 44.2749 - mae: 5.0639 - val_loss: 77.1274 - val_mae: 6.6783\n",
      "Epoch 408/1000\n",
      "515/515 [==============================] - 0s 266us/sample - loss: 42.3519 - mae: 4.9298 - val_loss: 61.7498 - val_mae: 6.2675\n",
      "Epoch 409/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 43.0789 - mae: 5.0232 - val_loss: 84.6308 - val_mae: 7.6781\n",
      "Epoch 410/1000\n",
      "515/515 [==============================] - 0s 259us/sample - loss: 45.1160 - mae: 5.0743 - val_loss: 79.5352 - val_mae: 7.5588\n",
      "Epoch 411/1000\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 40.5742 - mae: 4.9120 - val_loss: 63.3795 - val_mae: 6.5994\n",
      "Epoch 412/1000\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 40.7086 - mae: 4.9445 - val_loss: 68.2089 - val_mae: 6.6884\n",
      "Epoch 413/1000\n",
      "515/515 [==============================] - 0s 249us/sample - loss: 39.9219 - mae: 4.7068 - val_loss: 52.4048 - val_mae: 5.3611\n",
      "Epoch 414/1000\n",
      "515/515 [==============================] - 0s 283us/sample - loss: 42.7563 - mae: 4.9371 - val_loss: 71.2039 - val_mae: 6.9487\n",
      "Epoch 415/1000\n",
      "515/515 [==============================] - 0s 278us/sample - loss: 43.1272 - mae: 4.9852 - val_loss: 58.5359 - val_mae: 6.0878\n",
      "Epoch 416/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 41.2997 - mae: 4.8958 - val_loss: 51.7244 - val_mae: 5.2580\n",
      "Epoch 417/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 41.2059 - mae: 4.8534 - val_loss: 56.2172 - val_mae: 5.3948\n",
      "Epoch 418/1000\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 46.8682 - mae: 5.0442 - val_loss: 50.1198 - val_mae: 5.5255\n",
      "Epoch 419/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 39.4298 - mae: 4.7413 - val_loss: 61.8071 - val_mae: 5.8774\n",
      "Epoch 420/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 42.2090 - mae: 4.8956 - val_loss: 56.6025 - val_mae: 6.1372\n",
      "Epoch 421/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 40.6043 - mae: 4.8877 - val_loss: 50.5354 - val_mae: 5.4003\n",
      "Epoch 422/1000\n",
      "515/515 [==============================] - 0s 285us/sample - loss: 41.2773 - mae: 4.8692 - val_loss: 53.4399 - val_mae: 5.2692\n",
      "Epoch 423/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 44.8466 - mae: 5.1222 - val_loss: 46.2127 - val_mae: 5.1169\n",
      "Epoch 424/1000\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 39.0602 - mae: 4.7701 - val_loss: 59.5148 - val_mae: 6.2853\n",
      "Epoch 425/1000\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 43.4126 - mae: 5.0247 - val_loss: 60.9899 - val_mae: 6.1842\n",
      "Epoch 426/1000\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 40.8978 - mae: 4.8524 - val_loss: 47.6248 - val_mae: 5.3740\n",
      "Epoch 427/1000\n",
      "515/515 [==============================] - 0s 263us/sample - loss: 39.8310 - mae: 4.7442 - val_loss: 56.9245 - val_mae: 6.1407\n",
      "Epoch 428/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 44.6290 - mae: 4.9784 - val_loss: 80.1969 - val_mae: 7.4626\n",
      "Epoch 429/1000\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 38.7482 - mae: 4.7564 - val_loss: 69.8750 - val_mae: 6.3173\n",
      "Epoch 430/1000\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 40.1464 - mae: 4.8616 - val_loss: 99.9849 - val_mae: 8.3640\n",
      "Epoch 431/1000\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 39.0854 - mae: 4.6858 - val_loss: 64.2198 - val_mae: 6.6554\n",
      "Epoch 432/1000\n",
      "515/515 [==============================] - 0s 260us/sample - loss: 43.3948 - mae: 5.1084 - val_loss: 50.6485 - val_mae: 5.0660\n",
      "Epoch 433/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 40.7291 - mae: 4.8056 - val_loss: 49.6878 - val_mae: 5.0175\n",
      "Epoch 434/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 42.0551 - mae: 4.9245 - val_loss: 64.2450 - val_mae: 6.6485\n",
      "Epoch 435/1000\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 41.0757 - mae: 4.7856 - val_loss: 113.9039 - val_mae: 9.0648\n",
      "Epoch 436/1000\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 40.0782 - mae: 4.8068 - val_loss: 51.1298 - val_mae: 5.7324\n",
      "Epoch 437/1000\n",
      "515/515 [==============================] - 0s 305us/sample - loss: 41.7308 - mae: 4.8998 - val_loss: 128.0733 - val_mae: 9.7990\n",
      "Epoch 438/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 42.7173 - mae: 4.9370 - val_loss: 105.2478 - val_mae: 8.5765\n",
      "Epoch 439/1000\n",
      "515/515 [==============================] - 0s 240us/sample - loss: 41.4150 - mae: 4.9188 - val_loss: 54.3777 - val_mae: 5.9802\n",
      "Epoch 440/1000\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 37.7648 - mae: 4.6655 - val_loss: 152.2969 - val_mae: 10.2435\n",
      "Epoch 441/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 45.2757 - mae: 4.9297 - val_loss: 128.0273 - val_mae: 9.8029\n",
      "Epoch 442/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 43.6128 - mae: 4.9073 - val_loss: 188.1163 - val_mae: 11.7179\n",
      "Epoch 443/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 46.4864 - mae: 4.9802 - val_loss: 66.0742 - val_mae: 6.6673\n",
      "Epoch 444/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 37.5027 - mae: 4.6943 - val_loss: 48.6312 - val_mae: 5.4674\n",
      "Epoch 445/1000\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 41.8526 - mae: 5.0408 - val_loss: 73.2239 - val_mae: 7.0111\n",
      "Epoch 446/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 39.4134 - mae: 4.6581 - val_loss: 78.0441 - val_mae: 7.4774\n",
      "Epoch 447/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 37.7302 - mae: 4.7009 - val_loss: 94.0900 - val_mae: 8.2721\n",
      "Epoch 448/1000\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 41.4378 - mae: 4.8556 - val_loss: 83.3564 - val_mae: 7.7435\n",
      "Epoch 449/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 40.1489 - mae: 4.7889 - val_loss: 49.5914 - val_mae: 5.1479\n",
      "Epoch 450/1000\n",
      "515/515 [==============================] - 0s 234us/sample - loss: 39.6592 - mae: 4.7633 - val_loss: 66.7300 - val_mae: 6.7866\n",
      "Epoch 451/1000\n",
      "515/515 [==============================] - 0s 260us/sample - loss: 43.1370 - mae: 4.9836 - val_loss: 46.3527 - val_mae: 4.9986\n",
      "Epoch 452/1000\n",
      "515/515 [==============================] - 0s 272us/sample - loss: 39.7377 - mae: 4.8737 - val_loss: 48.8243 - val_mae: 5.0632\n",
      "Epoch 453/1000\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 37.0445 - mae: 4.5617 - val_loss: 55.4970 - val_mae: 5.5952\n",
      "Epoch 454/1000\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 37.2689 - mae: 4.5886 - val_loss: 65.1679 - val_mae: 6.6726\n",
      "Epoch 455/1000\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 39.6291 - mae: 4.7852 - val_loss: 57.5690 - val_mae: 5.4335\n",
      "Epoch 456/1000\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 40.2825 - mae: 4.7869 - val_loss: 54.2789 - val_mae: 5.9948\n",
      "Epoch 457/1000\n",
      "515/515 [==============================] - 0s 247us/sample - loss: 39.8177 - mae: 4.7840 - val_loss: 46.1299 - val_mae: 5.1729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 38.1694 - mae: 4.6586 - val_loss: 45.5611 - val_mae: 5.1207\n",
      "Epoch 459/1000\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 41.6866 - mae: 4.9452 - val_loss: 48.7298 - val_mae: 5.0366\n",
      "Epoch 460/1000\n",
      "515/515 [==============================] - 0s 271us/sample - loss: 37.9791 - mae: 4.6276 - val_loss: 50.0581 - val_mae: 5.6043\n",
      "Epoch 461/1000\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 38.1363 - mae: 4.7124 - val_loss: 49.8125 - val_mae: 5.4625\n",
      "Epoch 462/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 39.0733 - mae: 4.8210 - val_loss: 63.8375 - val_mae: 6.5449\n",
      "Epoch 463/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 38.2355 - mae: 4.6564 - val_loss: 48.9820 - val_mae: 5.3262\n",
      "Epoch 464/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 40.7994 - mae: 4.8261 - val_loss: 57.6227 - val_mae: 5.4225\n",
      "Epoch 465/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 37.8738 - mae: 4.6010 - val_loss: 52.5497 - val_mae: 5.1666\n",
      "Epoch 466/1000\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 42.4786 - mae: 5.0099 - val_loss: 57.0072 - val_mae: 6.1547\n",
      "Epoch 467/1000\n",
      "515/515 [==============================] - 0s 299us/sample - loss: 37.1975 - mae: 4.6141 - val_loss: 81.9656 - val_mae: 7.6335\n",
      "Epoch 468/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 41.0653 - mae: 4.8383 - val_loss: 46.1405 - val_mae: 5.1332\n",
      "Epoch 469/1000\n",
      "515/515 [==============================] - 0s 260us/sample - loss: 40.8897 - mae: 4.8888 - val_loss: 95.7426 - val_mae: 8.0645\n",
      "Epoch 470/1000\n",
      "515/515 [==============================] - 0s 228us/sample - loss: 40.1007 - mae: 4.7228 - val_loss: 54.5541 - val_mae: 5.8089\n",
      "Epoch 471/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 37.1196 - mae: 4.6386 - val_loss: 57.7277 - val_mae: 6.0771\n",
      "Epoch 472/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 39.2086 - mae: 4.7160 - val_loss: 160.2521 - val_mae: 10.6959\n",
      "Epoch 473/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 40.8719 - mae: 4.7449 - val_loss: 99.7212 - val_mae: 8.5293\n",
      "Epoch 474/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 40.8205 - mae: 4.8391 - val_loss: 62.6567 - val_mae: 5.8111\n",
      "Epoch 475/1000\n",
      "515/515 [==============================] - 0s 278us/sample - loss: 36.9726 - mae: 4.5363 - val_loss: 80.5411 - val_mae: 7.5525\n",
      "Epoch 476/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 37.1104 - mae: 4.5388 - val_loss: 107.5536 - val_mae: 8.6041\n",
      "Epoch 477/1000\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 40.9516 - mae: 4.7971 - val_loss: 52.2671 - val_mae: 5.1341\n",
      "Epoch 478/1000\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 35.7010 - mae: 4.4816 - val_loss: 52.5826 - val_mae: 5.0514\n",
      "Epoch 479/1000\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 40.9408 - mae: 4.8627 - val_loss: 65.1858 - val_mae: 5.9340\n",
      "Epoch 480/1000\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 37.6789 - mae: 4.6386 - val_loss: 87.5325 - val_mae: 7.3729\n",
      "Epoch 481/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 36.8135 - mae: 4.5409 - val_loss: 44.2704 - val_mae: 4.9501\n",
      "Epoch 482/1000\n",
      "515/515 [==============================] - 0s 293us/sample - loss: 38.1577 - mae: 4.7149 - val_loss: 48.4846 - val_mae: 5.0624\n",
      "Epoch 483/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 35.2286 - mae: 4.4482 - val_loss: 56.3992 - val_mae: 5.4480\n",
      "Epoch 484/1000\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 39.5720 - mae: 4.8293 - val_loss: 79.6942 - val_mae: 6.9763\n",
      "Epoch 485/1000\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 38.6066 - mae: 4.6768 - val_loss: 54.4994 - val_mae: 5.9528\n",
      "Epoch 486/1000\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 40.1976 - mae: 4.9239 - val_loss: 49.1644 - val_mae: 5.2835\n",
      "Epoch 487/1000\n",
      "515/515 [==============================] - 0s 266us/sample - loss: 36.6573 - mae: 4.6592 - val_loss: 56.6908 - val_mae: 5.9030\n",
      "Epoch 488/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 37.6093 - mae: 4.6353 - val_loss: 45.7531 - val_mae: 5.1978\n",
      "Epoch 489/1000\n",
      "515/515 [==============================] - 0s 309us/sample - loss: 40.5244 - mae: 4.7875 - val_loss: 74.4109 - val_mae: 7.2843\n",
      "Epoch 490/1000\n",
      "515/515 [==============================] - 0s 287us/sample - loss: 36.2124 - mae: 4.5654 - val_loss: 57.8302 - val_mae: 5.6001\n",
      "Epoch 491/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 38.3470 - mae: 4.6804 - val_loss: 103.0792 - val_mae: 8.2151\n",
      "Epoch 492/1000\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 40.0920 - mae: 4.7781 - val_loss: 48.2657 - val_mae: 5.3445\n",
      "Epoch 493/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 33.7345 - mae: 4.3838 - val_loss: 53.6148 - val_mae: 5.4785\n",
      "Epoch 494/1000\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 40.5188 - mae: 4.8919 - val_loss: 52.2998 - val_mae: 5.2936\n",
      "Epoch 495/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 38.1845 - mae: 4.5926 - val_loss: 91.1555 - val_mae: 7.9574\n",
      "Epoch 496/1000\n",
      "515/515 [==============================] - 0s 299us/sample - loss: 38.6763 - mae: 4.5966 - val_loss: 60.6067 - val_mae: 6.3368\n",
      "Epoch 497/1000\n",
      "515/515 [==============================] - 0s 279us/sample - loss: 39.0274 - mae: 4.7050 - val_loss: 47.3910 - val_mae: 4.8310\n",
      "Epoch 498/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 36.0667 - mae: 4.4865 - val_loss: 95.0758 - val_mae: 7.8703\n",
      "Epoch 499/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 39.9620 - mae: 4.8327 - val_loss: 93.7563 - val_mae: 7.8612\n",
      "Epoch 500/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 35.6802 - mae: 4.5364 - val_loss: 83.8472 - val_mae: 7.6350\n",
      "Epoch 501/1000\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 37.5389 - mae: 4.6377 - val_loss: 53.6759 - val_mae: 5.4352\n",
      "Epoch 502/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 39.3616 - mae: 4.7746 - val_loss: 111.6903 - val_mae: 8.8032\n",
      "Epoch 503/1000\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 39.7267 - mae: 4.6828 - val_loss: 65.9947 - val_mae: 6.2195\n",
      "Epoch 504/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 38.6707 - mae: 4.6460 - val_loss: 48.0879 - val_mae: 4.9230\n",
      "Epoch 505/1000\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 37.3035 - mae: 4.5768 - val_loss: 91.9705 - val_mae: 7.9409\n",
      "Epoch 506/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 36.1886 - mae: 4.5600 - val_loss: 83.9156 - val_mae: 6.9949\n",
      "Epoch 507/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 38.4069 - mae: 4.6546 - val_loss: 43.6404 - val_mae: 4.8536\n",
      "Epoch 508/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 38.0790 - mae: 4.7630 - val_loss: 51.4889 - val_mae: 5.2351\n",
      "Epoch 509/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 35.3448 - mae: 4.4763 - val_loss: 59.5452 - val_mae: 6.2500\n",
      "Epoch 510/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 37.8494 - mae: 4.6078 - val_loss: 49.6327 - val_mae: 5.5728\n",
      "Epoch 511/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 37.3237 - mae: 4.6555 - val_loss: 44.7576 - val_mae: 5.1356\n",
      "Epoch 512/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 34.9654 - mae: 4.4424 - val_loss: 74.6201 - val_mae: 7.2007\n",
      "Epoch 513/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 39.1684 - mae: 4.6486 - val_loss: 43.9978 - val_mae: 4.8196\n",
      "Epoch 514/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 37.2408 - mae: 4.5277 - val_loss: 55.2666 - val_mae: 5.3834\n",
      "Epoch 515/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 35.6279 - mae: 4.5191 - val_loss: 57.4517 - val_mae: 5.6956\n",
      "Epoch 516/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 37.0984 - mae: 4.5781 - val_loss: 46.9911 - val_mae: 4.8804\n",
      "Epoch 517/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 34.3626 - mae: 4.4603 - val_loss: 98.7679 - val_mae: 7.9582\n",
      "Epoch 518/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 39.3525 - mae: 4.7692 - val_loss: 49.2962 - val_mae: 4.9775\n",
      "Epoch 519/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 36.1594 - mae: 4.6195 - val_loss: 46.8598 - val_mae: 5.3470\n",
      "Epoch 520/1000\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 37.7936 - mae: 4.6613 - val_loss: 90.8229 - val_mae: 7.3592\n",
      "Epoch 521/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 34.9582 - mae: 4.4981 - val_loss: 46.0801 - val_mae: 4.8596\n",
      "Epoch 522/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 36.7929 - mae: 4.5223 - val_loss: 57.8813 - val_mae: 6.1837\n",
      "Epoch 523/1000\n",
      "515/515 [==============================] - 0s 203us/sample - loss: 36.3648 - mae: 4.5373 - val_loss: 50.0847 - val_mae: 5.0247\n",
      "Epoch 524/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 37.0548 - mae: 4.5969 - val_loss: 59.2610 - val_mae: 6.2228\n",
      "Epoch 525/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 34.1614 - mae: 4.3714 - val_loss: 136.8693 - val_mae: 9.5323\n",
      "Epoch 526/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 39.0785 - mae: 4.6368 - val_loss: 47.1890 - val_mae: 4.8915\n",
      "Epoch 527/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 40.0075 - mae: 4.7802 - val_loss: 126.5288 - val_mae: 9.2151\n",
      "Epoch 528/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 38.8205 - mae: 4.7075 - val_loss: 52.0631 - val_mae: 5.1478\n",
      "Epoch 529/1000\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 39.7346 - mae: 4.7724 - val_loss: 45.2452 - val_mae: 4.9284\n",
      "Epoch 530/1000\n",
      "515/515 [==============================] - 0s 325us/sample - loss: 34.6182 - mae: 4.4676 - val_loss: 69.5501 - val_mae: 6.9026\n",
      "Epoch 531/1000\n",
      "515/515 [==============================] - 0s 272us/sample - loss: 36.2760 - mae: 4.5868 - val_loss: 44.9196 - val_mae: 4.9310\n",
      "Epoch 532/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 33.6643 - mae: 4.3677 - val_loss: 59.1822 - val_mae: 5.8546\n",
      "Epoch 533/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 42.1456 - mae: 4.9307 - val_loss: 52.9051 - val_mae: 5.8438\n",
      "Epoch 534/1000\n",
      "515/515 [==============================] - 0s 247us/sample - loss: 34.3148 - mae: 4.3323 - val_loss: 46.3733 - val_mae: 5.3173\n",
      "Epoch 535/1000\n",
      "515/515 [==============================] - 0s 242us/sample - loss: 36.0982 - mae: 4.5280 - val_loss: 45.8571 - val_mae: 4.8696\n",
      "Epoch 536/1000\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 35.2045 - mae: 4.4698 - val_loss: 64.2019 - val_mae: 6.1930\n",
      "Epoch 537/1000\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 39.6027 - mae: 4.7793 - val_loss: 45.7134 - val_mae: 4.8538\n",
      "Epoch 538/1000\n",
      "515/515 [==============================] - 0s 279us/sample - loss: 33.5568 - mae: 4.4443 - val_loss: 233.5377 - val_mae: 13.2087\n",
      "Epoch 539/1000\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 42.3786 - mae: 4.6376 - val_loss: 52.0100 - val_mae: 5.2745\n",
      "Epoch 540/1000\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 36.6959 - mae: 4.5937 - val_loss: 60.7135 - val_mae: 5.8232\n",
      "Epoch 541/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 36.4541 - mae: 4.5323 - val_loss: 46.1168 - val_mae: 4.9401\n",
      "Epoch 542/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 35.8429 - mae: 4.5617 - val_loss: 72.8945 - val_mae: 7.1230\n",
      "Epoch 543/1000\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 37.4967 - mae: 4.5910 - val_loss: 50.9925 - val_mae: 5.1168\n",
      "Epoch 544/1000\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 33.3407 - mae: 4.3633 - val_loss: 68.1780 - val_mae: 6.6422\n",
      "Epoch 545/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 36.9909 - mae: 4.6362 - val_loss: 43.9015 - val_mae: 5.0893\n",
      "Epoch 546/1000\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 33.3644 - mae: 4.2718 - val_loss: 60.4054 - val_mae: 5.8219\n",
      "Epoch 547/1000\n",
      "515/515 [==============================] - 0s 234us/sample - loss: 37.2469 - mae: 4.6064 - val_loss: 50.2454 - val_mae: 5.5693\n",
      "Epoch 548/1000\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 33.2717 - mae: 4.3566 - val_loss: 127.4795 - val_mae: 9.7214\n",
      "Epoch 549/1000\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 40.1341 - mae: 4.6708 - val_loss: 66.0558 - val_mae: 6.1454\n",
      "Epoch 550/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 32.9134 - mae: 4.3463 - val_loss: 97.3935 - val_mae: 7.8120\n",
      "Epoch 551/1000\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 37.8071 - mae: 4.6826 - val_loss: 43.2902 - val_mae: 5.0253\n",
      "Epoch 552/1000\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 35.8916 - mae: 4.5293 - val_loss: 49.0757 - val_mae: 5.5181\n",
      "Epoch 553/1000\n",
      "515/515 [==============================] - 0s 311us/sample - loss: 36.5887 - mae: 4.5530 - val_loss: 56.7463 - val_mae: 6.0882\n",
      "Epoch 554/1000\n",
      "515/515 [==============================] - 0s 278us/sample - loss: 34.7675 - mae: 4.3608 - val_loss: 44.6809 - val_mae: 5.1440\n",
      "Epoch 555/1000\n",
      "515/515 [==============================] - 0s 273us/sample - loss: 33.8662 - mae: 4.3787 - val_loss: 82.8672 - val_mae: 7.5917\n",
      "Epoch 556/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 34.3846 - mae: 4.4358 - val_loss: 127.9468 - val_mae: 9.1104\n",
      "Epoch 557/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 39.4380 - mae: 4.6649 - val_loss: 55.0582 - val_mae: 6.0451\n",
      "Epoch 558/1000\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 35.4421 - mae: 4.4929 - val_loss: 68.6149 - val_mae: 6.3626\n",
      "Epoch 559/1000\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 34.4599 - mae: 4.4355 - val_loss: 48.2587 - val_mae: 5.4236\n",
      "Epoch 560/1000\n",
      "515/515 [==============================] - 0s 293us/sample - loss: 33.5940 - mae: 4.3454 - val_loss: 53.9465 - val_mae: 5.3336\n",
      "Epoch 561/1000\n",
      "515/515 [==============================] - 0s 279us/sample - loss: 34.7275 - mae: 4.4504 - val_loss: 47.0446 - val_mae: 5.3105\n",
      "Epoch 562/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 35.5140 - mae: 4.4555 - val_loss: 45.6686 - val_mae: 5.2388\n",
      "Epoch 563/1000\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 37.7761 - mae: 4.7181 - val_loss: 68.7200 - val_mae: 6.1631\n",
      "Epoch 564/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 34.7251 - mae: 4.4573 - val_loss: 43.2847 - val_mae: 4.8222\n",
      "Epoch 565/1000\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 32.9920 - mae: 4.2731 - val_loss: 48.6482 - val_mae: 4.9399\n",
      "Epoch 566/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 37.3218 - mae: 4.5597 - val_loss: 42.2298 - val_mae: 4.7248\n",
      "Epoch 567/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 31.2190 - mae: 4.2363 - val_loss: 50.8651 - val_mae: 5.1396\n",
      "Epoch 568/1000\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 37.6258 - mae: 4.6026 - val_loss: 47.3046 - val_mae: 4.9872\n",
      "Epoch 569/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 33.6689 - mae: 4.3878 - val_loss: 74.4302 - val_mae: 6.5810\n",
      "Epoch 570/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 37.0703 - mae: 4.5623 - val_loss: 44.8577 - val_mae: 5.1708\n",
      "Epoch 571/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 30.8958 - mae: 4.2104 - val_loss: 53.4442 - val_mae: 5.9315\n",
      "Epoch 572/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 38.3380 - mae: 4.6502 - val_loss: 74.3532 - val_mae: 6.5518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 573/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 32.8008 - mae: 4.2534 - val_loss: 61.0085 - val_mae: 6.4180\n",
      "Epoch 574/1000\n",
      "515/515 [==============================] - 0s 232us/sample - loss: 36.1039 - mae: 4.4991 - val_loss: 47.3292 - val_mae: 5.4705\n",
      "Epoch 575/1000\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 36.0510 - mae: 4.5580 - val_loss: 44.3178 - val_mae: 5.1845\n",
      "Epoch 576/1000\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 34.4607 - mae: 4.3656 - val_loss: 49.5759 - val_mae: 5.3768\n",
      "Epoch 577/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 36.0409 - mae: 4.5142 - val_loss: 57.5429 - val_mae: 6.2691\n",
      "Epoch 578/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 33.8275 - mae: 4.4173 - val_loss: 43.3709 - val_mae: 4.7375\n",
      "Epoch 579/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 33.1350 - mae: 4.2929 - val_loss: 50.3843 - val_mae: 5.4253\n",
      "Epoch 580/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 32.0389 - mae: 4.3125 - val_loss: 44.3182 - val_mae: 5.1084\n",
      "Epoch 581/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 35.1679 - mae: 4.4165 - val_loss: 145.1585 - val_mae: 10.0030\n",
      "Epoch 582/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 37.7096 - mae: 4.5415 - val_loss: 44.5473 - val_mae: 4.7404\n",
      "Epoch 583/1000\n",
      "515/515 [==============================] - 0s 226us/sample - loss: 34.2655 - mae: 4.4233 - val_loss: 49.3106 - val_mae: 5.1616\n",
      "Epoch 584/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 34.8441 - mae: 4.4095 - val_loss: 41.9163 - val_mae: 4.6042\n",
      "Epoch 585/1000\n",
      "515/515 [==============================] - 0s 295us/sample - loss: 32.5940 - mae: 4.2885 - val_loss: 46.1245 - val_mae: 5.1148\n",
      "Epoch 586/1000\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 33.1886 - mae: 4.3065 - val_loss: 79.9116 - val_mae: 7.4096\n",
      "Epoch 587/1000\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 35.2363 - mae: 4.5144 - val_loss: 88.9859 - val_mae: 8.0129\n",
      "Epoch 588/1000\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 35.2325 - mae: 4.4389 - val_loss: 41.4488 - val_mae: 4.6602\n",
      "Epoch 589/1000\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 33.4599 - mae: 4.3231 - val_loss: 85.5842 - val_mae: 7.7087\n",
      "Epoch 590/1000\n",
      "515/515 [==============================] - 0s 255us/sample - loss: 32.2238 - mae: 4.2277 - val_loss: 42.7204 - val_mae: 4.6493\n",
      "Epoch 591/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 35.8621 - mae: 4.5454 - val_loss: 49.4662 - val_mae: 5.5833\n",
      "Epoch 592/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 35.5133 - mae: 4.4291 - val_loss: 52.9324 - val_mae: 5.2974\n",
      "Epoch 593/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 36.5981 - mae: 4.5029 - val_loss: 42.1138 - val_mae: 4.7124\n",
      "Epoch 594/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 33.5533 - mae: 4.3800 - val_loss: 56.1694 - val_mae: 5.6823\n",
      "Epoch 595/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 35.0747 - mae: 4.3545 - val_loss: 53.6025 - val_mae: 5.6813\n",
      "Epoch 596/1000\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 33.6706 - mae: 4.3328 - val_loss: 63.1836 - val_mae: 6.4635\n",
      "Epoch 597/1000\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 33.7530 - mae: 4.3777 - val_loss: 100.5570 - val_mae: 8.0804\n",
      "Epoch 598/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 35.4205 - mae: 4.4216 - val_loss: 51.9442 - val_mae: 5.8662\n",
      "Epoch 599/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 33.6313 - mae: 4.4448 - val_loss: 45.2599 - val_mae: 4.7820\n",
      "Epoch 600/1000\n",
      "515/515 [==============================] - 0s 279us/sample - loss: 32.9267 - mae: 4.2805 - val_loss: 48.1857 - val_mae: 5.4920\n",
      "Epoch 601/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 37.3607 - mae: 4.5989 - val_loss: 57.7160 - val_mae: 5.6297\n",
      "Epoch 602/1000\n",
      "515/515 [==============================] - 0s 257us/sample - loss: 32.1180 - mae: 4.1734 - val_loss: 62.3728 - val_mae: 6.4076\n",
      "Epoch 603/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 35.8722 - mae: 4.4763 - val_loss: 40.4448 - val_mae: 4.6861\n",
      "Epoch 604/1000\n",
      "515/515 [==============================] - 0s 274us/sample - loss: 32.5862 - mae: 4.2562 - val_loss: 44.3771 - val_mae: 4.9709\n",
      "Epoch 605/1000\n",
      "515/515 [==============================] - 0s 333us/sample - loss: 31.5540 - mae: 4.2301 - val_loss: 50.4349 - val_mae: 5.6825\n",
      "Epoch 606/1000\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 31.8865 - mae: 4.2418 - val_loss: 139.1544 - val_mae: 9.7807\n",
      "Epoch 607/1000\n",
      "515/515 [==============================] - 0s 362us/sample - loss: 36.1824 - mae: 4.3935 - val_loss: 41.2528 - val_mae: 4.6229\n",
      "Epoch 608/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 34.2800 - mae: 4.4334 - val_loss: 57.0849 - val_mae: 5.5775\n",
      "Epoch 609/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 33.7348 - mae: 4.4061 - val_loss: 80.0815 - val_mae: 7.4830\n",
      "Epoch 610/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 33.8963 - mae: 4.3176 - val_loss: 153.1182 - val_mae: 10.3643\n",
      "Epoch 611/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 37.4904 - mae: 4.4942 - val_loss: 100.5318 - val_mae: 8.0607\n",
      "Epoch 612/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 32.3713 - mae: 4.2732 - val_loss: 69.2866 - val_mae: 6.4223\n",
      "Epoch 613/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 34.4026 - mae: 4.3659 - val_loss: 55.7624 - val_mae: 6.0745\n",
      "Epoch 614/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 36.3561 - mae: 4.5165 - val_loss: 56.8785 - val_mae: 6.0023\n",
      "Epoch 615/1000\n",
      "515/515 [==============================] - 0s 222us/sample - loss: 35.4128 - mae: 4.4531 - val_loss: 133.2785 - val_mae: 9.5161\n",
      "Epoch 616/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 36.4078 - mae: 4.5004 - val_loss: 48.2492 - val_mae: 4.9925\n",
      "Epoch 617/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 30.6629 - mae: 4.1685 - val_loss: 59.2885 - val_mae: 5.7647\n",
      "Epoch 618/1000\n",
      "515/515 [==============================] - 0s 191us/sample - loss: 38.9931 - mae: 4.6176 - val_loss: 43.8881 - val_mae: 4.7049\n",
      "Epoch 619/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 31.6466 - mae: 4.1924 - val_loss: 45.4785 - val_mae: 4.8250\n",
      "Epoch 620/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 32.2530 - mae: 4.2712 - val_loss: 69.3374 - val_mae: 6.7701\n",
      "Epoch 621/1000\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 36.9497 - mae: 4.5977 - val_loss: 43.7947 - val_mae: 4.9777\n",
      "Epoch 622/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 36.0709 - mae: 4.4979 - val_loss: 40.5593 - val_mae: 4.6356\n",
      "Epoch 623/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 32.3317 - mae: 4.2530 - val_loss: 49.0242 - val_mae: 5.0295\n",
      "Epoch 624/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 33.1325 - mae: 4.3205 - val_loss: 40.4663 - val_mae: 4.6308\n",
      "Epoch 625/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 34.0091 - mae: 4.4245 - val_loss: 53.7015 - val_mae: 5.9911\n",
      "Epoch 626/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 31.4936 - mae: 4.2157 - val_loss: 52.6402 - val_mae: 5.3656\n",
      "Epoch 627/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 32.8503 - mae: 4.4138 - val_loss: 43.8287 - val_mae: 5.1684\n",
      "Epoch 628/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 30.5180 - mae: 4.0761 - val_loss: 106.2684 - val_mae: 8.4658\n",
      "Epoch 629/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 34.6773 - mae: 4.3502 - val_loss: 43.8631 - val_mae: 4.7384\n",
      "Epoch 630/1000\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 33.1066 - mae: 4.3422 - val_loss: 42.7922 - val_mae: 4.6282\n",
      "Epoch 631/1000\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 33.2612 - mae: 4.3609 - val_loss: 101.6093 - val_mae: 8.3172\n",
      "Epoch 632/1000\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 34.9431 - mae: 4.3348 - val_loss: 39.1581 - val_mae: 4.5938\n",
      "Epoch 633/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 33.6104 - mae: 4.3544 - val_loss: 50.9331 - val_mae: 5.2646\n",
      "Epoch 634/1000\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 35.4271 - mae: 4.4096 - val_loss: 41.7173 - val_mae: 4.7402\n",
      "Epoch 635/1000\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 32.4638 - mae: 4.2422 - val_loss: 75.7420 - val_mae: 7.3884\n",
      "Epoch 636/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 32.1285 - mae: 4.3632 - val_loss: 48.2855 - val_mae: 4.9989\n",
      "Epoch 637/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 34.2909 - mae: 4.3554 - val_loss: 99.3990 - val_mae: 7.9874\n",
      "Epoch 638/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 36.1265 - mae: 4.4638 - val_loss: 63.2109 - val_mae: 6.1870\n",
      "Epoch 639/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 36.2814 - mae: 4.4841 - val_loss: 49.2661 - val_mae: 5.2813\n",
      "Epoch 640/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 32.5303 - mae: 4.1966 - val_loss: 46.9233 - val_mae: 5.1211\n",
      "Epoch 641/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 31.9836 - mae: 4.2033 - val_loss: 39.4802 - val_mae: 4.6364\n",
      "Epoch 642/1000\n",
      "515/515 [==============================] - 0s 293us/sample - loss: 33.4640 - mae: 4.2573 - val_loss: 39.9964 - val_mae: 4.8049\n",
      "Epoch 643/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 33.7979 - mae: 4.5232 - val_loss: 106.4334 - val_mae: 8.4422\n",
      "Epoch 644/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 39.2937 - mae: 4.6146 - val_loss: 53.2394 - val_mae: 5.5496\n",
      "Epoch 645/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 33.0819 - mae: 4.3431 - val_loss: 59.5984 - val_mae: 5.8877\n",
      "Epoch 646/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 34.2067 - mae: 4.2746 - val_loss: 64.2416 - val_mae: 6.3096\n",
      "Epoch 647/1000\n",
      "515/515 [==============================] - 0s 283us/sample - loss: 33.6557 - mae: 4.3366 - val_loss: 41.9550 - val_mae: 4.9742\n",
      "Epoch 648/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 34.7132 - mae: 4.4491 - val_loss: 64.7315 - val_mae: 6.3093\n",
      "Epoch 649/1000\n",
      "515/515 [==============================] - 0s 247us/sample - loss: 34.0261 - mae: 4.3576 - val_loss: 118.1702 - val_mae: 9.1285\n",
      "Epoch 650/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 34.9809 - mae: 4.4662 - val_loss: 39.8103 - val_mae: 4.5613\n",
      "Epoch 651/1000\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 29.4254 - mae: 4.0994 - val_loss: 48.9984 - val_mae: 5.6338\n",
      "Epoch 652/1000\n",
      "515/515 [==============================] - 0s 265us/sample - loss: 31.9161 - mae: 4.2092 - val_loss: 72.0930 - val_mae: 6.7304\n",
      "Epoch 653/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 35.2761 - mae: 4.5008 - val_loss: 44.5685 - val_mae: 4.7721\n",
      "Epoch 654/1000\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 29.7598 - mae: 4.0741 - val_loss: 76.4727 - val_mae: 6.7794\n",
      "Epoch 655/1000\n",
      "515/515 [==============================] - 0s 255us/sample - loss: 33.7821 - mae: 4.3685 - val_loss: 161.7887 - val_mae: 10.5161\n",
      "Epoch 656/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 36.3775 - mae: 4.3135 - val_loss: 39.7782 - val_mae: 4.7073\n",
      "Epoch 657/1000\n",
      "515/515 [==============================] - 0s 297us/sample - loss: 35.2522 - mae: 4.4536 - val_loss: 39.0200 - val_mae: 4.5394\n",
      "Epoch 658/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 30.7178 - mae: 4.1448 - val_loss: 45.4212 - val_mae: 4.8689\n",
      "Epoch 659/1000\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 30.5760 - mae: 4.0853 - val_loss: 46.5271 - val_mae: 5.1156\n",
      "Epoch 660/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 33.0225 - mae: 4.2689 - val_loss: 38.6755 - val_mae: 4.6595\n",
      "Epoch 661/1000\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 34.9315 - mae: 4.4505 - val_loss: 55.1500 - val_mae: 6.0613\n",
      "Epoch 662/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 32.4750 - mae: 4.3232 - val_loss: 72.1173 - val_mae: 7.1270\n",
      "Epoch 663/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 33.6799 - mae: 4.3699 - val_loss: 100.8503 - val_mae: 8.0372\n",
      "Epoch 664/1000\n",
      "515/515 [==============================] - 0s 247us/sample - loss: 31.3103 - mae: 4.1768 - val_loss: 76.4695 - val_mae: 7.1524\n",
      "Epoch 665/1000\n",
      "515/515 [==============================] - 0s 295us/sample - loss: 33.6376 - mae: 4.3305 - val_loss: 59.1498 - val_mae: 5.7889\n",
      "Epoch 666/1000\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 32.7128 - mae: 4.2791 - val_loss: 39.3537 - val_mae: 4.6940\n",
      "Epoch 667/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 32.0029 - mae: 4.1325 - val_loss: 38.3769 - val_mae: 4.5827\n",
      "Epoch 668/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 34.0365 - mae: 4.4598 - val_loss: 71.4860 - val_mae: 7.0218\n",
      "Epoch 669/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 34.4490 - mae: 4.4094 - val_loss: 58.8610 - val_mae: 6.2860\n",
      "Epoch 670/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 31.9515 - mae: 4.2750 - val_loss: 40.8641 - val_mae: 4.7674\n",
      "Epoch 671/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 33.5585 - mae: 4.3693 - val_loss: 51.8128 - val_mae: 5.8364\n",
      "Epoch 672/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 30.4569 - mae: 4.1394 - val_loss: 82.8006 - val_mae: 7.5575\n",
      "Epoch 673/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 34.4212 - mae: 4.4192 - val_loss: 46.7771 - val_mae: 5.0619\n",
      "Epoch 674/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 33.0951 - mae: 4.3037 - val_loss: 44.5234 - val_mae: 5.2477\n",
      "Epoch 675/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 32.9594 - mae: 4.2139 - val_loss: 52.0550 - val_mae: 5.8812\n",
      "Epoch 676/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 34.7579 - mae: 4.4494 - val_loss: 41.5009 - val_mae: 4.5977\n",
      "Epoch 677/1000\n",
      "515/515 [==============================] - 0s 189us/sample - loss: 29.4932 - mae: 4.0725 - val_loss: 70.1057 - val_mae: 6.6269\n",
      "Epoch 678/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 31.6069 - mae: 4.2708 - val_loss: 39.7873 - val_mae: 4.7713\n",
      "Epoch 679/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 35.5596 - mae: 4.4939 - val_loss: 43.0194 - val_mae: 4.7594\n",
      "Epoch 680/1000\n",
      "515/515 [==============================] - 0s 189us/sample - loss: 31.8442 - mae: 4.1241 - val_loss: 38.7071 - val_mae: 4.5684\n",
      "Epoch 681/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 35.2078 - mae: 4.3824 - val_loss: 45.2780 - val_mae: 4.9603\n",
      "Epoch 682/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 29.5134 - mae: 4.0542 - val_loss: 47.2548 - val_mae: 5.2430\n",
      "Epoch 683/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 32.2051 - mae: 4.2243 - val_loss: 48.4325 - val_mae: 5.3564\n",
      "Epoch 684/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 31.4825 - mae: 4.1222 - val_loss: 68.4549 - val_mae: 6.8121\n",
      "Epoch 685/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 32.4402 - mae: 4.3029 - val_loss: 41.2098 - val_mae: 4.6179\n",
      "Epoch 686/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 31.8410 - mae: 4.2452 - val_loss: 38.8637 - val_mae: 4.6367\n",
      "Epoch 687/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 32.8086 - mae: 4.2882 - val_loss: 96.3986 - val_mae: 8.2012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 688/1000\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 33.2083 - mae: 4.2491 - val_loss: 46.2829 - val_mae: 5.0524\n",
      "Epoch 689/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 31.9465 - mae: 4.2495 - val_loss: 39.1816 - val_mae: 4.5612\n",
      "Epoch 690/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 32.7848 - mae: 4.3398 - val_loss: 39.4778 - val_mae: 4.5231\n",
      "Epoch 691/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 31.7066 - mae: 4.2246 - val_loss: 48.0137 - val_mae: 5.4850\n",
      "Epoch 692/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 31.7628 - mae: 4.2418 - val_loss: 40.3486 - val_mae: 4.5469\n",
      "Epoch 693/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 32.5193 - mae: 4.2676 - val_loss: 43.1176 - val_mae: 4.9987\n",
      "Epoch 694/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 33.7850 - mae: 4.4095 - val_loss: 93.4245 - val_mae: 7.8015\n",
      "Epoch 695/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 35.8671 - mae: 4.3990 - val_loss: 40.8586 - val_mae: 4.6947\n",
      "Epoch 696/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 31.8176 - mae: 4.2297 - val_loss: 39.3871 - val_mae: 4.6646\n",
      "Epoch 697/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 31.2481 - mae: 4.2539 - val_loss: 41.8998 - val_mae: 4.6673\n",
      "Epoch 698/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 32.1154 - mae: 4.3110 - val_loss: 39.5603 - val_mae: 4.5569\n",
      "Epoch 699/1000\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 30.8169 - mae: 4.1222 - val_loss: 59.7510 - val_mae: 5.7986\n",
      "Epoch 700/1000\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 29.1732 - mae: 4.0919 - val_loss: 45.9519 - val_mae: 5.3947\n",
      "Epoch 701/1000\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 34.1266 - mae: 4.4087 - val_loss: 39.1317 - val_mae: 4.6802\n",
      "Epoch 702/1000\n",
      "515/515 [==============================] - 0s 244us/sample - loss: 31.4408 - mae: 4.1654 - val_loss: 67.1795 - val_mae: 6.8481\n",
      "Epoch 703/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 31.0606 - mae: 4.1980 - val_loss: 41.6617 - val_mae: 4.8356\n",
      "Epoch 704/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 33.6272 - mae: 4.3492 - val_loss: 39.0672 - val_mae: 4.7181\n",
      "Epoch 705/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 29.7212 - mae: 4.0313 - val_loss: 82.1769 - val_mae: 7.2119\n",
      "Epoch 706/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 34.3178 - mae: 4.4144 - val_loss: 45.4487 - val_mae: 5.1354\n",
      "Epoch 707/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 29.0515 - mae: 4.1607 - val_loss: 67.3552 - val_mae: 6.9137\n",
      "Epoch 708/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 32.2432 - mae: 4.2491 - val_loss: 127.7067 - val_mae: 9.2299\n",
      "Epoch 709/1000\n",
      "515/515 [==============================] - 0s 307us/sample - loss: 37.5865 - mae: 4.3488 - val_loss: 38.6052 - val_mae: 4.6959\n",
      "Epoch 710/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 29.9604 - mae: 4.0979 - val_loss: 48.1835 - val_mae: 5.5346\n",
      "Epoch 711/1000\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 29.9976 - mae: 4.0877 - val_loss: 103.9965 - val_mae: 8.0125\n",
      "Epoch 712/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 35.4207 - mae: 4.4542 - val_loss: 46.3066 - val_mae: 5.4084\n",
      "Epoch 713/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 33.5044 - mae: 4.2182 - val_loss: 46.4308 - val_mae: 5.4096\n",
      "Epoch 714/1000\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 29.8456 - mae: 4.0998 - val_loss: 55.3549 - val_mae: 5.8530\n",
      "Epoch 715/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 35.5440 - mae: 4.4887 - val_loss: 38.5041 - val_mae: 4.6443\n",
      "Epoch 716/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 29.1505 - mae: 4.0568 - val_loss: 57.9695 - val_mae: 6.1467\n",
      "Epoch 717/1000\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 30.9171 - mae: 4.1607 - val_loss: 107.5685 - val_mae: 8.3692\n",
      "Epoch 718/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 34.6354 - mae: 4.3204 - val_loss: 39.5867 - val_mae: 4.4908\n",
      "Epoch 719/1000\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 28.9086 - mae: 4.0853 - val_loss: 57.6318 - val_mae: 5.8427\n",
      "Epoch 720/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 31.4299 - mae: 4.2519 - val_loss: 41.4933 - val_mae: 4.9712\n",
      "Epoch 721/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 31.4013 - mae: 4.1912 - val_loss: 47.9566 - val_mae: 5.1382\n",
      "Epoch 722/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 30.5527 - mae: 4.1991 - val_loss: 40.8539 - val_mae: 4.5047\n",
      "Epoch 723/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 33.4729 - mae: 4.3287 - val_loss: 40.0858 - val_mae: 4.8938\n",
      "Epoch 724/1000\n",
      "515/515 [==============================] - 0s 228us/sample - loss: 28.7090 - mae: 4.0933 - val_loss: 37.2251 - val_mae: 4.4446\n",
      "Epoch 725/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 36.2279 - mae: 4.5240 - val_loss: 91.6301 - val_mae: 7.6192\n",
      "Epoch 726/1000\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 30.9931 - mae: 4.1059 - val_loss: 84.6180 - val_mae: 7.4060\n",
      "Epoch 727/1000\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 31.7846 - mae: 4.2194 - val_loss: 40.2064 - val_mae: 4.5706\n",
      "Epoch 728/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 31.0354 - mae: 4.1716 - val_loss: 44.6069 - val_mae: 5.1139\n",
      "Epoch 729/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 31.1368 - mae: 4.1449 - val_loss: 42.5178 - val_mae: 5.0038\n",
      "Epoch 730/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 32.1404 - mae: 4.2965 - val_loss: 43.5502 - val_mae: 5.0547\n",
      "Epoch 731/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 32.1405 - mae: 4.1874 - val_loss: 39.5222 - val_mae: 4.6629\n",
      "Epoch 732/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 29.8306 - mae: 4.0819 - val_loss: 72.6678 - val_mae: 6.7702\n",
      "Epoch 733/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 28.8790 - mae: 3.9564 - val_loss: 43.4431 - val_mae: 4.8512\n",
      "Epoch 734/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 34.2833 - mae: 4.4032 - val_loss: 91.5344 - val_mae: 7.8842\n",
      "Epoch 735/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 31.0561 - mae: 4.1259 - val_loss: 81.2860 - val_mae: 7.4228\n",
      "Epoch 736/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 30.2830 - mae: 4.1478 - val_loss: 45.3004 - val_mae: 4.7878\n",
      "Epoch 737/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 32.2971 - mae: 4.3150 - val_loss: 57.2967 - val_mae: 6.2342\n",
      "Epoch 738/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 30.0326 - mae: 4.1188 - val_loss: 42.7574 - val_mae: 4.8361\n",
      "Epoch 739/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 28.9386 - mae: 3.9793 - val_loss: 38.0496 - val_mae: 4.5099\n",
      "Epoch 740/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 30.2632 - mae: 4.1258 - val_loss: 37.5625 - val_mae: 4.6050\n",
      "Epoch 741/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 28.8003 - mae: 4.0266 - val_loss: 62.6143 - val_mae: 6.5796\n",
      "Epoch 742/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 29.1980 - mae: 4.0705 - val_loss: 54.0234 - val_mae: 6.0201\n",
      "Epoch 743/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 31.7724 - mae: 4.1930 - val_loss: 41.8727 - val_mae: 4.9921\n",
      "Epoch 744/1000\n",
      "515/515 [==============================] - 0s 191us/sample - loss: 31.2767 - mae: 4.1829 - val_loss: 81.6806 - val_mae: 6.8317\n",
      "Epoch 745/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 30.5807 - mae: 4.1145 - val_loss: 42.1467 - val_mae: 5.1174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 746/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 31.8913 - mae: 4.2012 - val_loss: 50.9024 - val_mae: 5.3448\n",
      "Epoch 747/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 29.2972 - mae: 4.0500 - val_loss: 41.4941 - val_mae: 4.6694\n",
      "Epoch 748/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 30.5106 - mae: 4.1566 - val_loss: 40.3331 - val_mae: 4.6441\n",
      "Epoch 749/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 31.4377 - mae: 4.3041 - val_loss: 42.4152 - val_mae: 4.8450\n",
      "Epoch 750/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 31.3887 - mae: 4.1726 - val_loss: 41.4749 - val_mae: 4.9943\n",
      "Epoch 751/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 30.6534 - mae: 4.1991 - val_loss: 51.0304 - val_mae: 5.8218\n",
      "Epoch 752/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 29.2998 - mae: 4.0362 - val_loss: 106.9338 - val_mae: 8.3250\n",
      "Epoch 753/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 29.3871 - mae: 4.0178 - val_loss: 38.6649 - val_mae: 4.4729\n",
      "Epoch 754/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 30.4114 - mae: 4.1334 - val_loss: 41.1973 - val_mae: 4.8524\n",
      "Epoch 755/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 30.5950 - mae: 4.0929 - val_loss: 47.0663 - val_mae: 5.1653\n",
      "Epoch 756/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 30.3123 - mae: 4.0987 - val_loss: 79.6718 - val_mae: 7.2937\n",
      "Epoch 757/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 35.3604 - mae: 4.4023 - val_loss: 38.6759 - val_mae: 4.4893\n",
      "Epoch 758/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 27.0864 - mae: 3.9212 - val_loss: 43.9989 - val_mae: 5.2041\n",
      "Epoch 759/1000\n",
      "515/515 [==============================] - 0s 193us/sample - loss: 30.1178 - mae: 4.2128 - val_loss: 40.6603 - val_mae: 4.5789\n",
      "Epoch 760/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 31.7485 - mae: 4.2245 - val_loss: 60.4591 - val_mae: 5.9804\n",
      "Epoch 761/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 32.1746 - mae: 4.1868 - val_loss: 56.6208 - val_mae: 5.7799\n",
      "Epoch 762/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 30.9278 - mae: 4.1542 - val_loss: 81.2827 - val_mae: 7.5605\n",
      "Epoch 763/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 30.9568 - mae: 4.1804 - val_loss: 36.9802 - val_mae: 4.4266\n",
      "Epoch 764/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 29.0903 - mae: 3.9970 - val_loss: 52.9150 - val_mae: 5.9613\n",
      "Epoch 765/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 34.1584 - mae: 4.3560 - val_loss: 40.6141 - val_mae: 4.7363\n",
      "Epoch 766/1000\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 27.1816 - mae: 3.9294 - val_loss: 46.2743 - val_mae: 5.3726\n",
      "Epoch 767/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 32.8833 - mae: 4.3676 - val_loss: 45.0030 - val_mae: 5.3201\n",
      "Epoch 768/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 31.6656 - mae: 4.2699 - val_loss: 59.2479 - val_mae: 6.1344\n",
      "Epoch 769/1000\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 28.3717 - mae: 4.0251 - val_loss: 40.4452 - val_mae: 4.7946\n",
      "Epoch 770/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 30.8383 - mae: 4.2069 - val_loss: 39.2302 - val_mae: 4.7168\n",
      "Epoch 771/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 33.3778 - mae: 4.3273 - val_loss: 45.3923 - val_mae: 5.3759\n",
      "Epoch 772/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 31.6242 - mae: 4.2953 - val_loss: 42.6322 - val_mae: 5.0656\n",
      "Epoch 773/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 28.3932 - mae: 3.9526 - val_loss: 49.9660 - val_mae: 5.7948\n",
      "Epoch 774/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 29.7358 - mae: 4.1035 - val_loss: 50.4308 - val_mae: 5.7978\n",
      "Epoch 775/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 28.7722 - mae: 4.0700 - val_loss: 38.1032 - val_mae: 4.4444\n",
      "Epoch 776/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 31.2797 - mae: 4.1298 - val_loss: 43.4929 - val_mae: 5.1786\n",
      "Epoch 777/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 28.2362 - mae: 4.0095 - val_loss: 39.7818 - val_mae: 4.8847\n",
      "Epoch 778/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 30.2997 - mae: 4.1519 - val_loss: 40.8043 - val_mae: 4.5395\n",
      "Epoch 779/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 26.2521 - mae: 3.8771 - val_loss: 47.4539 - val_mae: 5.5409\n",
      "Epoch 780/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 34.5230 - mae: 4.4225 - val_loss: 48.8486 - val_mae: 5.1274\n",
      "Epoch 781/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 30.1383 - mae: 4.1469 - val_loss: 39.7452 - val_mae: 4.6880\n",
      "Epoch 782/1000\n",
      "515/515 [==============================] - 0s 220us/sample - loss: 30.5195 - mae: 4.0258 - val_loss: 47.8267 - val_mae: 5.6840\n",
      "Epoch 783/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 30.3071 - mae: 4.1529 - val_loss: 46.6127 - val_mae: 5.0790\n",
      "Epoch 784/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 29.1494 - mae: 4.1474 - val_loss: 43.1613 - val_mae: 4.8363\n",
      "Epoch 785/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 29.1785 - mae: 4.1325 - val_loss: 47.0885 - val_mae: 5.0968\n",
      "Epoch 786/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 31.6801 - mae: 4.2283 - val_loss: 37.5731 - val_mae: 4.5914\n",
      "Epoch 787/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 29.6525 - mae: 4.1063 - val_loss: 38.2100 - val_mae: 4.6266\n",
      "Epoch 788/1000\n",
      "515/515 [==============================] - 0s 195us/sample - loss: 30.5283 - mae: 4.1216 - val_loss: 36.3692 - val_mae: 4.5453\n",
      "Epoch 789/1000\n",
      "515/515 [==============================] - 0s 193us/sample - loss: 30.2986 - mae: 4.1124 - val_loss: 47.7302 - val_mae: 5.5450\n",
      "Epoch 790/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 28.8979 - mae: 3.9984 - val_loss: 49.3040 - val_mae: 5.6202\n",
      "Epoch 791/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 29.5234 - mae: 4.1245 - val_loss: 36.3312 - val_mae: 4.4533\n",
      "Epoch 792/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 29.1895 - mae: 4.0198 - val_loss: 66.3635 - val_mae: 6.7750\n",
      "Epoch 793/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 28.1804 - mae: 3.9950 - val_loss: 55.7102 - val_mae: 5.9915\n",
      "Epoch 794/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 32.1401 - mae: 4.2032 - val_loss: 41.1011 - val_mae: 5.0407\n",
      "Epoch 795/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 30.7839 - mae: 4.1936 - val_loss: 38.4206 - val_mae: 4.5744\n",
      "Epoch 796/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 29.6084 - mae: 4.1330 - val_loss: 97.2232 - val_mae: 7.9951\n",
      "Epoch 797/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 30.3716 - mae: 4.1298 - val_loss: 52.7959 - val_mae: 5.4965\n",
      "Epoch 798/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 29.3355 - mae: 4.0456 - val_loss: 40.8485 - val_mae: 4.7292\n",
      "Epoch 799/1000\n",
      "515/515 [==============================] - 0s 191us/sample - loss: 29.0966 - mae: 4.0689 - val_loss: 45.6305 - val_mae: 5.4942\n",
      "Epoch 800/1000\n",
      "515/515 [==============================] - 0s 199us/sample - loss: 26.8847 - mae: 3.8906 - val_loss: 52.8562 - val_mae: 5.5303\n",
      "Epoch 801/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 30.2009 - mae: 4.1803 - val_loss: 37.1350 - val_mae: 4.5207\n",
      "Epoch 802/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 30.3269 - mae: 4.1273 - val_loss: 42.2678 - val_mae: 4.7695\n",
      "Epoch 803/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 29.8456 - mae: 4.0680 - val_loss: 51.4916 - val_mae: 5.7474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 804/1000\n",
      "515/515 [==============================] - 0s 266us/sample - loss: 29.4513 - mae: 4.0224 - val_loss: 42.7318 - val_mae: 5.1285\n",
      "Epoch 805/1000\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 27.9484 - mae: 3.9976 - val_loss: 39.3890 - val_mae: 4.7776\n",
      "Epoch 806/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 31.4531 - mae: 4.2003 - val_loss: 40.6860 - val_mae: 5.0066\n",
      "Epoch 807/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 28.7923 - mae: 4.0196 - val_loss: 38.9935 - val_mae: 4.6498\n",
      "Epoch 808/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 28.4813 - mae: 3.9579 - val_loss: 44.7071 - val_mae: 5.0137\n",
      "Epoch 809/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 28.4005 - mae: 4.0578 - val_loss: 36.6330 - val_mae: 4.5630\n",
      "Epoch 810/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 29.5755 - mae: 4.0529 - val_loss: 87.7446 - val_mae: 7.4630\n",
      "Epoch 811/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 31.0702 - mae: 4.1158 - val_loss: 36.8917 - val_mae: 4.6090\n",
      "Epoch 812/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 32.7451 - mae: 4.2422 - val_loss: 41.2137 - val_mae: 4.6285\n",
      "Epoch 813/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 28.8140 - mae: 4.0726 - val_loss: 50.7378 - val_mae: 5.6412\n",
      "Epoch 814/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 31.0393 - mae: 4.2208 - val_loss: 88.6689 - val_mae: 7.5611\n",
      "Epoch 815/1000\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 29.1864 - mae: 4.1313 - val_loss: 55.0267 - val_mae: 6.0688\n",
      "Epoch 816/1000\n",
      "515/515 [==============================] - 0s 226us/sample - loss: 28.3754 - mae: 4.0423 - val_loss: 41.1186 - val_mae: 4.6572\n",
      "Epoch 817/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 30.6750 - mae: 4.1593 - val_loss: 46.9407 - val_mae: 5.0390\n",
      "Epoch 818/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 27.2619 - mae: 3.8747 - val_loss: 42.0432 - val_mae: 4.8691\n",
      "Epoch 819/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 28.6483 - mae: 3.9839 - val_loss: 37.4502 - val_mae: 4.5876\n",
      "Epoch 820/1000\n",
      "515/515 [==============================] - 0s 266us/sample - loss: 29.9323 - mae: 4.1789 - val_loss: 38.6241 - val_mae: 4.8258\n",
      "Epoch 821/1000\n",
      "515/515 [==============================] - 0s 267us/sample - loss: 27.3291 - mae: 3.9365 - val_loss: 39.4056 - val_mae: 4.5469\n",
      "Epoch 822/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 32.4010 - mae: 4.2642 - val_loss: 36.6910 - val_mae: 4.5919\n",
      "Epoch 823/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 27.5162 - mae: 3.9496 - val_loss: 49.1334 - val_mae: 5.5877\n",
      "Epoch 824/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 30.9876 - mae: 4.1195 - val_loss: 52.2701 - val_mae: 5.4586\n",
      "Epoch 825/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 30.6180 - mae: 4.2674 - val_loss: 48.6043 - val_mae: 5.3582\n",
      "Epoch 826/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 28.4234 - mae: 4.0088 - val_loss: 41.1032 - val_mae: 4.6631\n",
      "Epoch 827/1000\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 29.2290 - mae: 4.0770 - val_loss: 83.9663 - val_mae: 7.7742\n",
      "Epoch 828/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 28.0371 - mae: 3.9960 - val_loss: 44.3792 - val_mae: 4.9821\n",
      "Epoch 829/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 27.7143 - mae: 3.9950 - val_loss: 37.9524 - val_mae: 4.7869\n",
      "Epoch 830/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 31.4734 - mae: 4.1947 - val_loss: 56.0641 - val_mae: 6.0244\n",
      "Epoch 831/1000\n",
      "515/515 [==============================] - 0s 199us/sample - loss: 31.0274 - mae: 4.2155 - val_loss: 64.0258 - val_mae: 6.2178\n",
      "Epoch 832/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 29.8810 - mae: 4.1346 - val_loss: 37.3817 - val_mae: 4.5091\n",
      "Epoch 833/1000\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 27.6320 - mae: 3.9866 - val_loss: 45.3637 - val_mae: 5.0628\n",
      "Epoch 834/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 29.7885 - mae: 4.1816 - val_loss: 37.2841 - val_mae: 4.5948\n",
      "Epoch 835/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 27.9997 - mae: 4.0337 - val_loss: 55.5008 - val_mae: 5.7267\n",
      "Epoch 836/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 32.9499 - mae: 4.3107 - val_loss: 52.6997 - val_mae: 5.6267\n",
      "Epoch 837/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 25.9924 - mae: 3.8359 - val_loss: 55.6531 - val_mae: 6.0030\n",
      "Epoch 838/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 28.9863 - mae: 4.0326 - val_loss: 67.2915 - val_mae: 6.9858\n",
      "Epoch 839/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 27.9206 - mae: 3.9910 - val_loss: 58.9695 - val_mae: 6.4510\n",
      "Epoch 840/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 28.9343 - mae: 4.0787 - val_loss: 37.6871 - val_mae: 4.6395\n",
      "Epoch 841/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 29.8166 - mae: 4.0469 - val_loss: 42.3019 - val_mae: 5.1471\n",
      "Epoch 842/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 30.1885 - mae: 4.1341 - val_loss: 38.7313 - val_mae: 4.5592\n",
      "Epoch 843/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 28.3455 - mae: 3.9836 - val_loss: 149.6300 - val_mae: 10.0827\n",
      "Epoch 844/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 32.1731 - mae: 4.1043 - val_loss: 74.9245 - val_mae: 7.3933\n",
      "Epoch 845/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 29.8011 - mae: 4.1259 - val_loss: 54.5600 - val_mae: 6.0091\n",
      "Epoch 846/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 30.0298 - mae: 4.1112 - val_loss: 46.1696 - val_mae: 4.9658\n",
      "Epoch 847/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 30.9025 - mae: 4.1210 - val_loss: 39.6611 - val_mae: 4.9333\n",
      "Epoch 848/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 29.7653 - mae: 4.1393 - val_loss: 57.1285 - val_mae: 6.2361\n",
      "Epoch 849/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 29.3144 - mae: 4.0894 - val_loss: 64.1018 - val_mae: 6.1586\n",
      "Epoch 850/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 28.3784 - mae: 3.9863 - val_loss: 45.3979 - val_mae: 4.8485\n",
      "Epoch 851/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 29.1685 - mae: 4.0392 - val_loss: 51.5429 - val_mae: 5.8016\n",
      "Epoch 852/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 28.1567 - mae: 4.0539 - val_loss: 93.1753 - val_mae: 7.7754\n",
      "Epoch 853/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 28.0267 - mae: 3.9402 - val_loss: 37.4979 - val_mae: 4.4871\n",
      "Epoch 854/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 26.2953 - mae: 3.8704 - val_loss: 46.6706 - val_mae: 5.1646\n",
      "Epoch 855/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 29.0948 - mae: 4.1551 - val_loss: 40.9750 - val_mae: 4.6612\n",
      "Epoch 856/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 31.3329 - mae: 4.1920 - val_loss: 38.4304 - val_mae: 4.5589\n",
      "Epoch 857/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 29.6779 - mae: 4.0301 - val_loss: 64.4585 - val_mae: 6.6357\n",
      "Epoch 858/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 26.8637 - mae: 3.8556 - val_loss: 44.9185 - val_mae: 4.9257\n",
      "Epoch 859/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 27.7957 - mae: 3.9014 - val_loss: 88.3560 - val_mae: 7.8912\n",
      "Epoch 860/1000\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 30.9374 - mae: 4.2105 - val_loss: 38.6001 - val_mae: 4.8566\n",
      "Epoch 861/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 30.2433 - mae: 4.1595 - val_loss: 40.1606 - val_mae: 4.6746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 862/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 27.6562 - mae: 3.8969 - val_loss: 61.3207 - val_mae: 6.2797\n",
      "Epoch 863/1000\n",
      "515/515 [==============================] - 0s 189us/sample - loss: 27.8107 - mae: 3.9172 - val_loss: 39.3114 - val_mae: 4.5511\n",
      "Epoch 864/1000\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 28.9826 - mae: 4.0170 - val_loss: 52.6825 - val_mae: 5.8502\n",
      "Epoch 865/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 29.7154 - mae: 4.1094 - val_loss: 37.6006 - val_mae: 4.4139\n",
      "Epoch 866/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 30.6470 - mae: 4.1276 - val_loss: 37.5347 - val_mae: 4.6298\n",
      "Epoch 867/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 25.6735 - mae: 3.8255 - val_loss: 41.3813 - val_mae: 5.0868\n",
      "Epoch 868/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 29.6978 - mae: 4.1030 - val_loss: 67.2139 - val_mae: 6.7991\n",
      "Epoch 869/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 27.9785 - mae: 3.9348 - val_loss: 58.4069 - val_mae: 5.7938\n",
      "Epoch 870/1000\n",
      "515/515 [==============================] - 0s 209us/sample - loss: 35.2244 - mae: 4.4054 - val_loss: 48.8793 - val_mae: 5.1686\n",
      "Epoch 871/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 25.8638 - mae: 3.8479 - val_loss: 37.0509 - val_mae: 4.4747\n",
      "Epoch 872/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 28.5112 - mae: 3.9969 - val_loss: 87.5471 - val_mae: 7.9845\n",
      "Epoch 873/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 31.9097 - mae: 4.1985 - val_loss: 41.2420 - val_mae: 4.7463\n",
      "Epoch 874/1000\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 28.6456 - mae: 4.0003 - val_loss: 37.9212 - val_mae: 4.6641\n",
      "Epoch 875/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 28.6699 - mae: 3.9931 - val_loss: 39.7115 - val_mae: 4.7826\n",
      "Epoch 876/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 29.3637 - mae: 4.0019 - val_loss: 35.8773 - val_mae: 4.4370\n",
      "Epoch 877/1000\n",
      "515/515 [==============================] - 0s 191us/sample - loss: 28.0921 - mae: 3.9318 - val_loss: 90.5157 - val_mae: 7.4990\n",
      "Epoch 878/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 28.2846 - mae: 3.9365 - val_loss: 80.6245 - val_mae: 7.1553\n",
      "Epoch 879/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 31.5336 - mae: 4.2422 - val_loss: 40.2408 - val_mae: 4.6434\n",
      "Epoch 880/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 30.0681 - mae: 4.1438 - val_loss: 39.5575 - val_mae: 4.5057\n",
      "Epoch 881/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 26.5201 - mae: 3.8953 - val_loss: 36.5188 - val_mae: 4.4428\n",
      "Epoch 882/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 26.9353 - mae: 3.9836 - val_loss: 61.1353 - val_mae: 5.9627\n",
      "Epoch 883/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 29.0105 - mae: 4.0658 - val_loss: 78.6447 - val_mae: 6.9171\n",
      "Epoch 884/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 28.8963 - mae: 3.9774 - val_loss: 66.1513 - val_mae: 6.4570\n",
      "Epoch 885/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 30.2819 - mae: 4.1208 - val_loss: 46.7486 - val_mae: 5.5356\n",
      "Epoch 886/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 26.3041 - mae: 3.7992 - val_loss: 77.2908 - val_mae: 7.1887\n",
      "Epoch 887/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 28.6982 - mae: 4.0582 - val_loss: 35.8926 - val_mae: 4.4477\n",
      "Epoch 888/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 26.1732 - mae: 3.9428 - val_loss: 38.4454 - val_mae: 4.7645\n",
      "Epoch 889/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 28.7267 - mae: 3.9466 - val_loss: 69.2321 - val_mae: 6.4886\n",
      "Epoch 890/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 29.2133 - mae: 4.0349 - val_loss: 98.7509 - val_mae: 8.0280\n",
      "Epoch 891/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 30.0571 - mae: 4.0016 - val_loss: 42.4168 - val_mae: 5.0260\n",
      "Epoch 892/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 27.5795 - mae: 3.8847 - val_loss: 56.1414 - val_mae: 5.7504\n",
      "Epoch 893/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 26.9115 - mae: 3.8975 - val_loss: 43.9787 - val_mae: 4.9999\n",
      "Epoch 894/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 28.7486 - mae: 3.9986 - val_loss: 71.2441 - val_mae: 6.8466\n",
      "Epoch 895/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 28.9163 - mae: 3.9179 - val_loss: 36.1149 - val_mae: 4.5325\n",
      "Epoch 896/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 29.2400 - mae: 3.9330 - val_loss: 49.6877 - val_mae: 5.6966\n",
      "Epoch 897/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 28.5286 - mae: 3.9944 - val_loss: 41.6231 - val_mae: 5.1468\n",
      "Epoch 898/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 28.6619 - mae: 4.0977 - val_loss: 45.8294 - val_mae: 5.4599\n",
      "Epoch 899/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 32.7794 - mae: 4.3201 - val_loss: 64.6026 - val_mae: 6.2880\n",
      "Epoch 900/1000\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 27.3768 - mae: 3.9655 - val_loss: 37.6922 - val_mae: 4.7374\n",
      "Epoch 901/1000\n",
      "515/515 [==============================] - 0s 193us/sample - loss: 29.5980 - mae: 4.0679 - val_loss: 40.6951 - val_mae: 4.7515\n",
      "Epoch 902/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 26.4742 - mae: 3.8273 - val_loss: 76.9619 - val_mae: 7.2864\n",
      "Epoch 903/1000\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 28.5889 - mae: 3.9449 - val_loss: 41.7149 - val_mae: 5.1199\n",
      "Epoch 904/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 28.2645 - mae: 3.9365 - val_loss: 40.3660 - val_mae: 4.9853\n",
      "Epoch 905/1000\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 28.1362 - mae: 4.0153 - val_loss: 35.3633 - val_mae: 4.4325\n",
      "Epoch 906/1000\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 29.0098 - mae: 3.9891 - val_loss: 37.5483 - val_mae: 4.7344\n",
      "Epoch 907/1000\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 27.6301 - mae: 3.9588 - val_loss: 45.1561 - val_mae: 5.0240\n",
      "Epoch 908/1000\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 28.6042 - mae: 4.0112 - val_loss: 36.9431 - val_mae: 4.5557\n",
      "Epoch 909/1000\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 26.2748 - mae: 3.8214 - val_loss: 88.0459 - val_mae: 7.7071\n",
      "Epoch 910/1000\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 28.2649 - mae: 4.0896 - val_loss: 77.1959 - val_mae: 7.3092\n",
      "Epoch 911/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 25.6890 - mae: 3.8202 - val_loss: 42.7491 - val_mae: 4.9062\n",
      "Epoch 912/1000\n",
      "515/515 [==============================] - 0s 272us/sample - loss: 26.8907 - mae: 3.8380 - val_loss: 63.4656 - val_mae: 6.7497\n",
      "Epoch 913/1000\n",
      "515/515 [==============================] - 0s 279us/sample - loss: 28.7986 - mae: 4.0200 - val_loss: 44.6723 - val_mae: 5.2711\n",
      "Epoch 914/1000\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 27.4967 - mae: 3.9849 - val_loss: 37.5411 - val_mae: 4.5137\n",
      "Epoch 915/1000\n",
      "515/515 [==============================] - 0s 228us/sample - loss: 27.0546 - mae: 3.8661 - val_loss: 60.8401 - val_mae: 6.2168\n",
      "Epoch 916/1000\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 30.0740 - mae: 4.1397 - val_loss: 42.0104 - val_mae: 5.0599\n",
      "Epoch 917/1000\n",
      "515/515 [==============================] - 0s 466us/sample - loss: 28.1420 - mae: 3.9944 - val_loss: 46.0404 - val_mae: 5.4635\n",
      "Epoch 918/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 29.4925 - mae: 4.0353 - val_loss: 38.0392 - val_mae: 4.4601\n",
      "Epoch 919/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 28.2902 - mae: 4.0269 - val_loss: 51.8727 - val_mae: 5.4548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 920/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 29.6725 - mae: 4.0995 - val_loss: 64.6298 - val_mae: 6.6946\n",
      "Epoch 921/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 27.2728 - mae: 3.8636 - val_loss: 40.5871 - val_mae: 5.0219\n",
      "Epoch 922/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 27.6409 - mae: 3.8939 - val_loss: 37.7984 - val_mae: 4.5617\n",
      "Epoch 923/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 30.1857 - mae: 4.1619 - val_loss: 52.3469 - val_mae: 5.9936\n",
      "Epoch 924/1000\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 25.4708 - mae: 3.7682 - val_loss: 38.1428 - val_mae: 4.6628\n",
      "Epoch 925/1000\n",
      "515/515 [==============================] - 0s 298us/sample - loss: 28.0235 - mae: 3.9183 - val_loss: 36.4453 - val_mae: 4.5493\n",
      "Epoch 926/1000\n",
      "515/515 [==============================] - 0s 318us/sample - loss: 27.9789 - mae: 3.8880 - val_loss: 40.8741 - val_mae: 4.7960\n",
      "Epoch 927/1000\n",
      "515/515 [==============================] - 0s 357us/sample - loss: 28.5317 - mae: 4.0578 - val_loss: 39.9967 - val_mae: 4.7092\n",
      "Epoch 928/1000\n",
      "515/515 [==============================] - 0s 448us/sample - loss: 28.4642 - mae: 4.0349 - val_loss: 44.0032 - val_mae: 5.2579\n",
      "Epoch 929/1000\n",
      "515/515 [==============================] - 0s 278us/sample - loss: 26.2163 - mae: 3.9507 - val_loss: 53.8344 - val_mae: 5.5425\n",
      "Epoch 930/1000\n",
      "515/515 [==============================] - 0s 277us/sample - loss: 28.2456 - mae: 4.0486 - val_loss: 37.8589 - val_mae: 4.5712\n",
      "Epoch 931/1000\n",
      "515/515 [==============================] - 0s 328us/sample - loss: 27.3106 - mae: 3.8334 - val_loss: 43.1438 - val_mae: 5.2393\n",
      "Epoch 932/1000\n",
      "515/515 [==============================] - 0s 263us/sample - loss: 29.2689 - mae: 4.0879 - val_loss: 36.5437 - val_mae: 4.3814\n",
      "Epoch 933/1000\n",
      "515/515 [==============================] - 0s 282us/sample - loss: 24.6777 - mae: 3.7774 - val_loss: 100.5893 - val_mae: 8.1656\n",
      "Epoch 934/1000\n",
      "515/515 [==============================] - 0s 332us/sample - loss: 29.7097 - mae: 4.0555 - val_loss: 64.8929 - val_mae: 6.7324\n",
      "Epoch 935/1000\n",
      "515/515 [==============================] - 0s 386us/sample - loss: 26.4010 - mae: 3.8438 - val_loss: 47.6013 - val_mae: 5.5890\n",
      "Epoch 936/1000\n",
      "515/515 [==============================] - 0s 431us/sample - loss: 27.0287 - mae: 3.8694 - val_loss: 57.6402 - val_mae: 5.8294\n",
      "Epoch 937/1000\n",
      "515/515 [==============================] - 0s 376us/sample - loss: 29.6951 - mae: 4.1064 - val_loss: 43.9427 - val_mae: 5.1927\n",
      "Epoch 938/1000\n",
      "515/515 [==============================] - 0s 272us/sample - loss: 27.8896 - mae: 3.9092 - val_loss: 47.1840 - val_mae: 5.5719\n",
      "Epoch 939/1000\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 26.7094 - mae: 3.9294 - val_loss: 63.0000 - val_mae: 6.2173\n",
      "Epoch 940/1000\n",
      "515/515 [==============================] - 0s 263us/sample - loss: 26.4879 - mae: 3.9418 - val_loss: 57.8491 - val_mae: 6.2968\n",
      "Epoch 941/1000\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 28.9131 - mae: 4.1039 - val_loss: 76.3243 - val_mae: 6.9745\n",
      "Epoch 942/1000\n",
      "515/515 [==============================] - 0s 285us/sample - loss: 24.2289 - mae: 3.7039 - val_loss: 82.0545 - val_mae: 7.5173\n",
      "Epoch 943/1000\n",
      "515/515 [==============================] - 0s 445us/sample - loss: 26.8829 - mae: 3.9243 - val_loss: 41.9915 - val_mae: 4.7955\n",
      "Epoch 944/1000\n",
      "515/515 [==============================] - 0s 273us/sample - loss: 29.5654 - mae: 4.0886 - val_loss: 37.1190 - val_mae: 4.5062\n",
      "Epoch 945/1000\n",
      "515/515 [==============================] - 0s 244us/sample - loss: 26.2309 - mae: 3.8497 - val_loss: 53.1131 - val_mae: 5.6055\n",
      "Epoch 946/1000\n",
      "515/515 [==============================] - ETA: 0s - loss: 26.4704 - mae: 4.01 - 0s 363us/sample - loss: 29.0130 - mae: 4.1420 - val_loss: 39.0519 - val_mae: 4.5443\n",
      "Epoch 947/1000\n",
      "515/515 [==============================] - 0s 297us/sample - loss: 26.3688 - mae: 3.8512 - val_loss: 36.9849 - val_mae: 4.6739\n",
      "Epoch 948/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 28.8656 - mae: 3.9955 - val_loss: 49.2552 - val_mae: 5.2731\n",
      "Epoch 949/1000\n",
      "515/515 [==============================] - 0s 484us/sample - loss: 29.0305 - mae: 4.0671 - val_loss: 55.3639 - val_mae: 5.5663\n",
      "Epoch 950/1000\n",
      "515/515 [==============================] - 0s 304us/sample - loss: 29.1296 - mae: 4.0333 - val_loss: 67.7242 - val_mae: 6.5220\n",
      "Epoch 951/1000\n",
      "515/515 [==============================] - 0s 420us/sample - loss: 29.5355 - mae: 4.1105 - val_loss: 36.9768 - val_mae: 4.4296\n",
      "Epoch 952/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 27.0156 - mae: 3.8419 - val_loss: 45.7466 - val_mae: 5.4499\n",
      "Epoch 953/1000\n",
      "515/515 [==============================] - 0s 493us/sample - loss: 25.9482 - mae: 3.7735 - val_loss: 116.6867 - val_mae: 9.1408\n",
      "Epoch 954/1000\n",
      "515/515 [==============================] - 0s 423us/sample - loss: 32.7339 - mae: 4.1342 - val_loss: 39.5397 - val_mae: 4.9268\n",
      "Epoch 955/1000\n",
      "515/515 [==============================] - 0s 419us/sample - loss: 27.1175 - mae: 3.9268 - val_loss: 36.2837 - val_mae: 4.5275\n",
      "Epoch 956/1000\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 22.7769 - mae: 3.5393 - val_loss: 66.2589 - val_mae: 6.8753\n",
      "Epoch 957/1000\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 30.0297 - mae: 4.1645 - val_loss: 38.1388 - val_mae: 4.8379\n",
      "Epoch 958/1000\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 27.2713 - mae: 3.8980 - val_loss: 36.6982 - val_mae: 4.5452\n",
      "Epoch 959/1000\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 26.5924 - mae: 3.7686 - val_loss: 40.0224 - val_mae: 4.9108\n",
      "Epoch 960/1000\n",
      "515/515 [==============================] - 0s 289us/sample - loss: 27.0991 - mae: 3.9485 - val_loss: 44.3739 - val_mae: 5.1528\n",
      "Epoch 961/1000\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 28.0318 - mae: 3.9484 - val_loss: 83.8962 - val_mae: 7.2251\n",
      "Epoch 962/1000\n",
      "515/515 [==============================] - 0s 406us/sample - loss: 31.1177 - mae: 4.1712 - val_loss: 41.7509 - val_mae: 4.6754\n",
      "Epoch 963/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 26.3008 - mae: 3.8922 - val_loss: 58.3335 - val_mae: 5.9678\n",
      "Epoch 964/1000\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 28.0400 - mae: 4.0013 - val_loss: 42.3507 - val_mae: 5.1196\n",
      "Epoch 965/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 29.4476 - mae: 4.0171 - val_loss: 45.6700 - val_mae: 5.3322\n",
      "Epoch 966/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 26.8916 - mae: 3.9143 - val_loss: 44.9223 - val_mae: 4.9479\n",
      "Epoch 967/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 27.7934 - mae: 3.9913 - val_loss: 69.3080 - val_mae: 6.9855\n",
      "Epoch 968/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 28.2301 - mae: 3.9265 - val_loss: 67.1474 - val_mae: 6.3276\n",
      "Epoch 969/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 28.2859 - mae: 4.0560 - val_loss: 40.0254 - val_mae: 4.9648\n",
      "Epoch 970/1000\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 30.4667 - mae: 4.0754 - val_loss: 43.4671 - val_mae: 4.8894\n",
      "Epoch 971/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 24.2046 - mae: 3.6865 - val_loss: 95.2513 - val_mae: 7.6633\n",
      "Epoch 972/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 28.0122 - mae: 3.9071 - val_loss: 45.8532 - val_mae: 5.4530\n",
      "Epoch 973/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 27.4379 - mae: 3.9195 - val_loss: 101.1060 - val_mae: 8.0957\n",
      "Epoch 974/1000\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 26.4053 - mae: 3.8315 - val_loss: 95.3615 - val_mae: 8.1486\n",
      "Epoch 975/1000\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 30.7207 - mae: 4.1232 - val_loss: 36.9602 - val_mae: 4.6376\n",
      "Epoch 976/1000\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 24.9129 - mae: 3.7372 - val_loss: 63.0586 - val_mae: 6.7125\n",
      "Epoch 977/1000\n",
      "515/515 [==============================] - 0s 272us/sample - loss: 29.0143 - mae: 4.0592 - val_loss: 39.4942 - val_mae: 4.5280\n",
      "Epoch 978/1000\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 25.7527 - mae: 3.6649 - val_loss: 43.3010 - val_mae: 5.1875\n",
      "Epoch 979/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 27.3512 - mae: 3.9359 - val_loss: 43.2481 - val_mae: 5.2008\n",
      "Epoch 980/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 26.9610 - mae: 3.9316 - val_loss: 139.2534 - val_mae: 9.7436\n",
      "Epoch 981/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 30.9946 - mae: 4.0075 - val_loss: 48.4450 - val_mae: 5.2251\n",
      "Epoch 982/1000\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 27.8510 - mae: 3.9132 - val_loss: 39.7926 - val_mae: 4.7746\n",
      "Epoch 983/1000\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 27.3807 - mae: 3.8615 - val_loss: 49.3769 - val_mae: 5.7954\n",
      "Epoch 984/1000\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 27.5876 - mae: 3.9546 - val_loss: 40.6562 - val_mae: 4.5995\n",
      "Epoch 985/1000\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 26.4056 - mae: 3.8108 - val_loss: 51.3697 - val_mae: 5.8534\n",
      "Epoch 986/1000\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 28.4853 - mae: 4.0203 - val_loss: 39.2921 - val_mae: 4.6679\n",
      "Epoch 987/1000\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 24.2891 - mae: 3.7613 - val_loss: 56.9285 - val_mae: 6.2631\n",
      "Epoch 988/1000\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 28.7256 - mae: 4.0635 - val_loss: 35.6944 - val_mae: 4.3811\n",
      "Epoch 989/1000\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 28.3637 - mae: 3.9461 - val_loss: 57.5595 - val_mae: 5.8767\n",
      "Epoch 990/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 25.7685 - mae: 3.8204 - val_loss: 37.2593 - val_mae: 4.5041\n",
      "Epoch 991/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 24.3824 - mae: 3.7881 - val_loss: 63.3532 - val_mae: 6.3115\n",
      "Epoch 992/1000\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 27.1702 - mae: 3.8712 - val_loss: 39.4614 - val_mae: 4.6957\n",
      "Epoch 993/1000\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 25.9150 - mae: 3.8706 - val_loss: 92.5533 - val_mae: 8.0173\n",
      "Epoch 994/1000\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 28.3559 - mae: 4.0064 - val_loss: 76.5518 - val_mae: 7.3214\n",
      "Epoch 995/1000\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 25.8694 - mae: 3.8253 - val_loss: 77.9594 - val_mae: 7.2952\n",
      "Epoch 996/1000\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 25.6563 - mae: 3.7040 - val_loss: 36.6483 - val_mae: 4.6225\n",
      "Epoch 997/1000\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 28.7038 - mae: 4.0685 - val_loss: 34.9375 - val_mae: 4.3598\n",
      "Epoch 998/1000\n",
      "515/515 [==============================] - 0s 253us/sample - loss: 26.8601 - mae: 3.8374 - val_loss: 39.8130 - val_mae: 4.7133\n",
      "Epoch 999/1000\n",
      "515/515 [==============================] - 0s 284us/sample - loss: 25.5020 - mae: 3.7756 - val_loss: 41.5890 - val_mae: 5.0759\n",
      "Epoch 1000/1000\n",
      "515/515 [==============================] - 0s 234us/sample - loss: 27.5480 - mae: 4.0107 - val_loss: 42.0166 - val_mae: 4.7644\n",
      "309/1 - 0s - loss: 38.2417 - mae: 5.1138\n",
      "\n",
      "47.30433426397132\n",
      "5.113768\n"
     ]
    }
   ],
   "source": [
    "models = tf.keras.models.Sequential\n",
    "layers = tf.keras.layers\n",
    "\n",
    "model = models([layers.Dense(64,input_shape = (input_shape,)),\n",
    "                layers.Dense(64,activation=\"relu\"),\n",
    "                layers.Dense(6,activation=\"relu\"), # tanh\n",
    "                layers.Dense(1)])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", # adam\n",
    "             loss=\"mse\",\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=1000,validation_data=(x_val,y_val))\n",
    "\n",
    "evaluation = model.evaluate(x_test,y_test,verbose=2)\n",
    "print()\n",
    "print(evaluation[0])\n",
    "print(evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['mae']\n",
    "val_acc = history.history['val_mae']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation mae')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('mae')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 47.30433426397132\n",
      "Mean Square Error 5.113768\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss :\",evaluation[0])\n",
    "print(\"Mean Square Error\",evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_model(epochs,drop):\n",
    "    print()\n",
    "    models = tf.keras.models.Sequential\n",
    "    layers = tf.keras.layers\n",
    "\n",
    "    model2 = models([layers.Dense(64,input_shape = (8,)),\n",
    "                     layers.Dropout(drop),\n",
    "                     layers.Dense(64,activation=\"relu\"),\n",
    "                     layers.Dense(64,activation=\"relu\"),\n",
    "                     layers.Dropout(drop),\n",
    "                     layers.Dense(1)])\n",
    "    model2.compile(optimizer=\"adam\", # rmsprop # adam # \n",
    "             loss=\"mse\", # binary_crossentropy\n",
    "              metrics=[\"mae\"])\n",
    "    history = model2.fit(x_train,y_train,epochs=epochs,validation_data=(x_val,y_val))\n",
    "    print()\n",
    "    evaluation = model2.evaluate(x_test,y_test,verbose=2)\n",
    "    print()\n",
    "    print(evaluation[0])\n",
    "    print(evaluation[1])\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    acc = history.history['mae']\n",
    "    val_acc = history.history['val_mae']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation mae')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "    print(evaluation[0])\n",
    "    print(evaluation[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train on 515 samples, validate on 206 samples\n",
      "Epoch 1/500\n",
      "515/515 [==============================] - 1s 2ms/sample - loss: 1478.0973 - mae: 34.6782 - val_loss: 1351.7363 - val_mae: 32.1450\n",
      "Epoch 2/500\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 1155.5303 - mae: 29.5885 - val_loss: 857.0885 - val_mae: 23.6896\n",
      "Epoch 3/500\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 544.0969 - mae: 18.5951 - val_loss: 340.4365 - val_mae: 15.0438\n",
      "Epoch 4/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 318.0028 - mae: 14.6579 - val_loss: 339.6172 - val_mae: 15.1479\n",
      "Epoch 5/500\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 298.7503 - mae: 14.0989 - val_loss: 325.6412 - val_mae: 14.6640\n",
      "Epoch 6/500\n",
      "515/515 [==============================] - 0s 316us/sample - loss: 288.7707 - mae: 13.8407 - val_loss: 317.7210 - val_mae: 14.5235\n",
      "Epoch 7/500\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 274.7020 - mae: 13.5929 - val_loss: 309.2813 - val_mae: 14.2885\n",
      "Epoch 8/500\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 269.6677 - mae: 13.3703 - val_loss: 304.1092 - val_mae: 14.1141\n",
      "Epoch 9/500\n",
      "515/515 [==============================] - 0s 291us/sample - loss: 264.1832 - mae: 13.3563 - val_loss: 296.3634 - val_mae: 13.9868\n",
      "Epoch 10/500\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 259.7217 - mae: 13.2632 - val_loss: 287.9674 - val_mae: 13.7256\n",
      "Epoch 11/500\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 251.5879 - mae: 12.9454 - val_loss: 280.6471 - val_mae: 13.5817\n",
      "Epoch 12/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 242.5704 - mae: 12.7958 - val_loss: 271.3733 - val_mae: 13.2985\n",
      "Epoch 13/500\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 232.5620 - mae: 12.6126 - val_loss: 265.0373 - val_mae: 13.1163\n",
      "Epoch 14/500\n",
      "515/515 [==============================] - 0s 289us/sample - loss: 224.8075 - mae: 12.3543 - val_loss: 259.3702 - val_mae: 12.9415\n",
      "Epoch 15/500\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 219.7136 - mae: 12.3026 - val_loss: 251.7669 - val_mae: 12.8640\n",
      "Epoch 16/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 216.5986 - mae: 12.2040 - val_loss: 247.2381 - val_mae: 12.6370\n",
      "Epoch 17/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 206.2743 - mae: 11.9700 - val_loss: 240.6392 - val_mae: 12.5191\n",
      "Epoch 18/500\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 201.4939 - mae: 11.8302 - val_loss: 237.4292 - val_mae: 12.3831\n",
      "Epoch 19/500\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 199.1258 - mae: 11.7525 - val_loss: 232.4253 - val_mae: 12.2851\n",
      "Epoch 20/500\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 201.6766 - mae: 11.8626 - val_loss: 229.6696 - val_mae: 12.1806\n",
      "Epoch 21/500\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 189.9710 - mae: 11.4752 - val_loss: 226.3488 - val_mae: 12.0866\n",
      "Epoch 22/500\n",
      "515/515 [==============================] - 0s 186us/sample - loss: 190.0899 - mae: 11.5252 - val_loss: 226.4793 - val_mae: 12.0115\n",
      "Epoch 23/500\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 183.8897 - mae: 11.2970 - val_loss: 218.4209 - val_mae: 11.9205\n",
      "Epoch 24/500\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 182.6011 - mae: 11.2182 - val_loss: 214.2928 - val_mae: 11.7882\n",
      "Epoch 25/500\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 177.3665 - mae: 11.0961 - val_loss: 209.9691 - val_mae: 11.6726\n",
      "Epoch 26/500\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 170.8995 - mae: 10.8463 - val_loss: 205.9539 - val_mae: 11.5519\n",
      "Epoch 27/500\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 169.9571 - mae: 10.7509 - val_loss: 201.9962 - val_mae: 11.4478\n",
      "Epoch 28/500\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 168.5263 - mae: 10.7462 - val_loss: 198.3331 - val_mae: 11.3161\n",
      "Epoch 29/500\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 157.8065 - mae: 10.5057 - val_loss: 194.3514 - val_mae: 11.1948\n",
      "Epoch 30/500\n",
      "515/515 [==============================] - 0s 266us/sample - loss: 156.3082 - mae: 10.3567 - val_loss: 190.2601 - val_mae: 11.1140\n",
      "Epoch 31/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 153.8285 - mae: 10.3171 - val_loss: 190.1340 - val_mae: 10.9977\n",
      "Epoch 32/500\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 163.8137 - mae: 10.5396 - val_loss: 184.4474 - val_mae: 10.9644\n",
      "Epoch 33/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 151.5375 - mae: 10.1813 - val_loss: 190.3816 - val_mae: 11.2852\n",
      "Epoch 34/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 147.7021 - mae: 10.0027 - val_loss: 176.5482 - val_mae: 10.6883\n",
      "Epoch 35/500\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 142.1047 - mae: 9.8193 - val_loss: 172.2476 - val_mae: 10.5307\n",
      "Epoch 36/500\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 133.3014 - mae: 9.5281 - val_loss: 169.8733 - val_mae: 10.4024\n",
      "Epoch 37/500\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 135.3788 - mae: 9.4740 - val_loss: 166.0875 - val_mae: 10.3613\n",
      "Epoch 38/500\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 135.5727 - mae: 9.5025 - val_loss: 161.7354 - val_mae: 10.1586\n",
      "Epoch 39/500\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 124.2312 - mae: 9.0925 - val_loss: 158.2911 - val_mae: 10.0266\n",
      "Epoch 40/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 128.0492 - mae: 9.2091 - val_loss: 159.0988 - val_mae: 10.0904\n",
      "Epoch 41/500\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 126.3166 - mae: 9.1462 - val_loss: 154.5697 - val_mae: 9.9320\n",
      "Epoch 42/500\n",
      "515/515 [==============================] - 0s 274us/sample - loss: 119.5931 - mae: 8.8772 - val_loss: 152.4111 - val_mae: 9.8710\n",
      "Epoch 43/500\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 119.1622 - mae: 8.8894 - val_loss: 146.2677 - val_mae: 9.6450\n",
      "Epoch 44/500\n",
      "515/515 [==============================] - 0s 293us/sample - loss: 128.8141 - mae: 9.2080 - val_loss: 149.7458 - val_mae: 9.8206\n",
      "Epoch 45/500\n",
      "515/515 [==============================] - 0s 293us/sample - loss: 119.1797 - mae: 8.8646 - val_loss: 146.2148 - val_mae: 9.6800\n",
      "Epoch 46/500\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 119.9262 - mae: 8.9162 - val_loss: 141.7062 - val_mae: 9.5197\n",
      "Epoch 47/500\n",
      "515/515 [==============================] - 0s 278us/sample - loss: 114.6637 - mae: 8.6054 - val_loss: 149.5037 - val_mae: 9.8977\n",
      "Epoch 48/500\n",
      "515/515 [==============================] - 0s 303us/sample - loss: 113.7874 - mae: 8.6132 - val_loss: 137.5485 - val_mae: 9.3489\n",
      "Epoch 49/500\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 110.8672 - mae: 8.5023 - val_loss: 143.1415 - val_mae: 9.5797\n",
      "Epoch 50/500\n",
      "515/515 [==============================] - 0s 305us/sample - loss: 125.4497 - mae: 9.0847 - val_loss: 135.6531 - val_mae: 9.3439\n",
      "Epoch 51/500\n",
      "515/515 [==============================] - 0s 310us/sample - loss: 114.3385 - mae: 8.6376 - val_loss: 138.6304 - val_mae: 9.4736\n",
      "Epoch 52/500\n",
      "515/515 [==============================] - 0s 293us/sample - loss: 126.6928 - mae: 9.0885 - val_loss: 133.5641 - val_mae: 9.2484\n",
      "Epoch 53/500\n",
      "515/515 [==============================] - 0s 338us/sample - loss: 109.5201 - mae: 8.3743 - val_loss: 131.1101 - val_mae: 9.1401\n",
      "Epoch 54/500\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 111.3242 - mae: 8.4490 - val_loss: 131.3823 - val_mae: 9.1515\n",
      "Epoch 55/500\n",
      "515/515 [==============================] - 0s 279us/sample - loss: 121.7535 - mae: 8.8416 - val_loss: 134.5520 - val_mae: 9.3076\n",
      "Epoch 56/500\n",
      "515/515 [==============================] - 0s 283us/sample - loss: 107.1958 - mae: 8.3593 - val_loss: 131.5324 - val_mae: 9.1920\n",
      "Epoch 57/500\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 112.8951 - mae: 8.4966 - val_loss: 131.5259 - val_mae: 9.2097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 111.8472 - mae: 8.4354 - val_loss: 129.0010 - val_mae: 9.0900\n",
      "Epoch 59/500\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 110.9560 - mae: 8.3749 - val_loss: 127.6058 - val_mae: 9.0105\n",
      "Epoch 60/500\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 106.3798 - mae: 8.1642 - val_loss: 132.8748 - val_mae: 9.2259\n",
      "Epoch 61/500\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 106.4250 - mae: 8.2774 - val_loss: 126.6526 - val_mae: 8.9621\n",
      "Epoch 62/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 103.8367 - mae: 8.1070 - val_loss: 126.8690 - val_mae: 8.9515\n",
      "Epoch 63/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 109.5880 - mae: 8.2808 - val_loss: 127.4850 - val_mae: 8.9860\n",
      "Epoch 64/500\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 108.8545 - mae: 8.2243 - val_loss: 140.7738 - val_mae: 9.5408\n",
      "Epoch 65/500\n",
      "515/515 [==============================] - 0s 260us/sample - loss: 112.7726 - mae: 8.4590 - val_loss: 134.5009 - val_mae: 9.3157\n",
      "Epoch 66/500\n",
      "515/515 [==============================] - 0s 285us/sample - loss: 107.8668 - mae: 8.2628 - val_loss: 127.0502 - val_mae: 8.9702\n",
      "Epoch 67/500\n",
      "515/515 [==============================] - 0s 612us/sample - loss: 110.0632 - mae: 8.1819 - val_loss: 124.8104 - val_mae: 8.8925\n",
      "Epoch 68/500\n",
      "515/515 [==============================] - 0s 549us/sample - loss: 109.4658 - mae: 8.2464 - val_loss: 127.8759 - val_mae: 9.0630\n",
      "Epoch 69/500\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 108.4145 - mae: 8.2123 - val_loss: 131.5069 - val_mae: 9.1661\n",
      "Epoch 70/500\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 110.5627 - mae: 8.2952 - val_loss: 129.6606 - val_mae: 9.1187\n",
      "Epoch 71/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 109.2910 - mae: 8.2296 - val_loss: 141.3801 - val_mae: 9.5172\n",
      "Epoch 72/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 119.9574 - mae: 8.8015 - val_loss: 137.2008 - val_mae: 9.4023\n",
      "Epoch 73/500\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 119.1558 - mae: 8.7947 - val_loss: 124.3437 - val_mae: 8.9143\n",
      "Epoch 74/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 110.9484 - mae: 8.3257 - val_loss: 123.5275 - val_mae: 8.8458\n",
      "Epoch 75/500\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 111.3315 - mae: 8.3528 - val_loss: 129.8196 - val_mae: 9.0951\n",
      "Epoch 76/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 117.1601 - mae: 8.5032 - val_loss: 122.0227 - val_mae: 8.7868\n",
      "Epoch 77/500\n",
      "515/515 [==============================] - 0s 260us/sample - loss: 107.3664 - mae: 8.1669 - val_loss: 125.9772 - val_mae: 8.9752\n",
      "Epoch 78/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 103.3764 - mae: 7.9749 - val_loss: 130.4023 - val_mae: 9.1386\n",
      "Epoch 79/500\n",
      "515/515 [==============================] - 0s 232us/sample - loss: 107.4668 - mae: 8.1428 - val_loss: 124.9557 - val_mae: 8.9349\n",
      "Epoch 80/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 99.7904 - mae: 7.7861 - val_loss: 131.3658 - val_mae: 9.2002\n",
      "Epoch 81/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 108.5894 - mae: 8.3501 - val_loss: 120.3854 - val_mae: 8.7422\n",
      "Epoch 82/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 105.3523 - mae: 7.9854 - val_loss: 119.2740 - val_mae: 8.7001\n",
      "Epoch 83/500\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 103.2110 - mae: 7.9949 - val_loss: 117.5938 - val_mae: 8.6382\n",
      "Epoch 84/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 99.6910 - mae: 7.8093 - val_loss: 118.1419 - val_mae: 8.6612\n",
      "Epoch 85/500\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 101.2984 - mae: 7.9644 - val_loss: 115.6198 - val_mae: 8.5565\n",
      "Epoch 86/500\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 100.5547 - mae: 7.7510 - val_loss: 114.3975 - val_mae: 8.5039\n",
      "Epoch 87/500\n",
      "515/515 [==============================] - 0s 311us/sample - loss: 95.5692 - mae: 7.5924 - val_loss: 113.9095 - val_mae: 8.4966\n",
      "Epoch 88/500\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 95.9112 - mae: 7.6467 - val_loss: 114.9020 - val_mae: 8.5378\n",
      "Epoch 89/500\n",
      "515/515 [==============================] - 0s 260us/sample - loss: 95.5509 - mae: 7.6695 - val_loss: 113.4068 - val_mae: 8.4465\n",
      "Epoch 90/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 95.1721 - mae: 7.6981 - val_loss: 113.1627 - val_mae: 8.4632\n",
      "Epoch 91/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 93.1886 - mae: 7.5882 - val_loss: 116.8862 - val_mae: 8.6133\n",
      "Epoch 92/500\n",
      "515/515 [==============================] - 0s 249us/sample - loss: 96.8966 - mae: 7.7936 - val_loss: 114.5797 - val_mae: 8.5247\n",
      "Epoch 93/500\n",
      "515/515 [==============================] - 0s 255us/sample - loss: 101.2019 - mae: 7.9472 - val_loss: 109.9003 - val_mae: 8.3436\n",
      "Epoch 94/500\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 92.9943 - mae: 7.5207 - val_loss: 106.9121 - val_mae: 8.1902\n",
      "Epoch 95/500\n",
      "515/515 [==============================] - 0s 266us/sample - loss: 91.9532 - mae: 7.3332 - val_loss: 111.3835 - val_mae: 8.3933\n",
      "Epoch 96/500\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 90.9029 - mae: 7.5113 - val_loss: 108.8415 - val_mae: 8.3174\n",
      "Epoch 97/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 91.6151 - mae: 7.4728 - val_loss: 109.8624 - val_mae: 8.3729\n",
      "Epoch 98/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 91.6465 - mae: 7.4263 - val_loss: 105.1267 - val_mae: 8.1428\n",
      "Epoch 99/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 93.7276 - mae: 7.4806 - val_loss: 103.6966 - val_mae: 8.0728\n",
      "Epoch 100/500\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 89.9694 - mae: 7.3364 - val_loss: 107.4681 - val_mae: 8.2438\n",
      "Epoch 101/500\n",
      "515/515 [==============================] - 0s 240us/sample - loss: 89.6255 - mae: 7.3350 - val_loss: 101.7901 - val_mae: 8.0149\n",
      "Epoch 102/500\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 84.5395 - mae: 7.0505 - val_loss: 99.9570 - val_mae: 7.9401\n",
      "Epoch 103/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 88.7470 - mae: 7.2141 - val_loss: 110.7080 - val_mae: 8.3997\n",
      "Epoch 104/500\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 93.3082 - mae: 7.5374 - val_loss: 104.1444 - val_mae: 8.1699\n",
      "Epoch 105/500\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 85.4776 - mae: 7.1308 - val_loss: 100.6013 - val_mae: 7.9083\n",
      "Epoch 106/500\n",
      "515/515 [==============================] - 0s 220us/sample - loss: 81.9216 - mae: 6.9595 - val_loss: 96.4747 - val_mae: 7.7784\n",
      "Epoch 107/500\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 83.4926 - mae: 6.9856 - val_loss: 95.2484 - val_mae: 7.6997\n",
      "Epoch 108/500\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 84.5483 - mae: 7.1159 - val_loss: 97.1747 - val_mae: 7.7759\n",
      "Epoch 109/500\n",
      "515/515 [==============================] - 0s 289us/sample - loss: 81.9068 - mae: 7.0016 - val_loss: 95.0669 - val_mae: 7.7022\n",
      "Epoch 110/500\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 80.9587 - mae: 6.9051 - val_loss: 96.5615 - val_mae: 7.7024\n",
      "Epoch 111/500\n",
      "515/515 [==============================] - 0s 260us/sample - loss: 80.4152 - mae: 6.9391 - val_loss: 93.4003 - val_mae: 7.6496\n",
      "Epoch 112/500\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 80.6682 - mae: 6.8243 - val_loss: 89.4532 - val_mae: 7.4006\n",
      "Epoch 113/500\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 84.5764 - mae: 7.0259 - val_loss: 93.2780 - val_mae: 7.6619\n",
      "Epoch 114/500\n",
      "515/515 [==============================] - 0s 283us/sample - loss: 83.3222 - mae: 7.0966 - val_loss: 90.7519 - val_mae: 7.4803\n",
      "Epoch 115/500\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 78.7974 - mae: 6.7410 - val_loss: 100.9125 - val_mae: 7.7601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 81.4729 - mae: 7.0205 - val_loss: 89.5052 - val_mae: 7.4474\n",
      "Epoch 117/500\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 82.5082 - mae: 6.9832 - val_loss: 86.3633 - val_mae: 7.2820\n",
      "Epoch 118/500\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 76.7810 - mae: 6.7530 - val_loss: 91.1400 - val_mae: 7.4447\n",
      "Epoch 119/500\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 75.4104 - mae: 6.6175 - val_loss: 87.8266 - val_mae: 7.4088\n",
      "Epoch 120/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 77.7160 - mae: 6.7994 - val_loss: 87.3666 - val_mae: 7.3960\n",
      "Epoch 121/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 76.9704 - mae: 6.7362 - val_loss: 89.2044 - val_mae: 7.3478\n",
      "Epoch 122/500\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 76.1012 - mae: 6.6325 - val_loss: 87.8762 - val_mae: 7.4793\n",
      "Epoch 123/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 78.5031 - mae: 6.7671 - val_loss: 83.2705 - val_mae: 7.1826\n",
      "Epoch 124/500\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 78.3660 - mae: 6.7789 - val_loss: 86.1052 - val_mae: 7.4012\n",
      "Epoch 125/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 71.4087 - mae: 6.4272 - val_loss: 82.4604 - val_mae: 7.0642\n",
      "Epoch 126/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 72.9241 - mae: 6.5528 - val_loss: 80.3622 - val_mae: 7.0148\n",
      "Epoch 127/500\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 78.1560 - mae: 6.7512 - val_loss: 88.8732 - val_mae: 7.5979\n",
      "Epoch 128/500\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 75.1981 - mae: 6.6732 - val_loss: 82.2776 - val_mae: 7.1515\n",
      "Epoch 129/500\n",
      "515/515 [==============================] - 0s 234us/sample - loss: 74.9491 - mae: 6.5115 - val_loss: 80.8696 - val_mae: 6.9677\n",
      "Epoch 130/500\n",
      "515/515 [==============================] - 0s 232us/sample - loss: 73.8595 - mae: 6.4940 - val_loss: 81.0604 - val_mae: 7.0928\n",
      "Epoch 131/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 72.1846 - mae: 6.4737 - val_loss: 79.0548 - val_mae: 6.8881\n",
      "Epoch 132/500\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 74.5247 - mae: 6.4083 - val_loss: 87.4817 - val_mae: 7.2028\n",
      "Epoch 133/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 73.3010 - mae: 6.5243 - val_loss: 88.3391 - val_mae: 7.1913\n",
      "Epoch 134/500\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 71.0132 - mae: 6.3751 - val_loss: 81.8557 - val_mae: 7.2113\n",
      "Epoch 135/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 78.3737 - mae: 6.7692 - val_loss: 77.6351 - val_mae: 6.8555\n",
      "Epoch 136/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 76.3868 - mae: 6.8223 - val_loss: 86.4315 - val_mae: 7.0558\n",
      "Epoch 137/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 79.4409 - mae: 6.9567 - val_loss: 83.9435 - val_mae: 7.0421\n",
      "Epoch 138/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 73.2841 - mae: 6.4484 - val_loss: 91.3045 - val_mae: 7.3037\n",
      "Epoch 139/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 75.1330 - mae: 6.5015 - val_loss: 79.1903 - val_mae: 6.9679\n",
      "Epoch 140/500\n",
      "515/515 [==============================] - 0s 234us/sample - loss: 70.6217 - mae: 6.5055 - val_loss: 78.4148 - val_mae: 6.9842\n",
      "Epoch 141/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 71.4962 - mae: 6.4251 - val_loss: 76.0256 - val_mae: 6.8211\n",
      "Epoch 142/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 71.4469 - mae: 6.3250 - val_loss: 78.9791 - val_mae: 7.1184\n",
      "Epoch 143/500\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 71.5221 - mae: 6.4229 - val_loss: 81.8915 - val_mae: 7.3654\n",
      "Epoch 144/500\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 74.9549 - mae: 6.5439 - val_loss: 79.3227 - val_mae: 7.1411\n",
      "Epoch 145/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 75.3996 - mae: 6.7243 - val_loss: 77.0599 - val_mae: 6.6688\n",
      "Epoch 146/500\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 71.3426 - mae: 6.5358 - val_loss: 80.8658 - val_mae: 6.9303\n",
      "Epoch 147/500\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 71.7812 - mae: 6.4877 - val_loss: 75.4990 - val_mae: 6.7231\n",
      "Epoch 148/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 68.9500 - mae: 6.2185 - val_loss: 86.1790 - val_mae: 7.0418\n",
      "Epoch 149/500\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 67.4702 - mae: 6.2226 - val_loss: 74.5066 - val_mae: 6.5663\n",
      "Epoch 150/500\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 71.2428 - mae: 6.4356 - val_loss: 73.0689 - val_mae: 6.6516\n",
      "Epoch 151/500\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 70.3897 - mae: 6.4006 - val_loss: 72.2048 - val_mae: 6.4824\n",
      "Epoch 152/500\n",
      "515/515 [==============================] - 0s 180us/sample - loss: 71.7499 - mae: 6.3855 - val_loss: 76.6191 - val_mae: 6.7230\n",
      "Epoch 153/500\n",
      "515/515 [==============================] - 0s 184us/sample - loss: 66.1794 - mae: 6.1566 - val_loss: 73.2572 - val_mae: 6.7501\n",
      "Epoch 154/500\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 69.9129 - mae: 6.3692 - val_loss: 70.9214 - val_mae: 6.4976\n",
      "Epoch 155/500\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 65.2216 - mae: 6.1596 - val_loss: 72.8736 - val_mae: 6.7254\n",
      "Epoch 156/500\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 65.0589 - mae: 6.1609 - val_loss: 70.2249 - val_mae: 6.4878\n",
      "Epoch 157/500\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 69.1680 - mae: 6.2604 - val_loss: 68.6319 - val_mae: 6.3766\n",
      "Epoch 158/500\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 65.2472 - mae: 6.1041 - val_loss: 76.0788 - val_mae: 6.9799\n",
      "Epoch 159/500\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 69.6411 - mae: 6.3259 - val_loss: 70.9038 - val_mae: 6.4104\n",
      "Epoch 160/500\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 68.2971 - mae: 6.3746 - val_loss: 70.6996 - val_mae: 6.3131\n",
      "Epoch 161/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 65.0720 - mae: 6.0566 - val_loss: 78.2018 - val_mae: 6.6897\n",
      "Epoch 162/500\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 69.6083 - mae: 6.3555 - val_loss: 96.6604 - val_mae: 7.4596\n",
      "Epoch 163/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 71.1215 - mae: 6.3888 - val_loss: 81.7339 - val_mae: 6.7920\n",
      "Epoch 164/500\n",
      "515/515 [==============================] - 0s 222us/sample - loss: 69.0693 - mae: 6.3582 - val_loss: 78.7802 - val_mae: 6.6399\n",
      "Epoch 165/500\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 64.9393 - mae: 6.2190 - val_loss: 74.9751 - val_mae: 6.4491\n",
      "Epoch 166/500\n",
      "515/515 [==============================] - 0s 236us/sample - loss: 64.9230 - mae: 6.1677 - val_loss: 69.3890 - val_mae: 6.5009\n",
      "Epoch 167/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 66.3606 - mae: 6.1667 - val_loss: 71.3197 - val_mae: 6.7032\n",
      "Epoch 168/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 62.9781 - mae: 5.9992 - val_loss: 72.4865 - val_mae: 6.8276\n",
      "Epoch 169/500\n",
      "515/515 [==============================] - 0s 192us/sample - loss: 63.6777 - mae: 6.0515 - val_loss: 71.6274 - val_mae: 6.7835\n",
      "Epoch 170/500\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 65.6733 - mae: 6.0414 - val_loss: 68.1723 - val_mae: 6.3536\n",
      "Epoch 171/500\n",
      "515/515 [==============================] - 0s 194us/sample - loss: 64.2414 - mae: 6.0772 - val_loss: 67.9592 - val_mae: 6.4639\n",
      "Epoch 172/500\n",
      "515/515 [==============================] - 0s 188us/sample - loss: 66.7867 - mae: 6.1469 - val_loss: 66.3705 - val_mae: 6.3314\n",
      "Epoch 173/500\n",
      "515/515 [==============================] - 0s 189us/sample - loss: 66.0204 - mae: 6.2039 - val_loss: 67.3655 - val_mae: 6.3425\n",
      "Epoch 174/500\n",
      "515/515 [==============================] - 0s 190us/sample - loss: 64.9739 - mae: 6.1557 - val_loss: 66.8242 - val_mae: 6.3252\n",
      "Epoch 175/500\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 64.3336 - mae: 5.9656 - val_loss: 75.2776 - val_mae: 6.4273\n",
      "Epoch 176/500\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 66.3497 - mae: 6.1889 - val_loss: 70.1272 - val_mae: 6.1972\n",
      "Epoch 177/500\n",
      "515/515 [==============================] - 0s 207us/sample - loss: 61.9842 - mae: 6.0049 - val_loss: 66.0651 - val_mae: 6.1262\n",
      "Epoch 178/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 61.3841 - mae: 5.9366 - val_loss: 63.7299 - val_mae: 6.0314\n",
      "Epoch 179/500\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 67.7740 - mae: 6.2273 - val_loss: 64.4746 - val_mae: 6.2574\n",
      "Epoch 180/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 62.1767 - mae: 5.9881 - val_loss: 65.1369 - val_mae: 6.0303\n",
      "Epoch 181/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 62.1113 - mae: 6.0252 - val_loss: 69.1915 - val_mae: 6.1399\n",
      "Epoch 182/500\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 60.3608 - mae: 5.8767 - val_loss: 63.0730 - val_mae: 6.0644\n",
      "Epoch 183/500\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 61.0629 - mae: 5.9227 - val_loss: 64.2087 - val_mae: 6.1962\n",
      "Epoch 184/500\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 63.6054 - mae: 6.1013 - val_loss: 61.7050 - val_mae: 5.8925\n",
      "Epoch 185/500\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 62.1121 - mae: 5.9219 - val_loss: 63.0414 - val_mae: 6.0305\n",
      "Epoch 186/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 59.9131 - mae: 5.8994 - val_loss: 62.6811 - val_mae: 5.9778\n",
      "Epoch 187/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 58.4012 - mae: 5.7311 - val_loss: 61.0990 - val_mae: 6.0103\n",
      "Epoch 188/500\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 59.6625 - mae: 5.9078 - val_loss: 66.4584 - val_mae: 6.4165\n",
      "Epoch 189/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 65.6828 - mae: 6.2307 - val_loss: 62.0114 - val_mae: 6.1403\n",
      "Epoch 190/500\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 59.2556 - mae: 5.8108 - val_loss: 60.5863 - val_mae: 5.9610\n",
      "Epoch 191/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 58.5267 - mae: 5.7865 - val_loss: 64.0989 - val_mae: 5.9212\n",
      "Epoch 192/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 65.5209 - mae: 6.1869 - val_loss: 66.3256 - val_mae: 5.9652\n",
      "Epoch 193/500\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 58.1198 - mae: 5.7725 - val_loss: 65.4018 - val_mae: 5.9344\n",
      "Epoch 194/500\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 58.6807 - mae: 5.7893 - val_loss: 60.7543 - val_mae: 5.9400\n",
      "Epoch 195/500\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 59.5662 - mae: 5.7800 - val_loss: 61.7492 - val_mae: 5.8339\n",
      "Epoch 196/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 62.0640 - mae: 5.9490 - val_loss: 70.8881 - val_mae: 6.8484\n",
      "Epoch 197/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 67.5214 - mae: 6.3606 - val_loss: 64.6680 - val_mae: 6.4281\n",
      "Epoch 198/500\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 60.7771 - mae: 5.9188 - val_loss: 60.1698 - val_mae: 5.8195\n",
      "Epoch 199/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 57.5158 - mae: 5.7378 - val_loss: 60.6061 - val_mae: 5.9045\n",
      "Epoch 200/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 57.8666 - mae: 5.7600 - val_loss: 59.6043 - val_mae: 6.0102\n",
      "Epoch 201/500\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 57.0822 - mae: 5.7949 - val_loss: 62.1219 - val_mae: 5.7872\n",
      "Epoch 202/500\n",
      "515/515 [==============================] - 0s 222us/sample - loss: 62.9654 - mae: 6.1976 - val_loss: 75.8201 - val_mae: 6.5116\n",
      "Epoch 203/500\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 62.7305 - mae: 6.0488 - val_loss: 62.2578 - val_mae: 5.8439\n",
      "Epoch 204/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 63.7945 - mae: 6.0737 - val_loss: 61.7742 - val_mae: 6.1917\n",
      "Epoch 205/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 63.0174 - mae: 6.0391 - val_loss: 65.2338 - val_mae: 6.3481\n",
      "Epoch 206/500\n",
      "515/515 [==============================] - 0s 218us/sample - loss: 56.4034 - mae: 5.7221 - val_loss: 58.4358 - val_mae: 5.7370\n",
      "Epoch 207/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 57.0041 - mae: 5.7453 - val_loss: 66.6941 - val_mae: 6.5473\n",
      "Epoch 208/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 57.5963 - mae: 5.7392 - val_loss: 58.3795 - val_mae: 5.7903\n",
      "Epoch 209/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 58.9176 - mae: 5.8459 - val_loss: 57.2117 - val_mae: 5.6816\n",
      "Epoch 210/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 54.9088 - mae: 5.6080 - val_loss: 57.8159 - val_mae: 5.8458\n",
      "Epoch 211/500\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 58.2075 - mae: 5.8248 - val_loss: 61.9584 - val_mae: 6.0968\n",
      "Epoch 212/500\n",
      "515/515 [==============================] - 0s 238us/sample - loss: 57.1553 - mae: 5.8086 - val_loss: 59.2846 - val_mae: 5.7924\n",
      "Epoch 213/500\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 57.2898 - mae: 5.7487 - val_loss: 59.7506 - val_mae: 5.6514\n",
      "Epoch 214/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 57.1405 - mae: 5.6326 - val_loss: 62.9381 - val_mae: 6.4252\n",
      "Epoch 215/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 54.8009 - mae: 5.6245 - val_loss: 58.4052 - val_mae: 5.5880\n",
      "Epoch 216/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 55.0032 - mae: 5.5902 - val_loss: 59.1015 - val_mae: 5.6750\n",
      "Epoch 217/500\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 53.7613 - mae: 5.4652 - val_loss: 56.2060 - val_mae: 5.7042\n",
      "Epoch 218/500\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 53.5662 - mae: 5.3775 - val_loss: 56.9719 - val_mae: 5.4619\n",
      "Epoch 219/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 54.2309 - mae: 5.5713 - val_loss: 61.5899 - val_mae: 5.6191\n",
      "Epoch 220/500\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 55.5767 - mae: 5.5875 - val_loss: 57.4248 - val_mae: 5.4885\n",
      "Epoch 221/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 55.4507 - mae: 5.5944 - val_loss: 57.2265 - val_mae: 5.4854\n",
      "Epoch 222/500\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 55.5094 - mae: 5.6229 - val_loss: 61.6517 - val_mae: 5.6927\n",
      "Epoch 223/500\n",
      "515/515 [==============================] - 0s 232us/sample - loss: 56.3332 - mae: 5.8180 - val_loss: 59.3463 - val_mae: 5.7054\n",
      "Epoch 224/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 60.2188 - mae: 5.8459 - val_loss: 58.2262 - val_mae: 5.9610\n",
      "Epoch 225/500\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 58.6119 - mae: 5.8411 - val_loss: 59.7637 - val_mae: 5.5429\n",
      "Epoch 226/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 56.4492 - mae: 5.7109 - val_loss: 55.5809 - val_mae: 5.5079\n",
      "Epoch 227/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 50.7101 - mae: 5.3713 - val_loss: 55.7447 - val_mae: 5.4495\n",
      "Epoch 228/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 57.3637 - mae: 5.7596 - val_loss: 54.1629 - val_mae: 5.4633\n",
      "Epoch 229/500\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 60.5438 - mae: 5.9608 - val_loss: 56.4414 - val_mae: 5.8488\n",
      "Epoch 230/500\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 55.1371 - mae: 5.6639 - val_loss: 56.0452 - val_mae: 5.4670\n",
      "Epoch 231/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 53.6085 - mae: 5.5290 - val_loss: 57.7112 - val_mae: 5.4490\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 0s 241us/sample - loss: 59.7346 - mae: 5.8503 - val_loss: 54.7295 - val_mae: 5.4538\n",
      "Epoch 233/500\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 56.4749 - mae: 5.7541 - val_loss: 54.3322 - val_mae: 5.3871\n",
      "Epoch 234/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 65.1341 - mae: 6.0719 - val_loss: 65.8964 - val_mae: 5.8985\n",
      "Epoch 235/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 56.1439 - mae: 5.8092 - val_loss: 54.6941 - val_mae: 5.5470\n",
      "Epoch 236/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 52.3920 - mae: 5.4688 - val_loss: 53.8017 - val_mae: 5.4521\n",
      "Epoch 237/500\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 53.1446 - mae: 5.5004 - val_loss: 54.3249 - val_mae: 5.5891\n",
      "Epoch 238/500\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 50.0568 - mae: 5.2931 - val_loss: 56.6839 - val_mae: 5.4226\n",
      "Epoch 239/500\n",
      "515/515 [==============================] - 0s 226us/sample - loss: 52.5084 - mae: 5.3921 - val_loss: 56.1293 - val_mae: 5.5307\n",
      "Epoch 240/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 59.8997 - mae: 5.8553 - val_loss: 53.7067 - val_mae: 5.6870\n",
      "Epoch 241/500\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 52.0676 - mae: 5.5200 - val_loss: 71.1025 - val_mae: 6.9242\n",
      "Epoch 242/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 56.9315 - mae: 5.7947 - val_loss: 60.7014 - val_mae: 6.1182\n",
      "Epoch 243/500\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 58.5209 - mae: 5.8172 - val_loss: 65.3747 - val_mae: 5.9081\n",
      "Epoch 244/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 56.3612 - mae: 5.6836 - val_loss: 52.2775 - val_mae: 5.4439\n",
      "Epoch 245/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 50.2107 - mae: 5.2728 - val_loss: 54.9810 - val_mae: 5.8598\n",
      "Epoch 246/500\n",
      "515/515 [==============================] - 0s 238us/sample - loss: 59.6604 - mae: 5.8794 - val_loss: 55.9657 - val_mae: 5.7743\n",
      "Epoch 247/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 48.5542 - mae: 5.2057 - val_loss: 55.8064 - val_mae: 6.0333\n",
      "Epoch 248/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 48.7049 - mae: 5.3068 - val_loss: 49.5519 - val_mae: 5.1292\n",
      "Epoch 249/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 47.2397 - mae: 5.1077 - val_loss: 58.1714 - val_mae: 6.1669\n",
      "Epoch 250/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 55.3330 - mae: 5.5746 - val_loss: 59.4318 - val_mae: 6.2316\n",
      "Epoch 251/500\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 54.4641 - mae: 5.6614 - val_loss: 49.2943 - val_mae: 5.2140\n",
      "Epoch 252/500\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 46.0208 - mae: 5.0932 - val_loss: 51.9201 - val_mae: 5.3886\n",
      "Epoch 253/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 47.4608 - mae: 5.2017 - val_loss: 49.3229 - val_mae: 5.2383\n",
      "Epoch 254/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 47.3797 - mae: 5.3241 - val_loss: 51.4355 - val_mae: 5.1930\n",
      "Epoch 255/500\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 52.1695 - mae: 5.4482 - val_loss: 55.3191 - val_mae: 5.3181\n",
      "Epoch 256/500\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 48.2019 - mae: 5.1201 - val_loss: 49.1179 - val_mae: 5.3466\n",
      "Epoch 257/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 47.7904 - mae: 5.2784 - val_loss: 49.9466 - val_mae: 5.3520\n",
      "Epoch 258/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 47.4639 - mae: 5.2168 - val_loss: 50.0532 - val_mae: 5.1439\n",
      "Epoch 259/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 47.6049 - mae: 5.0871 - val_loss: 48.5480 - val_mae: 5.1016\n",
      "Epoch 260/500\n",
      "515/515 [==============================] - 0s 236us/sample - loss: 49.3165 - mae: 5.3253 - val_loss: 58.1810 - val_mae: 6.2904\n",
      "Epoch 261/500\n",
      "515/515 [==============================] - 0s 226us/sample - loss: 51.5947 - mae: 5.4840 - val_loss: 46.7410 - val_mae: 5.1082\n",
      "Epoch 262/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 46.0418 - mae: 5.1263 - val_loss: 46.8123 - val_mae: 5.1416\n",
      "Epoch 263/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 47.5920 - mae: 5.2336 - val_loss: 47.9251 - val_mae: 5.3438\n",
      "Epoch 264/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 47.9818 - mae: 5.2645 - val_loss: 48.2053 - val_mae: 5.0493\n",
      "Epoch 265/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 44.0086 - mae: 4.9955 - val_loss: 48.5612 - val_mae: 5.0315\n",
      "Epoch 266/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 47.0183 - mae: 5.0924 - val_loss: 48.3945 - val_mae: 5.2777\n",
      "Epoch 267/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 47.7217 - mae: 5.2064 - val_loss: 51.0341 - val_mae: 5.5767\n",
      "Epoch 268/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 46.4867 - mae: 5.2011 - val_loss: 56.2552 - val_mae: 5.3843\n",
      "Epoch 269/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 46.7976 - mae: 5.2450 - val_loss: 48.0090 - val_mae: 4.9943\n",
      "Epoch 270/500\n",
      "515/515 [==============================] - 0s 220us/sample - loss: 44.2860 - mae: 4.9334 - val_loss: 46.9961 - val_mae: 5.2980\n",
      "Epoch 271/500\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 46.5686 - mae: 5.3500 - val_loss: 47.8145 - val_mae: 5.2441\n",
      "Epoch 272/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 46.8294 - mae: 5.1746 - val_loss: 47.7207 - val_mae: 4.9452\n",
      "Epoch 273/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 46.0455 - mae: 5.1344 - val_loss: 47.5889 - val_mae: 4.9969\n",
      "Epoch 274/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 46.7913 - mae: 5.1248 - val_loss: 49.0018 - val_mae: 5.4707\n",
      "Epoch 275/500\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 43.3639 - mae: 4.9913 - val_loss: 49.8461 - val_mae: 5.6547\n",
      "Epoch 276/500\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 51.4785 - mae: 5.5041 - val_loss: 50.4670 - val_mae: 5.2822\n",
      "Epoch 277/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 48.5866 - mae: 5.2687 - val_loss: 45.0025 - val_mae: 5.0386\n",
      "Epoch 278/500\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 41.5868 - mae: 4.7900 - val_loss: 48.5015 - val_mae: 5.4477\n",
      "Epoch 279/500\n",
      "515/515 [==============================] - 0s 224us/sample - loss: 46.6190 - mae: 5.2493 - val_loss: 45.7623 - val_mae: 5.1861\n",
      "Epoch 280/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 46.7397 - mae: 5.1434 - val_loss: 45.8860 - val_mae: 4.9999\n",
      "Epoch 281/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 44.2434 - mae: 5.0328 - val_loss: 44.9664 - val_mae: 4.9836\n",
      "Epoch 282/500\n",
      "515/515 [==============================] - 0s 351us/sample - loss: 45.6314 - mae: 5.0725 - val_loss: 45.2013 - val_mae: 4.9677\n",
      "Epoch 283/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 49.4533 - mae: 5.2520 - val_loss: 48.1569 - val_mae: 5.0029\n",
      "Epoch 284/500\n",
      "515/515 [==============================] - 0s 266us/sample - loss: 47.2181 - mae: 5.2118 - val_loss: 49.5867 - val_mae: 5.5916\n",
      "Epoch 285/500\n",
      "515/515 [==============================] - 0s 295us/sample - loss: 41.7415 - mae: 4.9135 - val_loss: 44.1549 - val_mae: 5.0374\n",
      "Epoch 286/500\n",
      "515/515 [==============================] - 0s 290us/sample - loss: 42.8719 - mae: 5.0244 - val_loss: 45.6293 - val_mae: 4.9618\n",
      "Epoch 287/500\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 42.5554 - mae: 4.8543 - val_loss: 44.9635 - val_mae: 5.0953\n",
      "Epoch 288/500\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 46.2669 - mae: 5.2305 - val_loss: 43.2924 - val_mae: 4.9676\n",
      "Epoch 289/500\n",
      "515/515 [==============================] - 0s 316us/sample - loss: 43.9087 - mae: 4.8961 - val_loss: 43.1291 - val_mae: 4.9579\n",
      "Epoch 290/500\n",
      "515/515 [==============================] - 0s 324us/sample - loss: 48.3581 - mae: 5.1918 - val_loss: 49.5046 - val_mae: 5.0632\n",
      "Epoch 291/500\n",
      "515/515 [==============================] - 0s 274us/sample - loss: 48.6999 - mae: 5.3521 - val_loss: 48.2897 - val_mae: 4.9790\n",
      "Epoch 292/500\n",
      "515/515 [==============================] - 0s 274us/sample - loss: 52.1670 - mae: 5.6089 - val_loss: 55.7207 - val_mae: 6.0947\n",
      "Epoch 293/500\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 53.5611 - mae: 5.6841 - val_loss: 52.6048 - val_mae: 5.7096\n",
      "Epoch 294/500\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 50.1485 - mae: 5.4054 - val_loss: 44.8234 - val_mae: 5.0417\n",
      "Epoch 295/500\n",
      "515/515 [==============================] - 0s 214us/sample - loss: 44.2661 - mae: 5.0521 - val_loss: 48.0541 - val_mae: 4.9371\n",
      "Epoch 296/500\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 39.9513 - mae: 4.7295 - val_loss: 52.5095 - val_mae: 5.0433\n",
      "Epoch 297/500\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 48.5473 - mae: 5.3830 - val_loss: 53.6996 - val_mae: 5.3334\n",
      "Epoch 298/500\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 42.0248 - mae: 5.0114 - val_loss: 54.3459 - val_mae: 5.2362\n",
      "Epoch 299/500\n",
      "515/515 [==============================] - 0s 198us/sample - loss: 46.3109 - mae: 5.1918 - val_loss: 47.1094 - val_mae: 4.9197\n",
      "Epoch 300/500\n",
      "515/515 [==============================] - 0s 283us/sample - loss: 44.7794 - mae: 5.0238 - val_loss: 46.4667 - val_mae: 5.3233\n",
      "Epoch 301/500\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 43.8312 - mae: 5.0292 - val_loss: 45.3187 - val_mae: 5.1882\n",
      "Epoch 302/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 40.6671 - mae: 4.8705 - val_loss: 47.8354 - val_mae: 4.9234\n",
      "Epoch 303/500\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 43.2985 - mae: 5.0615 - val_loss: 51.6585 - val_mae: 5.0570\n",
      "Epoch 304/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 44.1600 - mae: 4.9837 - val_loss: 46.3420 - val_mae: 5.1390\n",
      "Epoch 305/500\n",
      "515/515 [==============================] - 0s 196us/sample - loss: 42.2291 - mae: 4.9304 - val_loss: 45.3679 - val_mae: 5.3226\n",
      "Epoch 306/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 49.3969 - mae: 5.3281 - val_loss: 41.7377 - val_mae: 4.8917\n",
      "Epoch 307/500\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 42.4511 - mae: 4.8292 - val_loss: 44.7651 - val_mae: 5.1138\n",
      "Epoch 308/500\n",
      "515/515 [==============================] - 0s 202us/sample - loss: 38.2909 - mae: 4.6767 - val_loss: 42.7653 - val_mae: 4.9323\n",
      "Epoch 309/500\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 46.2036 - mae: 5.2017 - val_loss: 48.5894 - val_mae: 5.3146\n",
      "Epoch 310/500\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 40.8262 - mae: 4.9272 - val_loss: 43.5379 - val_mae: 4.8797\n",
      "Epoch 311/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 39.9050 - mae: 4.6782 - val_loss: 43.9823 - val_mae: 5.1610\n",
      "Epoch 312/500\n",
      "515/515 [==============================] - 0s 218us/sample - loss: 40.7453 - mae: 4.8026 - val_loss: 43.7300 - val_mae: 4.8124\n",
      "Epoch 313/500\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 40.5600 - mae: 4.7628 - val_loss: 41.8830 - val_mae: 4.8382\n",
      "Epoch 314/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 39.9738 - mae: 4.7375 - val_loss: 47.2818 - val_mae: 5.5702\n",
      "Epoch 315/500\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 39.3044 - mae: 4.7206 - val_loss: 41.6367 - val_mae: 4.8846\n",
      "Epoch 316/500\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 40.3024 - mae: 4.7706 - val_loss: 44.8808 - val_mae: 4.8740\n",
      "Epoch 317/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 44.7953 - mae: 5.0618 - val_loss: 45.5132 - val_mae: 5.0756\n",
      "Epoch 318/500\n",
      "515/515 [==============================] - 0s 214us/sample - loss: 38.0994 - mae: 4.6622 - val_loss: 44.8372 - val_mae: 4.8699\n",
      "Epoch 319/500\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 41.7184 - mae: 4.8549 - val_loss: 44.4042 - val_mae: 4.7942\n",
      "Epoch 320/500\n",
      "515/515 [==============================] - ETA: 0s - loss: 43.5558 - mae: 5.01 - 0s 247us/sample - loss: 41.6708 - mae: 4.9122 - val_loss: 48.6065 - val_mae: 5.4885\n",
      "Epoch 321/500\n",
      "515/515 [==============================] - 0s 287us/sample - loss: 43.7553 - mae: 5.0259 - val_loss: 41.8713 - val_mae: 4.7960\n",
      "Epoch 322/500\n",
      "515/515 [==============================] - 0s 274us/sample - loss: 45.1905 - mae: 5.2152 - val_loss: 62.8077 - val_mae: 5.8862\n",
      "Epoch 323/500\n",
      "515/515 [==============================] - 0s 234us/sample - loss: 42.3411 - mae: 4.9226 - val_loss: 45.1077 - val_mae: 4.7872\n",
      "Epoch 324/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 36.8108 - mae: 4.5247 - val_loss: 40.8637 - val_mae: 4.8129\n",
      "Epoch 325/500\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 39.3389 - mae: 4.6928 - val_loss: 46.2938 - val_mae: 4.8318\n",
      "Epoch 326/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 38.5027 - mae: 4.6615 - val_loss: 46.4085 - val_mae: 4.8576\n",
      "Epoch 327/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 40.6578 - mae: 4.8804 - val_loss: 42.4975 - val_mae: 4.9586\n",
      "Epoch 328/500\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 37.8651 - mae: 4.6677 - val_loss: 43.9529 - val_mae: 4.8320\n",
      "Epoch 329/500\n",
      "515/515 [==============================] - 0s 312us/sample - loss: 52.4762 - mae: 5.6082 - val_loss: 49.4280 - val_mae: 5.0695\n",
      "Epoch 330/500\n",
      "515/515 [==============================] - 0s 274us/sample - loss: 45.0938 - mae: 5.0990 - val_loss: 44.6926 - val_mae: 4.8044\n",
      "Epoch 331/500\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 41.8424 - mae: 4.9235 - val_loss: 51.5475 - val_mae: 5.0036\n",
      "Epoch 332/500\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 41.9882 - mae: 4.9162 - val_loss: 49.4180 - val_mae: 5.0515\n",
      "Epoch 333/500\n",
      "515/515 [==============================] - 0s 314us/sample - loss: 41.4563 - mae: 4.8305 - val_loss: 54.9806 - val_mae: 5.3959\n",
      "Epoch 334/500\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 41.1666 - mae: 4.8178 - val_loss: 47.4384 - val_mae: 4.8413\n",
      "Epoch 335/500\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 38.9308 - mae: 4.7617 - val_loss: 42.0280 - val_mae: 4.7328\n",
      "Epoch 336/500\n",
      "515/515 [==============================] - 0s 200us/sample - loss: 38.0236 - mae: 4.7494 - val_loss: 44.6495 - val_mae: 4.8842\n",
      "Epoch 337/500\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 36.6290 - mae: 4.5300 - val_loss: 43.1650 - val_mae: 5.2104\n",
      "Epoch 338/500\n",
      "515/515 [==============================] - 0s 278us/sample - loss: 38.9760 - mae: 4.7319 - val_loss: 42.8881 - val_mae: 5.0921\n",
      "Epoch 339/500\n",
      "515/515 [==============================] - 0s 225us/sample - loss: 40.1069 - mae: 4.8048 - val_loss: 40.5252 - val_mae: 4.8682\n",
      "Epoch 340/500\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 41.4703 - mae: 4.9236 - val_loss: 43.1315 - val_mae: 4.8021\n",
      "Epoch 341/500\n",
      "515/515 [==============================] - 0s 295us/sample - loss: 36.6008 - mae: 4.5738 - val_loss: 43.9367 - val_mae: 4.7343\n",
      "Epoch 342/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 37.2935 - mae: 4.6348 - val_loss: 40.0081 - val_mae: 4.7373\n",
      "Epoch 343/500\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 39.3537 - mae: 4.7012 - val_loss: 42.6646 - val_mae: 4.7446\n",
      "Epoch 344/500\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 38.7639 - mae: 4.5838 - val_loss: 40.8189 - val_mae: 4.6728\n",
      "Epoch 345/500\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 41.1205 - mae: 4.9287 - val_loss: 41.7718 - val_mae: 5.0552\n",
      "Epoch 346/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 40.5711 - mae: 4.9171 - val_loss: 40.1474 - val_mae: 4.6370\n",
      "Epoch 347/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 37.9173 - mae: 4.6714 - val_loss: 42.2784 - val_mae: 4.9030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/500\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 36.0545 - mae: 4.5656 - val_loss: 40.3021 - val_mae: 4.7699\n",
      "Epoch 349/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 38.2082 - mae: 4.8033 - val_loss: 46.3180 - val_mae: 4.8185\n",
      "Epoch 350/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 39.2032 - mae: 4.7352 - val_loss: 41.6833 - val_mae: 4.6829\n",
      "Epoch 351/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 37.6170 - mae: 4.6877 - val_loss: 44.4857 - val_mae: 4.6903\n",
      "Epoch 352/500\n",
      "515/515 [==============================] - 0s 311us/sample - loss: 42.0523 - mae: 4.9256 - val_loss: 45.3832 - val_mae: 4.6771\n",
      "Epoch 353/500\n",
      "515/515 [==============================] - 0s 353us/sample - loss: 37.1807 - mae: 4.6091 - val_loss: 41.7843 - val_mae: 5.0743\n",
      "Epoch 354/500\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 36.6974 - mae: 4.6711 - val_loss: 51.5492 - val_mae: 5.8772\n",
      "Epoch 355/500\n",
      "515/515 [==============================] - 0s 324us/sample - loss: 40.7971 - mae: 4.8845 - val_loss: 44.9174 - val_mae: 5.1787\n",
      "Epoch 356/500\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 39.5857 - mae: 4.7651 - val_loss: 56.3654 - val_mae: 5.5890\n",
      "Epoch 357/500\n",
      "515/515 [==============================] - 0s 322us/sample - loss: 44.3979 - mae: 5.0230 - val_loss: 40.9626 - val_mae: 4.8522\n",
      "Epoch 358/500\n",
      "515/515 [==============================] - 0s 297us/sample - loss: 36.9818 - mae: 4.5188 - val_loss: 40.2439 - val_mae: 4.9028\n",
      "Epoch 359/500\n",
      "515/515 [==============================] - 0s 351us/sample - loss: 37.9422 - mae: 4.6999 - val_loss: 40.9324 - val_mae: 4.6864\n",
      "Epoch 360/500\n",
      "515/515 [==============================] - 0s 306us/sample - loss: 36.7060 - mae: 4.5150 - val_loss: 39.4600 - val_mae: 4.7752\n",
      "Epoch 361/500\n",
      "515/515 [==============================] - 0s 241us/sample - loss: 35.6500 - mae: 4.5609 - val_loss: 41.2743 - val_mae: 4.7771\n",
      "Epoch 362/500\n",
      "515/515 [==============================] - 0s 335us/sample - loss: 35.7084 - mae: 4.5133 - val_loss: 41.4990 - val_mae: 5.0398\n",
      "Epoch 363/500\n",
      "515/515 [==============================] - 0s 322us/sample - loss: 37.6840 - mae: 4.6162 - val_loss: 43.7882 - val_mae: 5.1497\n",
      "Epoch 364/500\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 37.8259 - mae: 4.6493 - val_loss: 44.0219 - val_mae: 4.7355\n",
      "Epoch 365/500\n",
      "515/515 [==============================] - 0s 338us/sample - loss: 35.8741 - mae: 4.5074 - val_loss: 45.5961 - val_mae: 5.3678\n",
      "Epoch 366/500\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 39.6595 - mae: 4.8087 - val_loss: 41.0699 - val_mae: 4.8053\n",
      "Epoch 367/500\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 37.6318 - mae: 4.6624 - val_loss: 43.2463 - val_mae: 5.0855\n",
      "Epoch 368/500\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 45.0040 - mae: 5.1483 - val_loss: 43.8913 - val_mae: 5.1256\n",
      "Epoch 369/500\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 36.5621 - mae: 4.5394 - val_loss: 39.8352 - val_mae: 4.7878\n",
      "Epoch 370/500\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 37.6411 - mae: 4.5944 - val_loss: 46.2800 - val_mae: 4.8524\n",
      "Epoch 371/500\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 37.8322 - mae: 4.6003 - val_loss: 42.6181 - val_mae: 4.9969\n",
      "Epoch 372/500\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 39.3333 - mae: 4.7335 - val_loss: 40.2286 - val_mae: 4.7948\n",
      "Epoch 373/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 36.7913 - mae: 4.5391 - val_loss: 45.5042 - val_mae: 4.9861\n",
      "Epoch 374/500\n",
      "515/515 [==============================] - 0s 347us/sample - loss: 36.5254 - mae: 4.6062 - val_loss: 46.7770 - val_mae: 4.8448\n",
      "Epoch 375/500\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 37.7881 - mae: 4.6720 - val_loss: 40.2590 - val_mae: 4.7155\n",
      "Epoch 376/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 34.9354 - mae: 4.5288 - val_loss: 39.0022 - val_mae: 4.6606\n",
      "Epoch 377/500\n",
      "515/515 [==============================] - 0s 281us/sample - loss: 34.0776 - mae: 4.4516 - val_loss: 40.2619 - val_mae: 4.7443\n",
      "Epoch 378/500\n",
      "515/515 [==============================] - 0s 298us/sample - loss: 35.2372 - mae: 4.5461 - val_loss: 40.1515 - val_mae: 4.6236\n",
      "Epoch 379/500\n",
      "515/515 [==============================] - 0s 295us/sample - loss: 36.0499 - mae: 4.6523 - val_loss: 42.4803 - val_mae: 4.8074\n",
      "Epoch 380/500\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 35.4287 - mae: 4.4681 - val_loss: 41.1441 - val_mae: 4.6827\n",
      "Epoch 381/500\n",
      "515/515 [==============================] - 0s 384us/sample - loss: 36.1981 - mae: 4.5495 - val_loss: 41.3238 - val_mae: 4.9082\n",
      "Epoch 382/500\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 36.5664 - mae: 4.5607 - val_loss: 40.3320 - val_mae: 4.7220\n",
      "Epoch 383/500\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 35.0668 - mae: 4.5385 - val_loss: 38.1338 - val_mae: 4.6633\n",
      "Epoch 384/500\n",
      "515/515 [==============================] - 0s 295us/sample - loss: 37.8840 - mae: 4.6882 - val_loss: 42.1228 - val_mae: 5.0492\n",
      "Epoch 385/500\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 36.0642 - mae: 4.5099 - val_loss: 46.6769 - val_mae: 4.7537\n",
      "Epoch 386/500\n",
      "515/515 [==============================] - 0s 285us/sample - loss: 40.7494 - mae: 4.9041 - val_loss: 43.0714 - val_mae: 4.7983\n",
      "Epoch 387/500\n",
      "515/515 [==============================] - 0s 279us/sample - loss: 36.2345 - mae: 4.4991 - val_loss: 42.7943 - val_mae: 4.7176\n",
      "Epoch 388/500\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 38.9092 - mae: 4.6571 - val_loss: 40.5003 - val_mae: 4.6067\n",
      "Epoch 389/500\n",
      "515/515 [==============================] - 0s 295us/sample - loss: 35.2294 - mae: 4.5153 - val_loss: 41.2419 - val_mae: 4.8333\n",
      "Epoch 390/500\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 38.4472 - mae: 4.6579 - val_loss: 42.7580 - val_mae: 4.7231\n",
      "Epoch 391/500\n",
      "515/515 [==============================] - 0s 285us/sample - loss: 36.0404 - mae: 4.5734 - val_loss: 42.0790 - val_mae: 5.0154\n",
      "Epoch 392/500\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 44.2727 - mae: 5.0588 - val_loss: 43.3022 - val_mae: 5.1225\n",
      "Epoch 393/500\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 38.0018 - mae: 4.5803 - val_loss: 48.3574 - val_mae: 5.0806\n",
      "Epoch 394/500\n",
      "515/515 [==============================] - 0s 276us/sample - loss: 36.1667 - mae: 4.6508 - val_loss: 42.0213 - val_mae: 4.6920\n",
      "Epoch 395/500\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 32.4755 - mae: 4.2442 - val_loss: 38.9591 - val_mae: 4.7015\n",
      "Epoch 396/500\n",
      "515/515 [==============================] - 0s 268us/sample - loss: 32.3119 - mae: 4.3514 - val_loss: 38.6785 - val_mae: 4.5948\n",
      "Epoch 397/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 34.7823 - mae: 4.3022 - val_loss: 39.7276 - val_mae: 4.5670\n",
      "Epoch 398/500\n",
      "515/515 [==============================] - 0s 286us/sample - loss: 35.6690 - mae: 4.4792 - val_loss: 39.5401 - val_mae: 4.5725\n",
      "Epoch 399/500\n",
      "515/515 [==============================] - 0s 227us/sample - loss: 34.7312 - mae: 4.5421 - val_loss: 39.3743 - val_mae: 4.5664\n",
      "Epoch 400/500\n",
      "515/515 [==============================] - 0s 373us/sample - loss: 34.8388 - mae: 4.3586 - val_loss: 43.5738 - val_mae: 5.2295\n",
      "Epoch 401/500\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 40.5100 - mae: 4.7449 - val_loss: 39.3832 - val_mae: 4.7652\n",
      "Epoch 402/500\n",
      "515/515 [==============================] - 0s 244us/sample - loss: 33.8824 - mae: 4.4795 - val_loss: 39.1812 - val_mae: 4.5687\n",
      "Epoch 403/500\n",
      "515/515 [==============================] - 0s 310us/sample - loss: 35.4071 - mae: 4.5465 - val_loss: 41.6230 - val_mae: 4.7126\n",
      "Epoch 404/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 41.0668 - mae: 4.8654 - val_loss: 39.7640 - val_mae: 4.5592\n",
      "Epoch 405/500\n",
      "515/515 [==============================] - 0s 295us/sample - loss: 36.6087 - mae: 4.5739 - val_loss: 42.5001 - val_mae: 5.0231\n",
      "Epoch 406/500\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 32.4267 - mae: 4.1995 - val_loss: 39.0666 - val_mae: 4.6224\n",
      "Epoch 407/500\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 35.3950 - mae: 4.5250 - val_loss: 56.1873 - val_mae: 6.1813\n",
      "Epoch 408/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 41.0741 - mae: 5.0416 - val_loss: 43.1217 - val_mae: 5.0991\n",
      "Epoch 409/500\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 35.3081 - mae: 4.4138 - val_loss: 40.8796 - val_mae: 4.9327\n",
      "Epoch 410/500\n",
      "515/515 [==============================] - 0s 228us/sample - loss: 38.0913 - mae: 4.6843 - val_loss: 39.6320 - val_mae: 4.7277\n",
      "Epoch 411/500\n",
      "515/515 [==============================] - 0s 287us/sample - loss: 32.4372 - mae: 4.2601 - val_loss: 40.3330 - val_mae: 4.9495\n",
      "Epoch 412/500\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 32.1706 - mae: 4.3606 - val_loss: 38.9268 - val_mae: 4.5210\n",
      "Epoch 413/500\n",
      "515/515 [==============================] - 0s 243us/sample - loss: 35.7626 - mae: 4.4400 - val_loss: 39.3218 - val_mae: 4.5377\n",
      "Epoch 414/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 31.8811 - mae: 4.3310 - val_loss: 38.5094 - val_mae: 4.6247\n",
      "Epoch 415/500\n",
      "515/515 [==============================] - 0s 275us/sample - loss: 32.9753 - mae: 4.3404 - val_loss: 45.9369 - val_mae: 5.3234\n",
      "Epoch 416/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 39.5823 - mae: 4.7668 - val_loss: 41.0085 - val_mae: 4.6526\n",
      "Epoch 417/500\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 32.8322 - mae: 4.3919 - val_loss: 41.2461 - val_mae: 4.7407\n",
      "Epoch 418/500\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 31.7775 - mae: 4.2436 - val_loss: 43.6864 - val_mae: 4.6807\n",
      "Epoch 419/500\n",
      "515/515 [==============================] - 0s 270us/sample - loss: 36.2351 - mae: 4.6675 - val_loss: 59.8123 - val_mae: 5.6762\n",
      "Epoch 420/500\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 39.6939 - mae: 4.7814 - val_loss: 44.3017 - val_mae: 4.6383\n",
      "Epoch 421/500\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 40.3771 - mae: 4.8781 - val_loss: 42.3325 - val_mae: 4.7186\n",
      "Epoch 422/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 35.2293 - mae: 4.4169 - val_loss: 39.3703 - val_mae: 4.7698\n",
      "Epoch 423/500\n",
      "515/515 [==============================] - 0s 271us/sample - loss: 36.7483 - mae: 4.6928 - val_loss: 44.5643 - val_mae: 5.1521\n",
      "Epoch 424/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 35.7771 - mae: 4.5359 - val_loss: 38.9211 - val_mae: 4.5425\n",
      "Epoch 425/500\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 32.2295 - mae: 4.3426 - val_loss: 42.0345 - val_mae: 4.6202\n",
      "Epoch 426/500\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 31.1999 - mae: 4.2356 - val_loss: 37.9792 - val_mae: 4.4953\n",
      "Epoch 427/500\n",
      "515/515 [==============================] - 0s 314us/sample - loss: 34.2323 - mae: 4.2999 - val_loss: 40.2682 - val_mae: 4.7730\n",
      "Epoch 428/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 31.1464 - mae: 4.2186 - val_loss: 39.3229 - val_mae: 4.6490\n",
      "Epoch 429/500\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 31.9920 - mae: 4.2539 - val_loss: 41.3806 - val_mae: 4.9829\n",
      "Epoch 430/500\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 33.9503 - mae: 4.4845 - val_loss: 40.5294 - val_mae: 4.7963\n",
      "Epoch 431/500\n",
      "515/515 [==============================] - 0s 261us/sample - loss: 34.6043 - mae: 4.3988 - val_loss: 39.6606 - val_mae: 4.5406\n",
      "Epoch 432/500\n",
      "515/515 [==============================] - 0s 204us/sample - loss: 33.5278 - mae: 4.4272 - val_loss: 46.9224 - val_mae: 5.1083\n",
      "Epoch 433/500\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 37.3894 - mae: 4.6164 - val_loss: 39.5557 - val_mae: 4.7226\n",
      "Epoch 434/500\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 33.8912 - mae: 4.3294 - val_loss: 38.6688 - val_mae: 4.5675\n",
      "Epoch 435/500\n",
      "515/515 [==============================] - 0s 260us/sample - loss: 33.5849 - mae: 4.3683 - val_loss: 49.0739 - val_mae: 5.1487\n",
      "Epoch 436/500\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 38.9508 - mae: 4.7563 - val_loss: 47.0244 - val_mae: 4.9639\n",
      "Epoch 437/500\n",
      "515/515 [==============================] - 0s 274us/sample - loss: 33.5820 - mae: 4.4155 - val_loss: 38.2949 - val_mae: 4.6688\n",
      "Epoch 438/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 32.9794 - mae: 4.3916 - val_loss: 39.2367 - val_mae: 4.5917\n",
      "Epoch 439/500\n",
      "515/515 [==============================] - 0s 252us/sample - loss: 34.3804 - mae: 4.3838 - val_loss: 41.6034 - val_mae: 4.5663\n",
      "Epoch 440/500\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 32.9804 - mae: 4.3531 - val_loss: 38.5910 - val_mae: 4.6322\n",
      "Epoch 441/500\n",
      "515/515 [==============================] - 0s 355us/sample - loss: 32.0250 - mae: 4.1685 - val_loss: 38.3815 - val_mae: 4.4643\n",
      "Epoch 442/500\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 32.9681 - mae: 4.3005 - val_loss: 38.8596 - val_mae: 4.5249\n",
      "Epoch 443/500\n",
      "515/515 [==============================] - 0s 230us/sample - loss: 35.5593 - mae: 4.5020 - val_loss: 40.0949 - val_mae: 4.6632\n",
      "Epoch 444/500\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 32.6159 - mae: 4.2918 - val_loss: 38.2434 - val_mae: 4.6568\n",
      "Epoch 445/500\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 32.1700 - mae: 4.2726 - val_loss: 37.0554 - val_mae: 4.6200\n",
      "Epoch 446/500\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 39.9453 - mae: 4.8325 - val_loss: 40.1162 - val_mae: 4.5137\n",
      "Epoch 447/500\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 32.7837 - mae: 4.2768 - val_loss: 38.8053 - val_mae: 4.6144\n",
      "Epoch 448/500\n",
      "515/515 [==============================] - 0s 262us/sample - loss: 30.5392 - mae: 4.0877 - val_loss: 41.1174 - val_mae: 4.5868\n",
      "Epoch 449/500\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 34.3639 - mae: 4.5045 - val_loss: 38.8274 - val_mae: 4.5169\n",
      "Epoch 450/500\n",
      "515/515 [==============================] - 0s 274us/sample - loss: 32.3955 - mae: 4.2778 - val_loss: 42.1629 - val_mae: 4.7160\n",
      "Epoch 451/500\n",
      "515/515 [==============================] - 0s 224us/sample - loss: 36.1433 - mae: 4.6566 - val_loss: 38.6269 - val_mae: 4.4967\n",
      "Epoch 452/500\n",
      "515/515 [==============================] - 0s 279us/sample - loss: 32.5191 - mae: 4.2855 - val_loss: 48.1299 - val_mae: 5.5381\n",
      "Epoch 453/500\n",
      "515/515 [==============================] - 0s 219us/sample - loss: 48.2990 - mae: 5.3745 - val_loss: 41.1808 - val_mae: 4.7968\n",
      "Epoch 454/500\n",
      "515/515 [==============================] - 0s 245us/sample - loss: 36.7498 - mae: 4.6636 - val_loss: 41.0763 - val_mae: 4.6605\n",
      "Epoch 455/500\n",
      "515/515 [==============================] - 0s 221us/sample - loss: 33.6048 - mae: 4.2849 - val_loss: 39.9050 - val_mae: 4.6478\n",
      "Epoch 456/500\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 34.0148 - mae: 4.4087 - val_loss: 38.8045 - val_mae: 4.7655\n",
      "Epoch 457/500\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 30.1646 - mae: 4.2042 - val_loss: 38.3403 - val_mae: 4.6229\n",
      "Epoch 458/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 31.3658 - mae: 4.2296 - val_loss: 37.3414 - val_mae: 4.4736\n",
      "Epoch 459/500\n",
      "515/515 [==============================] - 0s 208us/sample - loss: 31.5675 - mae: 4.2175 - val_loss: 38.9139 - val_mae: 4.5322\n",
      "Epoch 460/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 30.7477 - mae: 4.2144 - val_loss: 38.0777 - val_mae: 4.5154\n",
      "Epoch 461/500\n",
      "515/515 [==============================] - 0s 239us/sample - loss: 30.1526 - mae: 4.0284 - val_loss: 37.6589 - val_mae: 4.4539\n",
      "Epoch 462/500\n",
      "515/515 [==============================] - 0s 213us/sample - loss: 31.2932 - mae: 4.2471 - val_loss: 42.4225 - val_mae: 4.8326\n",
      "Epoch 463/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 32.7271 - mae: 4.3997 - val_loss: 38.6656 - val_mae: 4.4654\n",
      "Epoch 464/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 0s 237us/sample - loss: 30.2204 - mae: 4.1129 - val_loss: 42.0425 - val_mae: 4.6343\n",
      "Epoch 465/500\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 31.9096 - mae: 4.1276 - val_loss: 41.3600 - val_mae: 4.9774\n",
      "Epoch 466/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 40.7786 - mae: 4.8281 - val_loss: 38.8640 - val_mae: 4.6143\n",
      "Epoch 467/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 34.4601 - mae: 4.4568 - val_loss: 40.2341 - val_mae: 4.6909\n",
      "Epoch 468/500\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 32.3818 - mae: 4.2689 - val_loss: 39.0649 - val_mae: 4.5072\n",
      "Epoch 469/500\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 32.6842 - mae: 4.3486 - val_loss: 36.7515 - val_mae: 4.4802\n",
      "Epoch 470/500\n",
      "515/515 [==============================] - 0s 242us/sample - loss: 32.1644 - mae: 4.2903 - val_loss: 39.2430 - val_mae: 4.4907\n",
      "Epoch 471/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 31.8342 - mae: 4.1120 - val_loss: 37.4373 - val_mae: 4.4426\n",
      "Epoch 472/500\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 29.8159 - mae: 4.0248 - val_loss: 41.7719 - val_mae: 4.6995\n",
      "Epoch 473/500\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 35.4733 - mae: 4.5042 - val_loss: 37.0461 - val_mae: 4.4760\n",
      "Epoch 474/500\n",
      "515/515 [==============================] - 0s 206us/sample - loss: 32.2091 - mae: 4.2765 - val_loss: 41.9154 - val_mae: 5.0180\n",
      "Epoch 475/500\n",
      "515/515 [==============================] - 0s 237us/sample - loss: 42.8541 - mae: 4.9951 - val_loss: 42.4824 - val_mae: 5.0693\n",
      "Epoch 476/500\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 38.7597 - mae: 4.6293 - val_loss: 40.8738 - val_mae: 4.6383\n",
      "Epoch 477/500\n",
      "515/515 [==============================] - 0s 266us/sample - loss: 32.6771 - mae: 4.2967 - val_loss: 38.5468 - val_mae: 4.5184\n",
      "Epoch 478/500\n",
      "515/515 [==============================] - 0s 231us/sample - loss: 32.5528 - mae: 4.2614 - val_loss: 40.8909 - val_mae: 4.9423\n",
      "Epoch 479/500\n",
      "515/515 [==============================] - 0s 266us/sample - loss: 32.3847 - mae: 4.3080 - val_loss: 38.3288 - val_mae: 4.5189\n",
      "Epoch 480/500\n",
      "515/515 [==============================] - 0s 217us/sample - loss: 31.9728 - mae: 4.2064 - val_loss: 50.4414 - val_mae: 5.4144\n",
      "Epoch 481/500\n",
      "515/515 [==============================] - 0s 246us/sample - loss: 35.1542 - mae: 4.4757 - val_loss: 39.4286 - val_mae: 4.5525\n",
      "Epoch 482/500\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 31.4009 - mae: 4.1542 - val_loss: 40.6067 - val_mae: 4.6562\n",
      "Epoch 483/500\n",
      "515/515 [==============================] - 0s 258us/sample - loss: 32.6695 - mae: 4.2814 - val_loss: 42.7651 - val_mae: 4.6572\n",
      "Epoch 484/500\n",
      "515/515 [==============================] - 0s 233us/sample - loss: 31.8877 - mae: 4.2552 - val_loss: 46.6478 - val_mae: 4.9949\n",
      "Epoch 485/500\n",
      "515/515 [==============================] - 0s 248us/sample - loss: 31.2043 - mae: 4.2276 - val_loss: 40.0859 - val_mae: 4.6325\n",
      "Epoch 486/500\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 31.1198 - mae: 4.1892 - val_loss: 37.2546 - val_mae: 4.5553\n",
      "Epoch 487/500\n",
      "515/515 [==============================] - 0s 266us/sample - loss: 31.2548 - mae: 4.1526 - val_loss: 37.7791 - val_mae: 4.4107\n",
      "Epoch 488/500\n",
      "515/515 [==============================] - 0s 210us/sample - loss: 31.1077 - mae: 4.2151 - val_loss: 39.8322 - val_mae: 4.5132\n",
      "Epoch 489/500\n",
      "515/515 [==============================] - 0s 254us/sample - loss: 32.0412 - mae: 4.3060 - val_loss: 36.4794 - val_mae: 4.3594\n",
      "Epoch 490/500\n",
      "515/515 [==============================] - 0s 223us/sample - loss: 35.9771 - mae: 4.5650 - val_loss: 42.9578 - val_mae: 5.2051\n",
      "Epoch 491/500\n",
      "515/515 [==============================] - 0s 250us/sample - loss: 36.4749 - mae: 4.6040 - val_loss: 38.6850 - val_mae: 4.6148\n",
      "Epoch 492/500\n",
      "515/515 [==============================] - 0s 235us/sample - loss: 33.7191 - mae: 4.3795 - val_loss: 45.8522 - val_mae: 4.9966\n",
      "Epoch 493/500\n",
      "515/515 [==============================] - 0s 351us/sample - loss: 29.9837 - mae: 4.1788 - val_loss: 36.2932 - val_mae: 4.4488\n",
      "Epoch 494/500\n",
      "515/515 [==============================] - 0s 244us/sample - loss: 31.2456 - mae: 4.2684 - val_loss: 37.0451 - val_mae: 4.5577\n",
      "Epoch 495/500\n",
      "515/515 [==============================] - 0s 293us/sample - loss: 31.1218 - mae: 4.2554 - val_loss: 37.7575 - val_mae: 4.5409\n",
      "Epoch 496/500\n",
      "515/515 [==============================] - 0s 229us/sample - loss: 30.7885 - mae: 4.2495 - val_loss: 47.1666 - val_mae: 5.1719\n",
      "Epoch 497/500\n",
      "515/515 [==============================] - 0s 256us/sample - loss: 45.6544 - mae: 5.2824 - val_loss: 46.4051 - val_mae: 4.7514\n",
      "Epoch 498/500\n",
      "515/515 [==============================] - 0s 212us/sample - loss: 33.4585 - mae: 4.2485 - val_loss: 39.3956 - val_mae: 4.5143\n",
      "Epoch 499/500\n",
      "515/515 [==============================] - 0s 264us/sample - loss: 28.6366 - mae: 4.0332 - val_loss: 43.1314 - val_mae: 4.7976\n",
      "Epoch 500/500\n",
      "515/515 [==============================] - 0s 215us/sample - loss: 29.1224 - mae: 4.0767 - val_loss: 37.4533 - val_mae: 4.5324\n",
      "\n",
      "309/1 - 0s - loss: 33.5740 - mae: 4.8430\n",
      "\n",
      "43.56033425809496\n",
      "4.843024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "43.56033425809496\n",
      "4.843024\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "drop   = 0.03\n",
    "tuning_model(epochs,drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(927, 8)\n",
      "(927,)\n",
      "(103, 8)\n",
      "(103,)\n"
     ]
    }
   ],
   "source": [
    "# Spliting in 90%, 10%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(Samples, Labels, test_size=0.1, random_state=1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# For Reusability, model is defined as a function.\n",
    "display(x_train.shape[1])\n",
    "def build_model():\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(64, activation = 'relu', input_shape = (x_train.shape[1],)))\n",
    "  model.add(layers.Dense(64, activation = 'relu'))\n",
    "  model.add(layers.Dense(1)) # no activation function\n",
    "  model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold #  0\n",
      "Train on 696 samples\n",
      "Epoch 1/3\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 421.7688 - mae: 16.1889\n",
      "Epoch 2/3\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 268.4288 - mae: 13.3191\n",
      "Epoch 3/3\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 242.7792 - mae: 12.8059\n",
      "processing fold #  1\n",
      "Train on 696 samples\n",
      "Epoch 1/3\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 399.5561 - mae: 15.7662\n",
      "Epoch 2/3\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 266.7776 - mae: 13.2048\n",
      "Epoch 3/3\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 238.9478 - mae: 12.6683\n",
      "processing fold #  2\n",
      "Train on 696 samples\n",
      "Epoch 1/3\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 408.6566 - mae: 16.0424\n",
      "Epoch 2/3\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 252.0894 - mae: 12.8018\n",
      "Epoch 3/3\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 231.5386 - mae: 12.4629\n",
      "processing fold #  3\n",
      "Train on 696 samples\n",
      "Epoch 1/3\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 441.5157 - mae: 16.6278\n",
      "Epoch 2/3\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 261.3870 - mae: 13.1351\n",
      "Epoch 3/3\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 238.3846 - mae: 12.56590s\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(x_train) // 4\n",
    "num_epochs = 3 #500\n",
    "all_scores = []\n",
    "all_mae_histories = []\n",
    "\n",
    "for i in range(k):\n",
    "  print('processing fold # ', i)\n",
    "  # prepare the validation data: data from partition # k\n",
    "  val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  \n",
    "  # prepare the training data: data from data - k\n",
    "  partial_train_data = np.concatenate(                    \n",
    "      [x_train[:i * num_val_samples],\n",
    "      x_train[(i + 1 ) * num_val_samples:]],\n",
    "  axis = 0)\n",
    "  partial_train_targets = np.concatenate(\n",
    "      [y_train[:i * num_val_samples],\n",
    "      y_train[(i + 1 ) * num_val_samples:]],\n",
    "  axis = 0)\n",
    "  # Build the Keras Models (already commpiled)\n",
    "  model = build_model()\n",
    "  # Train the model (in silence mode, verbose = 0)\n",
    "  model.fit(partial_train_data, partial_train_targets, epochs = num_epochs, batch_size = 1, verbose = 1)\n",
    "  # Evaluate the model on the validation data\n",
    "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose = 0)\n",
    "  all_scores.append(val_mae)\n",
    "\n",
    "  mae_history = history.history['val_mae']\n",
    "  all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.070949, 13.049539, 11.650019, 12.93433]\n",
      "\n",
      "12.426209\n",
      "\n",
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n"
     ]
    }
   ],
   "source": [
    "print(all_scores)\n",
    "print()\n",
    "print(np.mean(all_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(average_mae_history) + 1 ), average_mae_history)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "#We will save the model performance metrics in a DataFrame\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "Model = []\n",
    "RMSE = []\n",
    "R_sq = []\n",
    "cv = KFold(5, random_state = 1)\n",
    "\n",
    "#Creating a Function to append the cross validation scores of the algorithms\n",
    "def input_scores(name, model, x, y):\n",
    "    Model.append(name)\n",
    "    RMSE.append(np.sqrt((-1) * cross_val_score(model, x, y, cv=cv, \n",
    "                                               scoring='neg_mean_squared_error').mean()))\n",
    "    R_sq.append(cross_val_score(model, x, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor, \n",
    "                              AdaBoostRegressor)\n",
    "\n",
    "names = ['Linear Regression', 'Ridge Regression', 'Lasso Regression',\n",
    "         'K Neighbors Regressor', 'Decision Tree Regressor', \n",
    "         'Random Forest Regressor', 'Gradient Boosting Regressor',\n",
    "         'Adaboost Regressor']\n",
    "models = [LinearRegression(), Ridge(), Lasso(),\n",
    "          KNeighborsRegressor(), DecisionTreeRegressor(),\n",
    "          RandomForestRegressor(), GradientBoostingRegressor(), \n",
    "          AdaBoostRegressor()]\n",
    "\n",
    "#Running all algorithms\n",
    "for name, model in zip(names, models):\n",
    "    input_scores(name, model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWING ARE THE TRAINING SCORES: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>10.480037</td>\n",
       "      <td>0.612592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>10.579321</td>\n",
       "      <td>0.605819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>14.977339</td>\n",
       "      <td>0.209871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K Neighbors Regressor</td>\n",
       "      <td>9.452945</td>\n",
       "      <td>0.686480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>6.969771</td>\n",
       "      <td>0.818317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>5.226058</td>\n",
       "      <td>0.904758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>5.188036</td>\n",
       "      <td>0.905447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adaboost Regressor</td>\n",
       "      <td>7.777372</td>\n",
       "      <td>0.783471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model       RMSE  R Squared\n",
       "0            Linear Regression  10.480037   0.612592\n",
       "1             Ridge Regression  10.579321   0.605819\n",
       "2             Lasso Regression  14.977339   0.209871\n",
       "3        K Neighbors Regressor   9.452945   0.686480\n",
       "4      Decision Tree Regressor   6.969771   0.818317\n",
       "5      Random Forest Regressor   5.226058   0.904758\n",
       "6  Gradient Boosting Regressor   5.188036   0.905447\n",
       "7           Adaboost Regressor   7.777372   0.783471"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = pd.DataFrame({'Model': Model,\n",
    "                           'RMSE': RMSE,\n",
    "                           'R Squared': R_sq})\n",
    "print(\"FOLLOWING ARE THE TRAINING SCORES: \")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(Samples, Labels, test_size=0.1, random_state=1)\n",
    "\n",
    "\n",
    "def tuning_model2(epochs,drop,fold):\n",
    "    print()\n",
    "    models = tf.keras.models.Sequential\n",
    "    layers = tf.keras.layers\n",
    "\n",
    "    model2 = models([layers.Dense(64,input_shape = (8,)),\n",
    "                     layers.Dropout(drop),\n",
    "                     layers.Dense(64,activation=\"relu\"),\n",
    "                     layers.Dense(64,activation=\"relu\"),\n",
    "                     layers.Dropout(drop),\n",
    "                     layers.Dense(1)])\n",
    "    \n",
    "    model2.compile(optimizer=\"adam\", # rmsprop # adam # \n",
    "             loss=\"mse\", # binary_crossentropy\n",
    "              metrics=[\"mae\"])\n",
    "    \n",
    "    k = fold\n",
    "    num_val_samples = len(x_train) // 4\n",
    "    #num_epochs = 500\n",
    "    all_scores = []\n",
    "    all_mae_histories = []\n",
    "\n",
    "    for i in range(k):\n",
    "      print('processing fold # ', i)\n",
    "      # prepare the validation data: data from partition # k\n",
    "      val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "      val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "      # prepare the training data: data from data - k\n",
    "      partial_train_data = np.concatenate(                    \n",
    "          [x_train[:i * num_val_samples],\n",
    "          x_train[(i + 1 ) * num_val_samples:]],\n",
    "      axis = 0)\n",
    "      partial_train_targets = np.concatenate(\n",
    "          [y_train[:i * num_val_samples],\n",
    "          y_train[(i + 1 ) * num_val_samples:]],\n",
    "      axis = 0)\n",
    "      # Build the Keras Models (already commpiled)\n",
    "      # model = build_model()\n",
    "      # Train the model (in silence mode, verbose = 0)\n",
    "      model2.fit(partial_train_data, partial_train_targets, epochs = epochs, batch_size = 1, verbose = 1)\n",
    "      # Evaluate the model on the validation data\n",
    "      val_mse, val_mae = model2.evaluate(val_data, val_targets, verbose = 0)\n",
    "      all_scores.append(val_mae)\n",
    "\n",
    "      mae_history = history.history['val_mae']\n",
    "      all_mae_histories.append(mae_history)\n",
    "    \n",
    "    print(all_scores)\n",
    "    print()\n",
    "    print(\"mae :\",np.mean(all_scores))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "processing fold #  0\n",
      "Train on 696 samples\n",
      "Epoch 1/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 344.6003 - mae: 15.1123\n",
      "Epoch 2/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 234.2371 - mae: 12.5852\n",
      "Epoch 3/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 193.2320 - mae: 11.4432\n",
      "Epoch 4/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 164.5516 - mae: 10.5870\n",
      "Epoch 5/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 140.5493 - mae: 9.5219\n",
      "Epoch 6/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 131.6334 - mae: 9.2559\n",
      "Epoch 7/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 125.2156 - mae: 8.8420\n",
      "Epoch 8/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 127.7482 - mae: 8.9837\n",
      "Epoch 9/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 121.8087 - mae: 8.8231\n",
      "Epoch 10/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 116.7923 - mae: 8.5941\n",
      "Epoch 11/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 116.8437 - mae: 8.4102\n",
      "Epoch 12/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 100.5693 - mae: 7.8787\n",
      "Epoch 13/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 99.5136 - mae: 7.6295\n",
      "Epoch 14/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 96.6562 - mae: 7.6572\n",
      "Epoch 15/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 89.5399 - mae: 7.3302\n",
      "Epoch 16/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 86.5871 - mae: 7.1573\n",
      "Epoch 17/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 84.3475 - mae: 7.0781\n",
      "Epoch 18/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 76.8717 - mae: 6.7755\n",
      "Epoch 19/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 73.3704 - mae: 6.6005\n",
      "Epoch 20/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 72.8737 - mae: 6.5770\n",
      "Epoch 21/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 72.8135 - mae: 6.5035\n",
      "Epoch 22/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 73.1759 - mae: 6.6197\n",
      "Epoch 23/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 73.1641 - mae: 6.4981\n",
      "Epoch 24/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 67.8945 - mae: 6.4417\n",
      "Epoch 25/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 70.1111 - mae: 6.4206\n",
      "Epoch 26/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 71.5496 - mae: 6.5088\n",
      "Epoch 27/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 68.0682 - mae: 6.3550\n",
      "Epoch 28/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 68.6471 - mae: 6.3388\n",
      "Epoch 29/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 68.3688 - mae: 6.5029\n",
      "Epoch 30/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 64.4626 - mae: 6.1386\n",
      "Epoch 31/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 60.5242 - mae: 6.0780\n",
      "Epoch 32/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 62.1068 - mae: 6.0768\n",
      "Epoch 33/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 63.8331 - mae: 6.0977\n",
      "Epoch 34/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 60.1790 - mae: 6.1202\n",
      "Epoch 35/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 63.6264 - mae: 6.0323\n",
      "Epoch 36/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 57.4795 - mae: 5.8485\n",
      "Epoch 37/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 56.5136 - mae: 5.8160\n",
      "Epoch 38/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 54.8358 - mae: 5.7153\n",
      "Epoch 39/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 55.3432 - mae: 5.7010\n",
      "Epoch 40/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 54.0794 - mae: 5.5426\n",
      "Epoch 41/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 60.4752 - mae: 5.9905\n",
      "Epoch 42/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 55.9363 - mae: 5.6468\n",
      "Epoch 43/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 48.9157 - mae: 5.3261\n",
      "Epoch 44/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 56.1681 - mae: 5.5640\n",
      "Epoch 45/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 50.2248 - mae: 5.4311\n",
      "Epoch 46/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 51.9691 - mae: 5.5325\n",
      "Epoch 47/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 52.1788 - mae: 5.5361\n",
      "Epoch 48/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 53.5695 - mae: 5.4838\n",
      "Epoch 49/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 47.1126 - mae: 5.3166\n",
      "Epoch 50/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 53.2821 - mae: 5.6439\n",
      "Epoch 51/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 53.0398 - mae: 5.5510\n",
      "Epoch 52/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 51.5747 - mae: 5.4092\n",
      "Epoch 53/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 48.4686 - mae: 5.2567\n",
      "Epoch 54/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 52.8596 - mae: 5.5480\n",
      "Epoch 55/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 49.0527 - mae: 5.3692\n",
      "Epoch 56/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 51.6395 - mae: 5.3501\n",
      "Epoch 57/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 49.7048 - mae: 5.3289\n",
      "Epoch 58/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 47.6804 - mae: 5.2877\n",
      "Epoch 59/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 48.9377 - mae: 5.3036\n",
      "Epoch 60/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 42.6990 - mae: 5.0089\n",
      "Epoch 61/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 48.3788 - mae: 5.3040\n",
      "Epoch 62/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 54.8385 - mae: 5.6878\n",
      "Epoch 63/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 45.7539 - mae: 5.2368\n",
      "Epoch 64/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 44.2892 - mae: 5.0326\n",
      "Epoch 65/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 46.0828 - mae: 5.1647\n",
      "Epoch 66/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 47.2899 - mae: 5.2050\n",
      "Epoch 67/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 43.7829 - mae: 5.1162\n",
      "Epoch 68/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 46.8956 - mae: 5.1895\n",
      "Epoch 69/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 44.3420 - mae: 5.0463\n",
      "Epoch 70/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 48.0863 - mae: 5.2603\n",
      "Epoch 71/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 43.7028 - mae: 4.9626\n",
      "Epoch 72/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 43.8683 - mae: 5.0815\n",
      "Epoch 73/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 46.8631 - mae: 5.1054\n",
      "Epoch 74/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 45.6501 - mae: 5.0561\n",
      "Epoch 75/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 44.0122 - mae: 5.0835\n",
      "Epoch 76/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 51.4736 - mae: 5.3324\n",
      "Epoch 77/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 46.4636 - mae: 5.2609\n",
      "Epoch 78/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 42.8434 - mae: 4.9098\n",
      "Epoch 79/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 48.0601 - mae: 5.3015\n",
      "Epoch 80/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 43.3571 - mae: 4.9610\n",
      "Epoch 81/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 43.6963 - mae: 4.9808\n",
      "Epoch 82/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 41.4335 - mae: 4.9247\n",
      "Epoch 83/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 45.5346 - mae: 5.1571\n",
      "Epoch 84/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 44.9439 - mae: 5.0153\n",
      "Epoch 85/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 44.4916 - mae: 4.9742\n",
      "Epoch 86/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 43.4141 - mae: 4.9343\n",
      "Epoch 87/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 43.0507 - mae: 4.9488\n",
      "Epoch 88/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 42.2520 - mae: 4.9218\n",
      "Epoch 89/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 40.8038 - mae: 4.8397\n",
      "Epoch 90/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 41.8843 - mae: 5.0130\n",
      "Epoch 91/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 43.7364 - mae: 4.9062\n",
      "Epoch 92/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 40.9820 - mae: 4.8135\n",
      "Epoch 93/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 40.6650 - mae: 4.8933\n",
      "Epoch 94/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 40.5133 - mae: 4.7334\n",
      "Epoch 95/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 49.2199 - mae: 5.2042\n",
      "Epoch 96/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 43.2186 - mae: 4.9174\n",
      "Epoch 97/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 40.4020 - mae: 4.7672\n",
      "Epoch 98/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 41.8500 - mae: 4.8789\n",
      "Epoch 99/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 39.2891 - mae: 4.7309\n",
      "Epoch 100/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 45.6523 - mae: 5.0892\n",
      "Epoch 101/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 39.6565 - mae: 4.6933\n",
      "Epoch 102/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 42.7227 - mae: 4.8902\n",
      "Epoch 103/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 41.2406 - mae: 4.7796\n",
      "Epoch 104/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 40.0707 - mae: 4.6968\n",
      "Epoch 105/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 39.8776 - mae: 4.6944\n",
      "Epoch 106/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 40.0420 - mae: 4.6778\n",
      "Epoch 107/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 38.9314 - mae: 4.6805\n",
      "Epoch 108/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 40.6831 - mae: 4.8596\n",
      "Epoch 109/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 40.7394 - mae: 4.8835\n",
      "Epoch 110/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 42.0837 - mae: 4.7866\n",
      "Epoch 111/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 37.1744 - mae: 4.6384\n",
      "Epoch 112/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 37.7958 - mae: 4.6304\n",
      "Epoch 113/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 39.3429 - mae: 4.6374\n",
      "Epoch 114/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 38.9241 - mae: 4.6436\n",
      "Epoch 115/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 37.0227 - mae: 4.5094\n",
      "Epoch 116/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 39.3236 - mae: 4.6754\n",
      "Epoch 117/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 37.2825 - mae: 4.6178\n",
      "Epoch 118/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 37.3559 - mae: 4.6589\n",
      "Epoch 119/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 39.2709 - mae: 4.6776\n",
      "Epoch 120/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 40.0864 - mae: 4.8032\n",
      "Epoch 121/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 35.3715 - mae: 4.4500\n",
      "Epoch 122/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 41.0019 - mae: 4.8789\n",
      "Epoch 123/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 36.6680 - mae: 4.5332\n",
      "Epoch 124/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 36.8568 - mae: 4.6523\n",
      "Epoch 125/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 38.1889 - mae: 4.6497\n",
      "Epoch 126/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 36.6192 - mae: 4.6027\n",
      "Epoch 127/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 33.4436 - mae: 4.3760\n",
      "Epoch 128/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 37.6531 - mae: 4.6241\n",
      "Epoch 129/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 37.2717 - mae: 4.5643\n",
      "Epoch 130/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 37.9400 - mae: 4.6098\n",
      "Epoch 131/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 35.1566 - mae: 4.5041\n",
      "Epoch 132/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 36.4878 - mae: 4.5744\n",
      "Epoch 133/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 37.4315 - mae: 4.5502\n",
      "Epoch 134/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 34.0036 - mae: 4.4114\n",
      "Epoch 135/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 33.0745 - mae: 4.3524\n",
      "Epoch 136/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 42.0143 - mae: 4.7818\n",
      "Epoch 137/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 35.9851 - mae: 4.5347\n",
      "Epoch 138/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 38.3687 - mae: 4.5819\n",
      "Epoch 139/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 32.3394 - mae: 4.3816\n",
      "Epoch 140/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 41.2072 - mae: 4.6721\n",
      "Epoch 141/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 43.8173 - mae: 4.9092\n",
      "Epoch 142/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 33.9912 - mae: 4.3341\n",
      "Epoch 143/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 37.3069 - mae: 4.6276\n",
      "Epoch 144/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 31.5680 - mae: 4.3056\n",
      "Epoch 145/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 33.4536 - mae: 4.2827\n",
      "Epoch 146/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 33.1286 - mae: 4.3762\n",
      "Epoch 147/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 33.9242 - mae: 4.3682\n",
      "Epoch 148/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 32.0700 - mae: 4.2599\n",
      "Epoch 149/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 38.3551 - mae: 4.6590\n",
      "Epoch 150/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 34.4913 - mae: 4.3773\n",
      "Epoch 151/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 31.6527 - mae: 4.1573\n",
      "Epoch 152/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 34.0074 - mae: 4.3614\n",
      "Epoch 153/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 35.2298 - mae: 4.3803\n",
      "Epoch 154/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 30.1155 - mae: 4.1314\n",
      "Epoch 155/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 31.4407 - mae: 4.3405\n",
      "Epoch 156/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 36.2565 - mae: 4.4327\n",
      "Epoch 157/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 33.2077 - mae: 4.2852\n",
      "Epoch 158/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 36.4044 - mae: 4.5786\n",
      "Epoch 159/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 34.7931 - mae: 4.4281\n",
      "Epoch 160/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 33.6631 - mae: 4.4726\n",
      "Epoch 161/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 36.3541 - mae: 4.4810\n",
      "Epoch 162/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 38.7480 - mae: 4.5596\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 3s 4ms/sample - loss: 35.1391 - mae: 4.4079\n",
      "Epoch 164/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 34.6274 - mae: 4.4117\n",
      "Epoch 165/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 35.5325 - mae: 4.3939\n",
      "Epoch 166/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.4612 - mae: 4.0520\n",
      "Epoch 167/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 38.5321 - mae: 4.6211\n",
      "Epoch 168/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 33.5434 - mae: 4.3251\n",
      "Epoch 169/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 37.3250 - mae: 4.5401\n",
      "Epoch 170/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 32.7941 - mae: 4.2875\n",
      "Epoch 171/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 32.9515 - mae: 4.3834\n",
      "Epoch 172/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 31.3061 - mae: 4.1835\n",
      "Epoch 173/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 37.3986 - mae: 4.4839\n",
      "Epoch 174/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 33.9115 - mae: 4.4151\n",
      "Epoch 175/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.9698 - mae: 4.1485\n",
      "Epoch 176/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 35.0020 - mae: 4.4474\n",
      "Epoch 177/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 28.4940 - mae: 4.0818\n",
      "Epoch 178/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 29.1142 - mae: 4.0122\n",
      "Epoch 179/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 35.0589 - mae: 4.2727\n",
      "Epoch 180/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 35.1385 - mae: 4.3560\n",
      "Epoch 181/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 30.5261 - mae: 4.1563\n",
      "Epoch 182/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 30.7190 - mae: 4.1339\n",
      "Epoch 183/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 31.4516 - mae: 4.1603\n",
      "Epoch 184/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 31.3985 - mae: 4.0943\n",
      "Epoch 185/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 36.5517 - mae: 4.4829\n",
      "Epoch 186/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 29.1422 - mae: 3.9741\n",
      "Epoch 187/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 31.5316 - mae: 4.2089\n",
      "Epoch 188/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 34.7627 - mae: 4.4107\n",
      "Epoch 189/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 30.9515 - mae: 4.1766\n",
      "Epoch 190/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 32.4696 - mae: 4.1755\n",
      "Epoch 191/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 35.8675 - mae: 4.3954\n",
      "Epoch 192/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 34.1369 - mae: 4.3290\n",
      "Epoch 193/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.9994 - mae: 4.1031\n",
      "Epoch 194/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 31.4093 - mae: 4.2262\n",
      "Epoch 195/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 32.0499 - mae: 4.1414\n",
      "Epoch 196/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.5333 - mae: 4.1280\n",
      "Epoch 197/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.2477 - mae: 4.1778\n",
      "Epoch 198/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 35.5793 - mae: 4.3839\n",
      "Epoch 199/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.7565 - mae: 4.1682\n",
      "Epoch 200/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.1091 - mae: 4.0080\n",
      "Epoch 201/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 31.5804 - mae: 4.2244\n",
      "Epoch 202/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.1073 - mae: 3.9071\n",
      "Epoch 203/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 30.7385 - mae: 4.1634\n",
      "Epoch 204/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 29.9484 - mae: 4.0749\n",
      "Epoch 205/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 29.3387 - mae: 4.0342\n",
      "Epoch 206/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 31.5462 - mae: 4.1815\n",
      "Epoch 207/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 30.0688 - mae: 4.2327\n",
      "Epoch 208/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 31.1767 - mae: 4.1591\n",
      "Epoch 209/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 30.5885 - mae: 4.1413\n",
      "Epoch 210/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.9851 - mae: 4.1950\n",
      "Epoch 211/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.5600 - mae: 4.2266\n",
      "Epoch 212/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 26.6258 - mae: 3.9625\n",
      "Epoch 213/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 34.2421 - mae: 4.2639\n",
      "Epoch 214/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 29.6567 - mae: 4.1674\n",
      "Epoch 215/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.1438 - mae: 4.1822\n",
      "Epoch 216/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.6089 - mae: 4.0025\n",
      "Epoch 217/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 32.3662 - mae: 4.3348\n",
      "Epoch 218/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 32.1001 - mae: 4.2989\n",
      "Epoch 219/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 31.7714 - mae: 4.2033\n",
      "Epoch 220/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 31.1500 - mae: 4.1866\n",
      "Epoch 221/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 24.3203 - mae: 3.6524\n",
      "Epoch 222/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 31.9932 - mae: 4.2618\n",
      "Epoch 223/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 31.0196 - mae: 4.1576\n",
      "Epoch 224/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 29.3177 - mae: 4.0495\n",
      "Epoch 225/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 31.4652 - mae: 4.1337\n",
      "Epoch 226/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.0478 - mae: 4.0025\n",
      "Epoch 227/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 34.6437 - mae: 4.3070\n",
      "Epoch 228/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.8795 - mae: 3.9858\n",
      "Epoch 229/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.4457 - mae: 4.1466\n",
      "Epoch 230/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.6290 - mae: 3.9641\n",
      "Epoch 231/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.7275 - mae: 3.9498\n",
      "Epoch 232/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 34.7204 - mae: 4.4520\n",
      "Epoch 233/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.1801 - mae: 4.0069\n",
      "Epoch 234/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.2576 - mae: 4.0766\n",
      "Epoch 235/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.8871 - mae: 3.9134\n",
      "Epoch 236/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 33.7734 - mae: 4.2854\n",
      "Epoch 237/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.1451 - mae: 3.9326\n",
      "Epoch 238/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.1162 - mae: 3.9884\n",
      "Epoch 239/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.2190 - mae: 4.1944\n",
      "Epoch 240/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.2758 - mae: 4.0034\n",
      "Epoch 241/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 29.2583 - mae: 4.0065\n",
      "Epoch 242/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 26.8120 - mae: 3.8704\n",
      "Epoch 243/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 26.9924 - mae: 3.9350\n",
      "Epoch 244/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.9672 - mae: 3.9033\n",
      "Epoch 245/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 29.7257 - mae: 4.0816\n",
      "Epoch 246/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.1557 - mae: 4.0033\n",
      "Epoch 247/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 31.1026 - mae: 4.1074\n",
      "Epoch 248/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.8745 - mae: 4.0543\n",
      "Epoch 249/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 25.6735 - mae: 3.8161\n",
      "Epoch 250/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 26.9117 - mae: 3.8380\n",
      "Epoch 251/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.8605 - mae: 3.9664\n",
      "Epoch 252/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.8697 - mae: 3.9520\n",
      "Epoch 253/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 29.2069 - mae: 4.0771\n",
      "Epoch 254/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 29.3241 - mae: 4.1442\n",
      "Epoch 255/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.1753 - mae: 4.0844\n",
      "Epoch 256/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 26.5747 - mae: 3.9015\n",
      "Epoch 257/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.6128 - mae: 3.8778\n",
      "Epoch 258/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 29.2338 - mae: 3.9833\n",
      "Epoch 259/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 34.1157 - mae: 4.3205\n",
      "Epoch 260/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.0140 - mae: 3.9281\n",
      "Epoch 261/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 26.1746 - mae: 3.8838\n",
      "Epoch 262/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.9140 - mae: 4.0420\n",
      "Epoch 263/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.3115 - mae: 4.0875\n",
      "Epoch 264/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 26.8875 - mae: 3.8638\n",
      "Epoch 265/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.7059 - mae: 4.0052\n",
      "Epoch 266/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 24.0100 - mae: 3.7388\n",
      "Epoch 267/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.1545 - mae: 3.9081\n",
      "Epoch 268/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 29.7907 - mae: 4.0361\n",
      "Epoch 269/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 29.1151 - mae: 3.9839\n",
      "Epoch 270/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.2864 - mae: 3.9701\n",
      "Epoch 271/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 29.6374 - mae: 4.0717\n",
      "Epoch 272/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.1714 - mae: 3.9299\n",
      "Epoch 273/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 25.8205 - mae: 3.8516\n",
      "Epoch 274/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.2156 - mae: 3.8791\n",
      "Epoch 275/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 26.7405 - mae: 3.9814\n",
      "Epoch 276/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 31.2638 - mae: 4.1275\n",
      "Epoch 277/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.2585 - mae: 3.9101\n",
      "Epoch 278/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.0547 - mae: 3.9177\n",
      "Epoch 279/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 26.6017 - mae: 3.8039\n",
      "Epoch 280/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 25.0798 - mae: 3.6962\n",
      "Epoch 281/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.1976 - mae: 4.0064\n",
      "Epoch 282/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 29.7348 - mae: 4.0754\n",
      "Epoch 283/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 26.3218 - mae: 3.7806\n",
      "Epoch 284/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 26.6369 - mae: 3.7778\n",
      "Epoch 285/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 26.1215 - mae: 3.8346\n",
      "Epoch 286/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 27.1556 - mae: 3.8937\n",
      "Epoch 287/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 28.6679 - mae: 3.9671\n",
      "Epoch 288/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 30.7857 - mae: 4.1386\n",
      "Epoch 289/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 25.0479 - mae: 3.7571\n",
      "Epoch 290/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 23.7450 - mae: 3.5381\n",
      "Epoch 291/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 33.8691 - mae: 4.2713\n",
      "Epoch 292/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 23.5309 - mae: 3.7065\n",
      "Epoch 293/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 25.2793 - mae: 3.8154\n",
      "Epoch 294/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 25.6589 - mae: 3.7817\n",
      "Epoch 295/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 25.1257 - mae: 3.7910\n",
      "Epoch 296/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 29.4878 - mae: 4.0405\n",
      "Epoch 297/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 24.1705 - mae: 3.6811\n",
      "Epoch 298/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 27.2228 - mae: 3.7912\n",
      "Epoch 299/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 26.5895 - mae: 3.8219\n",
      "Epoch 300/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 25.9669 - mae: 3.8316\n",
      "Epoch 301/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 25.4899 - mae: 3.8607\n",
      "Epoch 302/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 26.1485 - mae: 3.8302\n",
      "Epoch 303/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 26.1617 - mae: 3.7671\n",
      "Epoch 304/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 26.9393 - mae: 3.9090\n",
      "Epoch 305/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 23.8182 - mae: 3.6413\n",
      "Epoch 306/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 25.5747 - mae: 3.7981\n",
      "Epoch 307/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 26.6032 - mae: 3.8671\n",
      "Epoch 308/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 25.5517 - mae: 3.8193\n",
      "Epoch 309/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 23.9842 - mae: 3.6313\n",
      "Epoch 310/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 23.9322 - mae: 3.6831\n",
      "Epoch 311/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 25.5166 - mae: 3.7079\n",
      "Epoch 312/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 23.9409 - mae: 3.6315\n",
      "Epoch 313/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 28.4646 - mae: 3.9108\n",
      "Epoch 314/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 24.0246 - mae: 3.6818\n",
      "Epoch 315/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 24.3924 - mae: 3.7110\n",
      "Epoch 316/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 28.2319 - mae: 3.8368\n",
      "Epoch 317/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 25.0966 - mae: 3.7549\n",
      "Epoch 318/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 23.7884 - mae: 3.5834\n",
      "Epoch 319/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 29.2037 - mae: 3.9915\n",
      "Epoch 320/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 25.2475 - mae: 3.7872\n",
      "Epoch 321/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 27.3138 - mae: 3.8592\n",
      "Epoch 322/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 24.7237 - mae: 3.7289\n",
      "Epoch 323/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 22.8633 - mae: 3.6430\n",
      "Epoch 324/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 23.9005 - mae: 3.7556\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 3s 4ms/sample - loss: 27.9994 - mae: 3.9716\n",
      "Epoch 326/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.6201 - mae: 3.7535\n",
      "Epoch 327/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 33.3961 - mae: 4.2145\n",
      "Epoch 328/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.4158 - mae: 3.5790\n",
      "Epoch 329/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.0013 - mae: 3.7431\n",
      "Epoch 330/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 25.1572 - mae: 3.5925\n",
      "Epoch 331/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 23.3005 - mae: 3.6372\n",
      "Epoch 332/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 24.6555 - mae: 3.6829\n",
      "Epoch 333/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 23.3420 - mae: 3.6743\n",
      "Epoch 334/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.0142 - mae: 3.5963\n",
      "Epoch 335/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.4802 - mae: 3.7166\n",
      "Epoch 336/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 24.6544 - mae: 3.7598\n",
      "Epoch 337/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 26.1546 - mae: 3.7976\n",
      "Epoch 338/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 27.3614 - mae: 3.7478\n",
      "Epoch 339/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 23.9964 - mae: 3.6949\n",
      "Epoch 340/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 26.2546 - mae: 3.7989\n",
      "Epoch 341/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 23.3432 - mae: 3.6182\n",
      "Epoch 342/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 27.4215 - mae: 3.8663\n",
      "Epoch 343/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 23.9957 - mae: 3.7043\n",
      "Epoch 344/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 22.4658 - mae: 3.5183\n",
      "Epoch 345/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 24.9801 - mae: 3.6823\n",
      "Epoch 346/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 25.4952 - mae: 3.7520\n",
      "Epoch 347/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 24.5113 - mae: 3.6932\n",
      "Epoch 348/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 22.9141 - mae: 3.5906\n",
      "Epoch 349/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 27.9608 - mae: 3.8850\n",
      "Epoch 350/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 22.8576 - mae: 3.5496\n",
      "Epoch 351/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 26.0108 - mae: 3.7588\n",
      "Epoch 352/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.9977 - mae: 3.6066\n",
      "Epoch 353/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.6863 - mae: 3.6098\n",
      "Epoch 354/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.6182 - mae: 3.6440\n",
      "Epoch 355/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.2700 - mae: 3.6924\n",
      "Epoch 356/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 36.2696 - mae: 4.3695\n",
      "Epoch 357/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 25.7710 - mae: 3.7750\n",
      "Epoch 358/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.2280 - mae: 3.6564\n",
      "Epoch 359/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.5346 - mae: 3.6906\n",
      "Epoch 360/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 29.0027 - mae: 4.0151\n",
      "Epoch 361/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.8178 - mae: 3.6567\n",
      "Epoch 362/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.7335 - mae: 3.7843\n",
      "Epoch 363/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.5474 - mae: 3.7644\n",
      "Epoch 364/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.7870 - mae: 3.5438\n",
      "Epoch 365/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.4923 - mae: 3.7188\n",
      "Epoch 366/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 23.0466 - mae: 3.5868\n",
      "Epoch 367/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.8341 - mae: 3.6694\n",
      "Epoch 368/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.8102 - mae: 3.5815\n",
      "Epoch 369/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.4753 - mae: 3.5291\n",
      "Epoch 370/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 29.4543 - mae: 4.0441\n",
      "Epoch 371/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.4934 - mae: 3.6968\n",
      "Epoch 372/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.2798 - mae: 3.6224\n",
      "Epoch 373/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.6154 - mae: 3.6914\n",
      "Epoch 374/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.7132 - mae: 3.5811\n",
      "Epoch 375/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.2610 - mae: 3.5118\n",
      "Epoch 376/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.3957 - mae: 3.5422\n",
      "Epoch 377/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.3999 - mae: 3.8418\n",
      "Epoch 378/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.6406 - mae: 3.4875\n",
      "Epoch 379/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 26.0777 - mae: 3.8056\n",
      "Epoch 380/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.0914 - mae: 3.7613\n",
      "Epoch 381/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.8224 - mae: 3.6179\n",
      "Epoch 382/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.0923 - mae: 3.5014\n",
      "Epoch 383/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.6322 - mae: 3.4807\n",
      "Epoch 384/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.7953 - mae: 3.6316\n",
      "Epoch 385/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.8087 - mae: 3.7883\n",
      "Epoch 386/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.6645 - mae: 3.7037\n",
      "Epoch 387/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.9185 - mae: 3.6939\n",
      "Epoch 388/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.5025 - mae: 3.7826\n",
      "Epoch 389/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.4515 - mae: 3.4849\n",
      "Epoch 390/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.4814 - mae: 3.5825\n",
      "Epoch 391/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.6234 - mae: 3.5733\n",
      "Epoch 392/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.2522 - mae: 3.6977\n",
      "Epoch 393/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.9632 - mae: 3.4172\n",
      "Epoch 394/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.9170 - mae: 3.6128\n",
      "Epoch 395/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.1037 - mae: 3.6241\n",
      "Epoch 396/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.3774 - mae: 3.3868\n",
      "Epoch 397/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.7026 - mae: 3.3147\n",
      "Epoch 398/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.6494 - mae: 3.7310\n",
      "Epoch 399/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.1246 - mae: 3.5733\n",
      "Epoch 400/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.3245 - mae: 3.5593\n",
      "Epoch 401/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.2117 - mae: 3.6586\n",
      "Epoch 402/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.2187 - mae: 3.4051\n",
      "Epoch 403/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.6569 - mae: 3.6334\n",
      "Epoch 404/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 23.2357 - mae: 3.5913\n",
      "Epoch 405/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 25.2365 - mae: 3.7769\n",
      "Epoch 406/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.7799 - mae: 3.5377\n",
      "Epoch 407/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 21.3211 - mae: 3.4450\n",
      "Epoch 408/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.2304 - mae: 3.5826\n",
      "Epoch 409/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.2295 - mae: 3.5324\n",
      "Epoch 410/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 22.4324 - mae: 3.5669\n",
      "Epoch 411/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.5160 - mae: 3.7448\n",
      "Epoch 412/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.5368 - mae: 3.5340\n",
      "Epoch 413/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.5298 - mae: 3.4623\n",
      "Epoch 414/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 33.8266 - mae: 4.2251\n",
      "Epoch 415/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.8923 - mae: 3.3971\n",
      "Epoch 416/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.1299 - mae: 3.5054\n",
      "Epoch 417/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.3353 - mae: 3.4729\n",
      "Epoch 418/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.9333 - mae: 3.5183\n",
      "Epoch 419/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.9753 - mae: 3.5178\n",
      "Epoch 420/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.2719 - mae: 3.5320\n",
      "Epoch 421/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.4271 - mae: 3.4552\n",
      "Epoch 422/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.6655 - mae: 3.6648\n",
      "Epoch 423/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.5777 - mae: 3.4710\n",
      "Epoch 424/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.6813 - mae: 3.5436\n",
      "Epoch 425/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.0298 - mae: 3.4311\n",
      "Epoch 426/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.3354 - mae: 3.3893\n",
      "Epoch 427/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 20.2769 - mae: 3.4050\n",
      "Epoch 428/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.4261 - mae: 3.5079\n",
      "Epoch 429/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 26.0965 - mae: 3.7731\n",
      "Epoch 430/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.4559 - mae: 3.3237\n",
      "Epoch 431/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.5533 - mae: 3.4160\n",
      "Epoch 432/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.2142 - mae: 3.4798\n",
      "Epoch 433/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.0543 - mae: 3.6810\n",
      "Epoch 434/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.6957 - mae: 3.3723\n",
      "Epoch 435/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.2341 - mae: 3.3292\n",
      "Epoch 436/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 25.6456 - mae: 3.7366\n",
      "Epoch 437/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.2715 - mae: 3.5089\n",
      "Epoch 438/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.9439 - mae: 3.4164\n",
      "Epoch 439/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.2559 - mae: 3.3143\n",
      "Epoch 440/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.4528 - mae: 3.5725\n",
      "Epoch 441/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.1196 - mae: 3.4498\n",
      "Epoch 442/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.7651 - mae: 3.5327\n",
      "Epoch 443/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.6234 - mae: 3.6424\n",
      "Epoch 444/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.9876 - mae: 3.5301\n",
      "Epoch 445/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 22.3666 - mae: 3.4962\n",
      "Epoch 446/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 36.0169 - mae: 4.3074\n",
      "Epoch 447/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.6848 - mae: 3.6680\n",
      "Epoch 448/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.9447 - mae: 3.3925\n",
      "Epoch 449/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.1952 - mae: 3.4794\n",
      "Epoch 450/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.1525 - mae: 3.5778\n",
      "Epoch 451/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.5774 - mae: 3.4277\n",
      "Epoch 452/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.1205 - mae: 3.5089\n",
      "Epoch 453/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.5233 - mae: 3.5489\n",
      "Epoch 454/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 17.8661 - mae: 3.0862\n",
      "Epoch 455/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.8637 - mae: 3.5528\n",
      "Epoch 456/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.1632 - mae: 3.3466\n",
      "Epoch 457/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 27.2236 - mae: 3.8657\n",
      "Epoch 458/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.7116 - mae: 3.2632\n",
      "Epoch 459/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.7723 - mae: 3.3461\n",
      "Epoch 460/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.1438 - mae: 3.6884\n",
      "Epoch 461/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.6434 - mae: 3.4969\n",
      "Epoch 462/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.2635 - mae: 3.4200\n",
      "Epoch 463/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5688 - mae: 3.4434\n",
      "Epoch 464/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.8476 - mae: 3.5525\n",
      "Epoch 465/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.3281 - mae: 3.3083\n",
      "Epoch 466/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.1272 - mae: 3.3271\n",
      "Epoch 467/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.0561 - mae: 3.2584\n",
      "Epoch 468/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.5203 - mae: 3.5278\n",
      "Epoch 469/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.5171 - mae: 3.5918\n",
      "Epoch 470/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.8931 - mae: 3.2880\n",
      "Epoch 471/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5050 - mae: 3.3439\n",
      "Epoch 472/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.0475 - mae: 3.3507\n",
      "Epoch 473/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.3868 - mae: 3.3623\n",
      "Epoch 474/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.1804 - mae: 3.3177\n",
      "Epoch 475/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.3381 - mae: 3.4059\n",
      "Epoch 476/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.4005 - mae: 3.5852\n",
      "Epoch 477/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.8353 - mae: 3.4093\n",
      "Epoch 478/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.1551 - mae: 3.3405\n",
      "Epoch 479/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 22.6188 - mae: 3.5535\n",
      "Epoch 480/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 20.1446 - mae: 3.2922\n",
      "Epoch 481/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.7392 - mae: 3.3687\n",
      "Epoch 482/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.8380 - mae: 3.3087\n",
      "Epoch 483/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.8409 - mae: 3.3905\n",
      "Epoch 484/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5311 - mae: 3.3869\n",
      "Epoch 485/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.1577 - mae: 3.3482\n",
      "Epoch 486/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.7057 - mae: 3.7713\n",
      "Epoch 487/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.6695 - mae: 3.4170\n",
      "Epoch 488/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.9317 - mae: 3.2328\n",
      "Epoch 489/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.0398 - mae: 3.3301\n",
      "Epoch 490/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.3174 - mae: 3.3971\n",
      "Epoch 491/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.1061 - mae: 3.5602\n",
      "Epoch 492/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.6211 - mae: 3.3436\n",
      "Epoch 493/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.1130 - mae: 3.3417\n",
      "Epoch 494/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.8485 - mae: 3.3572\n",
      "Epoch 495/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 26.9475 - mae: 3.9059\n",
      "Epoch 496/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.5617 - mae: 3.4843\n",
      "Epoch 497/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.9725 - mae: 3.5896\n",
      "Epoch 498/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.4866 - mae: 3.4142\n",
      "Epoch 499/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.2287 - mae: 3.2832\n",
      "Epoch 500/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 21.1783 - mae: 3.4651\n",
      "processing fold #  1\n",
      "Train on 696 samples\n",
      "Epoch 1/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 32.4437 - mae: 4.0705\n",
      "Epoch 2/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 27.2953 - mae: 3.8176\n",
      "Epoch 3/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.5141 - mae: 3.6707\n",
      "Epoch 4/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 28.1843 - mae: 3.9042\n",
      "Epoch 5/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 26.5750 - mae: 3.8064\n",
      "Epoch 6/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.9548 - mae: 3.7224\n",
      "Epoch 7/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 26.2367 - mae: 3.7792\n",
      "Epoch 8/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.8162 - mae: 3.6916\n",
      "Epoch 9/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.3896 - mae: 3.7009\n",
      "Epoch 10/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.8467 - mae: 3.7222\n",
      "Epoch 11/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.1685 - mae: 3.3991\n",
      "Epoch 12/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.6754 - mae: 3.5775\n",
      "Epoch 13/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.5860 - mae: 3.7792\n",
      "Epoch 14/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.8786 - mae: 3.5783\n",
      "Epoch 15/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.3477 - mae: 3.5010\n",
      "Epoch 16/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.4015 - mae: 3.5352\n",
      "Epoch 17/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 26.4111 - mae: 3.7464\n",
      "Epoch 18/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 26.1275 - mae: 3.7903\n",
      "Epoch 19/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.2117 - mae: 3.5850\n",
      "Epoch 20/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.5355 - mae: 3.4368\n",
      "Epoch 21/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.3631 - mae: 3.5359\n",
      "Epoch 22/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.0505 - mae: 3.6220\n",
      "Epoch 23/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.5746 - mae: 3.6214\n",
      "Epoch 24/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.9327 - mae: 3.5283\n",
      "Epoch 25/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 21.9657 - mae: 3.4618\n",
      "Epoch 26/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 21.2495 - mae: 3.4452\n",
      "Epoch 27/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.4723 - mae: 3.7287\n",
      "Epoch 28/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.9615 - mae: 3.3487\n",
      "Epoch 29/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.5129 - mae: 3.6867\n",
      "Epoch 30/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.8353 - mae: 3.5195\n",
      "Epoch 31/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.6702 - mae: 3.4567\n",
      "Epoch 32/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 22.2337 - mae: 3.3962\n",
      "Epoch 33/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.6086 - mae: 3.3563\n",
      "Epoch 34/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.4332 - mae: 3.4545\n",
      "Epoch 35/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.9199 - mae: 3.3326\n",
      "Epoch 36/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.2222 - mae: 3.4235\n",
      "Epoch 37/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.0936 - mae: 3.5018\n",
      "Epoch 38/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.3140 - mae: 3.4426\n",
      "Epoch 39/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5735 - mae: 3.4127\n",
      "Epoch 40/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.8255 - mae: 3.4153\n",
      "Epoch 41/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.1092 - mae: 3.4445\n",
      "Epoch 42/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.2934 - mae: 3.4668\n",
      "Epoch 43/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.4263 - mae: 3.5360\n",
      "Epoch 44/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.4663 - mae: 3.5762\n",
      "Epoch 45/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 25.2597 - mae: 3.6930\n",
      "Epoch 46/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 19.9705 - mae: 3.2593\n",
      "Epoch 47/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.0007 - mae: 3.4502\n",
      "Epoch 48/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 24.2521 - mae: 3.5312\n",
      "Epoch 49/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 23.3883 - mae: 3.5663\n",
      "Epoch 50/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 22.0928 - mae: 3.4632\n",
      "Epoch 51/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 19.7629 - mae: 3.3389\n",
      "Epoch 52/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 20.5708 - mae: 3.3290\n",
      "Epoch 53/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 22.7008 - mae: 3.4700\n",
      "Epoch 54/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 22.5348 - mae: 3.4488\n",
      "Epoch 55/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 20.7104 - mae: 3.3031\n",
      "Epoch 56/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 21.1038 - mae: 3.4340\n",
      "Epoch 57/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.1520 - mae: 3.4794\n",
      "Epoch 58/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 21.1377 - mae: 3.4363\n",
      "Epoch 59/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.7505 - mae: 3.4984\n",
      "Epoch 60/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 20.8008 - mae: 3.3443\n",
      "Epoch 61/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 21.2729 - mae: 3.4163\n",
      "Epoch 62/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 23.0349 - mae: 3.5680\n",
      "Epoch 63/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 20.8839 - mae: 3.4622\n",
      "Epoch 64/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 20.3488 - mae: 3.3567\n",
      "Epoch 65/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 21.9406 - mae: 3.4920\n",
      "Epoch 66/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 20.9309 - mae: 3.3858\n",
      "Epoch 67/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 20.9735 - mae: 3.3353\n",
      "Epoch 68/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 20.2814 - mae: 3.2337\n",
      "Epoch 69/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 20.3015 - mae: 3.3202\n",
      "Epoch 70/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 22.2625 - mae: 3.4972\n",
      "Epoch 71/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 19.4310 - mae: 3.2260\n",
      "Epoch 72/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 19.6111 - mae: 3.3103\n",
      "Epoch 73/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.5250 - mae: 3.3035\n",
      "Epoch 74/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 19.8516 - mae: 3.3028\n",
      "Epoch 75/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.2815 - mae: 3.3638\n",
      "Epoch 76/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.3776 - mae: 3.4534\n",
      "Epoch 77/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.1694 - mae: 3.3533\n",
      "Epoch 78/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.6563 - mae: 3.3787\n",
      "Epoch 79/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.8924 - mae: 3.3297\n",
      "Epoch 80/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.6080 - mae: 3.4857\n",
      "Epoch 81/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.9433 - mae: 3.4272\n",
      "Epoch 82/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.5570 - mae: 3.5887\n",
      "Epoch 83/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 20.5711 - mae: 3.3298\n",
      "Epoch 84/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.5086 - mae: 3.2557\n",
      "Epoch 85/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.4150 - mae: 3.4543\n",
      "Epoch 86/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.4243 - mae: 3.3219\n",
      "Epoch 87/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.6554 - mae: 3.6995\n",
      "Epoch 88/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.3700 - mae: 3.1746\n",
      "Epoch 89/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.8316 - mae: 3.4531\n",
      "Epoch 90/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.4270 - mae: 3.4441\n",
      "Epoch 91/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.8710 - mae: 3.2750\n",
      "Epoch 92/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 21.0967 - mae: 3.3979\n",
      "Epoch 93/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.9932 - mae: 3.3664\n",
      "Epoch 94/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.4521 - mae: 3.4840\n",
      "Epoch 95/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5431 - mae: 3.3152\n",
      "Epoch 96/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.1925 - mae: 3.2033\n",
      "Epoch 97/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.7003 - mae: 3.2587\n",
      "Epoch 98/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.1128 - mae: 3.1353\n",
      "Epoch 99/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.6045 - mae: 3.1213\n",
      "Epoch 100/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 22.6868 - mae: 3.4220\n",
      "Epoch 101/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.5256 - mae: 3.2389\n",
      "Epoch 102/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.2577 - mae: 3.1844\n",
      "Epoch 103/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.9785 - mae: 3.2325\n",
      "Epoch 104/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.9111 - mae: 3.3744\n",
      "Epoch 105/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.5154 - mae: 2.9958\n",
      "Epoch 106/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.3798 - mae: 3.2506\n",
      "Epoch 107/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.1346 - mae: 3.5383\n",
      "Epoch 108/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 24.1447 - mae: 3.5471\n",
      "Epoch 109/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.6722 - mae: 3.2565\n",
      "Epoch 110/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.0518 - mae: 3.1866\n",
      "Epoch 111/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.3349 - mae: 3.3357\n",
      "Epoch 112/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.0537 - mae: 3.3407\n",
      "Epoch 113/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.5296 - mae: 3.2825\n",
      "Epoch 114/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.4271 - mae: 3.3066\n",
      "Epoch 115/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.7801 - mae: 3.1981\n",
      "Epoch 116/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.3960 - mae: 3.2146\n",
      "Epoch 117/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.3371 - mae: 3.3082\n",
      "Epoch 118/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.1725 - mae: 3.2432\n",
      "Epoch 119/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.1209 - mae: 3.2255\n",
      "Epoch 120/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.8786 - mae: 3.3869\n",
      "Epoch 121/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.5903 - mae: 3.1481\n",
      "Epoch 122/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 20.6778 - mae: 3.3371\n",
      "Epoch 123/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 19.3152 - mae: 3.2433\n",
      "Epoch 124/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.1900 - mae: 3.3671\n",
      "Epoch 125/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 18.5054 - mae: 3.1287\n",
      "Epoch 126/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 17.2593 - mae: 3.0514\n",
      "Epoch 127/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 17.5273 - mae: 3.1390\n",
      "Epoch 128/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 19.7129 - mae: 3.2651\n",
      "Epoch 129/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 18.1351 - mae: 3.1491\n",
      "Epoch 130/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.2988 - mae: 3.2017\n",
      "Epoch 131/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.0019 - mae: 3.2480\n",
      "Epoch 132/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.1652 - mae: 3.0363\n",
      "Epoch 133/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.7814 - mae: 3.0480\n",
      "Epoch 134/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5432 - mae: 3.3061\n",
      "Epoch 135/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.7442 - mae: 3.0891\n",
      "Epoch 136/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.2378 - mae: 3.1967\n",
      "Epoch 137/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.1687 - mae: 3.4301\n",
      "Epoch 138/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.6057 - mae: 3.2290\n",
      "Epoch 139/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.1252 - mae: 3.2443\n",
      "Epoch 140/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.5676 - mae: 3.4201\n",
      "Epoch 141/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.1164 - mae: 3.2313\n",
      "Epoch 142/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.1871 - mae: 3.1129\n",
      "Epoch 143/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.0109 - mae: 3.3498\n",
      "Epoch 144/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 21.3940 - mae: 3.4280\n",
      "Epoch 145/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.5022 - mae: 3.1690\n",
      "Epoch 146/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5904 - mae: 3.3439\n",
      "Epoch 147/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.3414 - mae: 3.1873\n",
      "Epoch 148/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.3895 - mae: 3.0596\n",
      "Epoch 149/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.6906 - mae: 3.2067\n",
      "Epoch 150/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.7121 - mae: 3.1431\n",
      "Epoch 151/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.1860 - mae: 3.0758\n",
      "Epoch 152/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.5201 - mae: 3.2682\n",
      "Epoch 153/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.0750 - mae: 3.1221\n",
      "Epoch 154/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.9484 - mae: 3.3221\n",
      "Epoch 155/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 19.3249 - mae: 3.2830\n",
      "Epoch 156/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.7337 - mae: 3.1873\n",
      "Epoch 157/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.4533 - mae: 3.0924\n",
      "Epoch 158/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.0796 - mae: 3.2424\n",
      "Epoch 159/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.2754 - mae: 3.0456\n",
      "Epoch 160/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.7253 - mae: 3.3604\n",
      "Epoch 161/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 21.6843 - mae: 3.4373\n",
      "Epoch 162/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 16.8803 - mae: 2.9849\n",
      "Epoch 163/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.0552 - mae: 3.3107\n",
      "Epoch 164/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.7893 - mae: 3.1368\n",
      "Epoch 165/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.6027 - mae: 3.0842\n",
      "Epoch 166/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.7845 - mae: 3.1339\n",
      "Epoch 167/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.2537 - mae: 3.1782\n",
      "Epoch 168/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.0137 - mae: 3.3352\n",
      "Epoch 169/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.9830 - mae: 3.1146\n",
      "Epoch 170/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.4473 - mae: 3.1408\n",
      "Epoch 171/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.6477 - mae: 3.1438\n",
      "Epoch 172/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.5798 - mae: 3.2593\n",
      "Epoch 173/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.0383 - mae: 3.1717\n",
      "Epoch 174/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 21.2159 - mae: 3.3709\n",
      "Epoch 175/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.1773 - mae: 3.1364\n",
      "Epoch 176/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.5835 - mae: 3.1190\n",
      "Epoch 177/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.4978 - mae: 3.2093\n",
      "Epoch 178/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5415 - mae: 3.3311\n",
      "Epoch 179/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 19.7940 - mae: 3.2498\n",
      "Epoch 180/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.8104 - mae: 3.2672\n",
      "Epoch 181/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.6644 - mae: 3.1837\n",
      "Epoch 182/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.1801 - mae: 2.9814\n",
      "Epoch 183/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.2771 - mae: 3.1667\n",
      "Epoch 184/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5702 - mae: 3.3677\n",
      "Epoch 185/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.9749 - mae: 3.1258\n",
      "Epoch 186/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.4405 - mae: 3.4821\n",
      "Epoch 187/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.1836 - mae: 3.2394\n",
      "Epoch 188/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.3656 - mae: 3.0562\n",
      "Epoch 189/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.1024 - mae: 3.1527\n",
      "Epoch 190/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.8993 - mae: 3.1570\n",
      "Epoch 191/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.4475 - mae: 3.1081\n",
      "Epoch 192/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.9618 - mae: 3.2303\n",
      "Epoch 193/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.5126 - mae: 2.9911\n",
      "Epoch 194/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.5359 - mae: 3.0243\n",
      "Epoch 195/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.7425 - mae: 3.3066\n",
      "Epoch 196/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 18.7786 - mae: 3.1829\n",
      "Epoch 197/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.4660 - mae: 3.0992\n",
      "Epoch 198/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.8196 - mae: 3.1438\n",
      "Epoch 199/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.9648 - mae: 3.1781\n",
      "Epoch 200/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.3939 - mae: 3.2072\n",
      "Epoch 201/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.1278 - mae: 3.2146\n",
      "Epoch 202/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.6396 - mae: 3.0913\n",
      "Epoch 203/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.7133 - mae: 3.2608\n",
      "Epoch 204/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 22.4148 - mae: 3.4376\n",
      "Epoch 205/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 16.1512 - mae: 2.9516\n",
      "Epoch 206/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 15.8692 - mae: 2.9619\n",
      "Epoch 207/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 23.1532 - mae: 3.5342\n",
      "Epoch 208/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.2637 - mae: 3.2455\n",
      "Epoch 209/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.3320 - mae: 3.0299\n",
      "Epoch 210/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.7435 - mae: 3.1385\n",
      "Epoch 211/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.8267 - mae: 3.0562\n",
      "Epoch 212/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.3324 - mae: 3.3545\n",
      "Epoch 213/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.8052 - mae: 3.0767\n",
      "Epoch 214/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 17.7078 - mae: 3.1376\n",
      "Epoch 215/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.6470 - mae: 3.0981\n",
      "Epoch 216/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5959 - mae: 3.3041\n",
      "Epoch 217/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.1181 - mae: 3.0858\n",
      "Epoch 218/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.5420 - mae: 3.1868\n",
      "Epoch 219/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.3012 - mae: 3.2315\n",
      "Epoch 220/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.9736 - mae: 3.1969\n",
      "Epoch 221/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.3523 - mae: 3.0227\n",
      "Epoch 222/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.3599 - mae: 3.1940\n",
      "Epoch 223/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.4904 - mae: 3.3469\n",
      "Epoch 224/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.0138 - mae: 3.1316\n",
      "Epoch 225/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.3402 - mae: 2.9293\n",
      "Epoch 226/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.6597 - mae: 2.9554\n",
      "Epoch 227/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.1386 - mae: 3.1971\n",
      "Epoch 228/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 19.0086 - mae: 3.2198\n",
      "Epoch 229/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 17.0791 - mae: 3.1147\n",
      "Epoch 230/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 16.9151 - mae: 3.1027\n",
      "Epoch 231/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 17.5113 - mae: 3.0554\n",
      "Epoch 232/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 18.2600 - mae: 3.1926\n",
      "Epoch 233/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.6076 - mae: 3.2033\n",
      "Epoch 234/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.5788 - mae: 3.1071\n",
      "Epoch 235/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.0180 - mae: 3.1481\n",
      "Epoch 236/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 18.3148 - mae: 3.0786\n",
      "Epoch 237/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 16.4885 - mae: 3.0069\n",
      "Epoch 238/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 17.7359 - mae: 3.0621\n",
      "Epoch 239/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.8116 - mae: 3.0000\n",
      "Epoch 240/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.5803 - mae: 3.2131\n",
      "Epoch 241/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.3411 - mae: 3.1333\n",
      "Epoch 242/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 13.9184 - mae: 2.7966\n",
      "Epoch 243/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 16.9506 - mae: 3.0209\n",
      "Epoch 244/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 17.1160 - mae: 3.0679\n",
      "Epoch 245/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 17.2884 - mae: 3.0521\n",
      "Epoch 246/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 19.3161 - mae: 3.2283\n",
      "Epoch 247/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.0144 - mae: 2.9891\n",
      "Epoch 248/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.6150 - mae: 3.1856\n",
      "Epoch 249/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.2275 - mae: 2.9765\n",
      "Epoch 250/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.1506 - mae: 3.2046\n",
      "Epoch 251/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.7397 - mae: 3.0797\n",
      "Epoch 252/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.7330 - mae: 3.0816\n",
      "Epoch 253/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.8172 - mae: 3.1647\n",
      "Epoch 254/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.1094 - mae: 3.1118\n",
      "Epoch 255/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.2291 - mae: 3.0108\n",
      "Epoch 256/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.4199 - mae: 2.9711\n",
      "Epoch 257/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.8978 - mae: 3.2311\n",
      "Epoch 258/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.4931 - mae: 3.1260\n",
      "Epoch 259/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 18.1783 - mae: 3.1075\n",
      "Epoch 260/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 16.3814 - mae: 2.9415\n",
      "Epoch 261/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5005 - mae: 3.2781\n",
      "Epoch 262/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.5026 - mae: 2.9907\n",
      "Epoch 263/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.3363 - mae: 3.0443\n",
      "Epoch 264/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.2495 - mae: 3.1251\n",
      "Epoch 265/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.1500 - mae: 3.0464\n",
      "Epoch 266/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5892 - mae: 3.3030\n",
      "Epoch 267/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.7182 - mae: 3.1216\n",
      "Epoch 268/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.0710 - mae: 3.0290\n",
      "Epoch 269/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.0049 - mae: 2.9376\n",
      "Epoch 270/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.8192 - mae: 2.9611\n",
      "Epoch 271/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.3881 - mae: 3.0711\n",
      "Epoch 272/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.7599 - mae: 3.1086\n",
      "Epoch 273/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.3901 - mae: 2.9433\n",
      "Epoch 274/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.4681 - mae: 3.1673\n",
      "Epoch 275/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.7462 - mae: 3.0248\n",
      "Epoch 276/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.0491 - mae: 3.1230\n",
      "Epoch 277/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.6395 - mae: 3.1315\n",
      "Epoch 278/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.4922 - mae: 3.0615\n",
      "Epoch 279/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.0700 - mae: 3.0032\n",
      "Epoch 280/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.3541 - mae: 2.9191\n",
      "Epoch 281/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.1156 - mae: 3.0692\n",
      "Epoch 282/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.9262 - mae: 3.0346\n",
      "Epoch 283/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.5207 - mae: 3.0815\n",
      "Epoch 284/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 17.0305 - mae: 2.9889\n",
      "Epoch 285/500\n",
      "696/696 [==============================] - 4s 6ms/sample - loss: 16.0780 - mae: 2.9384\n",
      "Epoch 286/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.1891 - mae: 2.9983\n",
      "Epoch 287/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.1249 - mae: 3.1103\n",
      "Epoch 288/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.9153 - mae: 2.9488\n",
      "Epoch 289/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.0352 - mae: 2.9760\n",
      "Epoch 290/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.4008 - mae: 3.0059\n",
      "Epoch 291/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.4477 - mae: 3.0581\n",
      "Epoch 292/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.7467 - mae: 2.8354\n",
      "Epoch 293/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.6936 - mae: 2.9660\n",
      "Epoch 294/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.6597 - mae: 3.0709\n",
      "Epoch 295/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 14.9859 - mae: 2.8020\n",
      "Epoch 296/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.5820 - mae: 3.1118\n",
      "Epoch 297/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.6406 - mae: 3.2488\n",
      "Epoch 298/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.8134 - mae: 2.9811\n",
      "Epoch 299/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.0819 - mae: 2.8793\n",
      "Epoch 300/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.3156 - mae: 2.9043\n",
      "Epoch 301/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.7536 - mae: 2.9547\n",
      "Epoch 302/500\n",
      "696/696 [==============================] - 4s 5ms/sample - loss: 15.2306 - mae: 2.8633\n",
      "Epoch 303/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.5035 - mae: 3.1526\n",
      "Epoch 304/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 14.6827 - mae: 2.7899\n",
      "Epoch 305/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.2379 - mae: 3.0389\n",
      "Epoch 306/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 19.0933 - mae: 3.2228\n",
      "Epoch 307/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.5212 - mae: 3.0733\n",
      "Epoch 308/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.6124 - mae: 2.8331\n",
      "Epoch 309/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.1332 - mae: 3.0097\n",
      "Epoch 310/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 20.5253 - mae: 3.3627\n",
      "Epoch 311/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.4046 - mae: 2.9487\n",
      "Epoch 312/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.8263 - mae: 2.9198\n",
      "Epoch 313/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.1386 - mae: 3.1283\n",
      "Epoch 314/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.1021 - mae: 3.1662\n",
      "Epoch 315/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.2479 - mae: 2.8155\n",
      "Epoch 316/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 14.7215 - mae: 2.7883\n",
      "Epoch 317/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.8587 - mae: 3.0305\n",
      "Epoch 318/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.8092 - mae: 3.0402\n",
      "Epoch 319/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 14.0736 - mae: 2.7181\n",
      "Epoch 320/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.1618 - mae: 2.9309\n",
      "Epoch 321/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.9000 - mae: 2.8932\n",
      "Epoch 322/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.8754 - mae: 2.9725\n",
      "Epoch 323/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.5604 - mae: 3.0434\n",
      "Epoch 324/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.4881 - mae: 2.9195\n",
      "Epoch 325/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.5067 - mae: 2.9712\n",
      "Epoch 326/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 14.2837 - mae: 2.8093\n",
      "Epoch 327/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.9905 - mae: 3.0029\n",
      "Epoch 328/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.5806 - mae: 2.9269\n",
      "Epoch 329/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.1788 - mae: 3.0236\n",
      "Epoch 330/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 14.3715 - mae: 2.7812\n",
      "Epoch 331/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.9127 - mae: 3.1045\n",
      "Epoch 332/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 18.6678 - mae: 3.2147\n",
      "Epoch 333/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.3517 - mae: 2.9863\n",
      "Epoch 334/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.5694 - mae: 3.0855\n",
      "Epoch 335/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.8351 - mae: 3.0324\n",
      "Epoch 336/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.7875 - mae: 2.9593\n",
      "Epoch 337/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.8829 - mae: 2.9319\n",
      "Epoch 338/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.8513 - mae: 2.9845\n",
      "Epoch 339/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 15.8537 - mae: 2.8947\n",
      "Epoch 340/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.7230 - mae: 3.0966\n",
      "Epoch 341/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 14.7521 - mae: 2.8806\n",
      "Epoch 342/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.9836 - mae: 3.1173\n",
      "Epoch 343/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 17.2327 - mae: 3.0027\n",
      "Epoch 344/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.2018 - mae: 2.8698\n",
      "Epoch 345/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.1470 - mae: 2.9576\n",
      "Epoch 346/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.2696 - mae: 3.0405\n",
      "Epoch 347/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.3391 - mae: 2.8708\n",
      "Epoch 348/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.4416 - mae: 2.9736\n",
      "Epoch 349/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.9099 - mae: 3.0027\n",
      "Epoch 350/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.2648 - mae: 2.8509\n",
      "Epoch 351/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.9409 - mae: 2.9883\n",
      "Epoch 352/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1983 - mae: 2.7596\n",
      "Epoch 353/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.1371 - mae: 3.0015\n",
      "Epoch 354/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.1597 - mae: 2.9759\n",
      "Epoch 355/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8886 - mae: 2.9208\n",
      "Epoch 356/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.6016 - mae: 2.9682\n",
      "Epoch 357/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.5054 - mae: 3.0060\n",
      "Epoch 358/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.3756 - mae: 2.9164\n",
      "Epoch 359/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8916 - mae: 2.9130\n",
      "Epoch 360/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.8033 - mae: 3.0670\n",
      "Epoch 361/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.6435 - mae: 2.9500\n",
      "Epoch 362/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.7057 - mae: 3.1437\n",
      "Epoch 363/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.3555 - mae: 2.9233\n",
      "Epoch 364/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.5293 - mae: 2.9916\n",
      "Epoch 365/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.6613 - mae: 3.0818\n",
      "Epoch 366/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.7133 - mae: 2.8459\n",
      "Epoch 367/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.5991 - mae: 2.9463\n",
      "Epoch 368/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.6944 - mae: 3.0130\n",
      "Epoch 369/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1353 - mae: 2.8008\n",
      "Epoch 370/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.3915 - mae: 2.9117\n",
      "Epoch 371/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.7570 - mae: 3.0239\n",
      "Epoch 372/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.8061 - mae: 3.1217\n",
      "Epoch 373/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.8368 - mae: 2.8591\n",
      "Epoch 374/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.2131 - mae: 2.9002\n",
      "Epoch 375/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5021 - mae: 2.8993\n",
      "Epoch 376/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.5325 - mae: 2.8097\n",
      "Epoch 377/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.7306 - mae: 2.8981\n",
      "Epoch 378/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.9616 - mae: 2.9612\n",
      "Epoch 379/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.7229 - mae: 3.0699\n",
      "Epoch 380/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.6678 - mae: 2.8593\n",
      "Epoch 381/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.1023 - mae: 2.9835\n",
      "Epoch 382/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2154 - mae: 2.7743\n",
      "Epoch 383/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0566 - mae: 2.7659\n",
      "Epoch 384/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.4305 - mae: 2.8700\n",
      "Epoch 385/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.5031 - mae: 2.9964\n",
      "Epoch 386/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.9814 - mae: 3.0351\n",
      "Epoch 387/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.7474 - mae: 3.0306\n",
      "Epoch 388/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.4464 - mae: 2.9513\n",
      "Epoch 389/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.6560 - mae: 2.9535\n",
      "Epoch 390/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.2134 - mae: 3.0642\n",
      "Epoch 391/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.3519 - mae: 3.0210\n",
      "Epoch 392/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.0943 - mae: 2.8940\n",
      "Epoch 393/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 19.8120 - mae: 3.2005\n",
      "Epoch 394/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.2792 - mae: 3.0194\n",
      "Epoch 395/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9597 - mae: 2.8267\n",
      "Epoch 396/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.0612 - mae: 2.9103\n",
      "Epoch 397/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.1680 - mae: 2.9566\n",
      "Epoch 398/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.3908 - mae: 3.1210\n",
      "Epoch 399/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.1159 - mae: 3.0684\n",
      "Epoch 400/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.7996 - mae: 2.9320\n",
      "Epoch 401/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.8575 - mae: 3.1720\n",
      "Epoch 402/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.3665 - mae: 2.7836\n",
      "Epoch 403/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.6094 - mae: 2.9125\n",
      "Epoch 404/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9517 - mae: 2.8465\n",
      "Epoch 405/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7858 - mae: 2.8584\n",
      "Epoch 406/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.5920 - mae: 2.8382\n",
      "Epoch 407/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.0451 - mae: 2.9040\n",
      "Epoch 408/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5217 - mae: 2.7098\n",
      "Epoch 409/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.4792 - mae: 3.0543\n",
      "Epoch 410/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.2186 - mae: 3.0324\n",
      "Epoch 411/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.0781 - mae: 3.0133\n",
      "Epoch 412/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.1671 - mae: 2.9838\n",
      "Epoch 413/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9684 - mae: 2.7986\n",
      "Epoch 414/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.6535 - mae: 3.0861\n",
      "Epoch 415/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.3970 - mae: 2.8811\n",
      "Epoch 416/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.2060 - mae: 2.9430\n",
      "Epoch 417/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 17.3217 - mae: 2.9818\n",
      "Epoch 418/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.1159 - mae: 2.7104\n",
      "Epoch 419/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.7660 - mae: 3.0505\n",
      "Epoch 420/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8084 - mae: 2.8398\n",
      "Epoch 421/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.8539 - mae: 2.9457\n",
      "Epoch 422/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.6701 - mae: 2.9898\n",
      "Epoch 423/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.3149 - mae: 2.8695\n",
      "Epoch 424/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.8479 - mae: 2.8307\n",
      "Epoch 425/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7533 - mae: 2.6812\n",
      "Epoch 426/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.2510 - mae: 2.6792\n",
      "Epoch 427/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.4336 - mae: 2.9579\n",
      "Epoch 428/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.0586 - mae: 2.9316\n",
      "Epoch 429/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.0463 - mae: 2.8052\n",
      "Epoch 430/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.8767 - mae: 3.0602\n",
      "Epoch 431/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.1616 - mae: 2.9319\n",
      "Epoch 432/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3550 - mae: 2.8102\n",
      "Epoch 433/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.3212 - mae: 2.7517\n",
      "Epoch 434/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 16.2635 - mae: 2.9495\n",
      "Epoch 435/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.9570 - mae: 2.8638\n",
      "Epoch 436/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.2927 - mae: 2.8002\n",
      "Epoch 437/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.1625 - mae: 2.7612\n",
      "Epoch 438/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.8321 - mae: 2.7850\n",
      "Epoch 439/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.2515 - mae: 2.6980\n",
      "Epoch 440/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.6356 - mae: 3.0044\n",
      "Epoch 441/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 17.0013 - mae: 2.9287\n",
      "Epoch 442/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.9685 - mae: 2.8627\n",
      "Epoch 443/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.6258 - mae: 2.9051\n",
      "Epoch 444/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.8059 - mae: 2.7945\n",
      "Epoch 445/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.1113 - mae: 2.7913\n",
      "Epoch 446/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.4143 - mae: 2.8724\n",
      "Epoch 447/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 13.6423 - mae: 2.6683\n",
      "Epoch 448/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.4918 - mae: 2.9065\n",
      "Epoch 449/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.5569 - mae: 2.8342\n",
      "Epoch 450/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.7029 - mae: 2.9505\n",
      "Epoch 451/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.3443 - mae: 2.8373\n",
      "Epoch 452/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.8176 - mae: 2.9661\n",
      "Epoch 453/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.6875 - mae: 3.0025\n",
      "Epoch 454/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.9890 - mae: 2.9450\n",
      "Epoch 455/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.2310 - mae: 2.7009\n",
      "Epoch 456/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.8520 - mae: 2.9410\n",
      "Epoch 457/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.2601 - mae: 2.9372\n",
      "Epoch 458/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.8905 - mae: 2.8634\n",
      "Epoch 459/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.5339 - mae: 2.7801\n",
      "Epoch 460/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.1398 - mae: 2.9152\n",
      "Epoch 461/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.2951 - mae: 2.9087\n",
      "Epoch 462/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.2933 - mae: 2.9053\n",
      "Epoch 463/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.4308 - mae: 2.8446\n",
      "Epoch 464/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.8807 - mae: 3.0001\n",
      "Epoch 465/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.8392 - mae: 2.9361\n",
      "Epoch 466/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.5815 - mae: 2.8510\n",
      "Epoch 467/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 18.4870 - mae: 3.1555\n",
      "Epoch 468/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.9865 - mae: 2.9585\n",
      "Epoch 469/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 13.5152 - mae: 2.7033\n",
      "Epoch 470/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 17.0624 - mae: 2.9352\n",
      "Epoch 471/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.5586 - mae: 2.9872\n",
      "Epoch 472/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.7746 - mae: 2.9043\n",
      "Epoch 473/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.7578 - mae: 2.7896\n",
      "Epoch 474/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.8520 - mae: 2.8911\n",
      "Epoch 475/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 17.5397 - mae: 3.0107\n",
      "Epoch 476/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.4107 - mae: 2.9391\n",
      "Epoch 477/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.6383 - mae: 2.8681\n",
      "Epoch 478/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 13.2598 - mae: 2.6510\n",
      "Epoch 479/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.9283 - mae: 2.9433\n",
      "Epoch 480/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.8868 - mae: 2.7753\n",
      "Epoch 481/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.9529 - mae: 3.0329\n",
      "Epoch 482/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.6608 - mae: 2.8095\n",
      "Epoch 483/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.9169 - mae: 3.0207\n",
      "Epoch 484/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.9226 - mae: 2.6245\n",
      "Epoch 485/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.0670 - mae: 2.7931\n",
      "Epoch 486/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.9000 - mae: 2.8704\n",
      "Epoch 487/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.8077 - mae: 2.9111\n",
      "Epoch 488/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.8102 - mae: 2.8849\n",
      "Epoch 489/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.7676 - mae: 2.7591\n",
      "Epoch 490/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.7098 - mae: 2.8351\n",
      "Epoch 491/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.0274 - mae: 2.8721\n",
      "Epoch 492/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.4100 - mae: 2.8496\n",
      "Epoch 493/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 18.8472 - mae: 3.0674\n",
      "Epoch 494/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.6662 - mae: 2.7987\n",
      "Epoch 495/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 13.8586 - mae: 2.6991\n",
      "Epoch 496/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.4997 - mae: 2.8146\n",
      "Epoch 497/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.6618 - mae: 2.8288\n",
      "Epoch 498/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.0757 - mae: 2.8693\n",
      "Epoch 499/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.1175 - mae: 2.6620\n",
      "Epoch 500/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.5953 - mae: 2.8454\n",
      "processing fold #  2\n",
      "Train on 696 samples\n",
      "Epoch 1/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 22.5947 - mae: 3.4773\n",
      "Epoch 2/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 18.0114 - mae: 3.0842\n",
      "Epoch 3/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 19.7428 - mae: 3.3311\n",
      "Epoch 4/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 18.5204 - mae: 3.1431\n",
      "Epoch 5/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 17.3765 - mae: 3.0859\n",
      "Epoch 6/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 17.6788 - mae: 3.0441\n",
      "Epoch 7/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 18.9503 - mae: 3.1470\n",
      "Epoch 8/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 17.5091 - mae: 3.1374\n",
      "Epoch 9/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 19.3397 - mae: 3.2134\n",
      "Epoch 10/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 18.4464 - mae: 3.0562\n",
      "Epoch 11/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 20.2122 - mae: 3.3280\n",
      "Epoch 12/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.7167 - mae: 3.0179\n",
      "Epoch 13/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 18.8184 - mae: 3.1787\n",
      "Epoch 14/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 18.4678 - mae: 3.1290\n",
      "Epoch 15/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.3143 - mae: 3.0690\n",
      "Epoch 16/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 17.7621 - mae: 3.1298\n",
      "Epoch 17/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.3924 - mae: 2.9198\n",
      "Epoch 18/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 17.4063 - mae: 3.0164\n",
      "Epoch 19/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 18.0250 - mae: 3.1617\n",
      "Epoch 20/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 17.5955 - mae: 3.1351\n",
      "Epoch 21/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.7987 - mae: 2.9207\n",
      "Epoch 22/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 19.1101 - mae: 3.2647\n",
      "Epoch 23/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 17.3890 - mae: 3.0556\n",
      "Epoch 24/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.1609 - mae: 2.9350\n",
      "Epoch 25/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.8702 - mae: 3.0337\n",
      "Epoch 26/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.8257 - mae: 3.1293\n",
      "Epoch 27/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.1579 - mae: 2.9214\n",
      "Epoch 28/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.4678 - mae: 3.0588\n",
      "Epoch 29/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.2607 - mae: 2.8831\n",
      "Epoch 30/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 19.2562 - mae: 3.1893\n",
      "Epoch 31/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.3923 - mae: 2.9874\n",
      "Epoch 32/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 17.8481 - mae: 3.0255\n",
      "Epoch 33/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.1754 - mae: 2.9577\n",
      "Epoch 34/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.0309 - mae: 2.8717\n",
      "Epoch 35/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.5198 - mae: 2.9922\n",
      "Epoch 36/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.0586 - mae: 2.9711\n",
      "Epoch 37/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.6639 - mae: 2.8736\n",
      "Epoch 38/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.3931 - mae: 2.6908\n",
      "Epoch 39/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.0425 - mae: 3.0139\n",
      "Epoch 40/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.8090 - mae: 2.9929\n",
      "Epoch 41/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.8102 - mae: 2.9738\n",
      "Epoch 42/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 17.1715 - mae: 3.0127\n",
      "Epoch 43/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.7582 - mae: 3.0203\n",
      "Epoch 44/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.1829 - mae: 2.9260\n",
      "Epoch 45/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.9708 - mae: 2.8505\n",
      "Epoch 46/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.6255 - mae: 2.9158\n",
      "Epoch 47/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 17.7279 - mae: 3.0563\n",
      "Epoch 48/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.3505 - mae: 2.8694\n",
      "Epoch 49/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 20.1942 - mae: 3.2544\n",
      "Epoch 50/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.9774 - mae: 2.9144\n",
      "Epoch 51/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.5306 - mae: 2.9162\n",
      "Epoch 52/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 17.3289 - mae: 3.0569\n",
      "Epoch 53/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.7190 - mae: 2.7791\n",
      "Epoch 54/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.5547 - mae: 2.8426\n",
      "Epoch 55/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.5913 - mae: 3.0013\n",
      "Epoch 56/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.4969 - mae: 2.8944\n",
      "Epoch 57/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.2533 - mae: 2.8532\n",
      "Epoch 58/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.9914 - mae: 3.2207\n",
      "Epoch 59/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.0976 - mae: 3.0239\n",
      "Epoch 60/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.4434 - mae: 2.9232\n",
      "Epoch 61/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.1980 - mae: 2.9270\n",
      "Epoch 62/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.0964 - mae: 3.0070\n",
      "Epoch 63/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.2432 - mae: 2.8008\n",
      "Epoch 64/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 19.1215 - mae: 3.2200\n",
      "Epoch 65/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5416 - mae: 2.8506\n",
      "Epoch 66/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.8091 - mae: 2.9722\n",
      "Epoch 67/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7194 - mae: 2.7935\n",
      "Epoch 68/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.6110 - mae: 2.9013\n",
      "Epoch 69/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.2453 - mae: 2.7427\n",
      "Epoch 70/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.1019 - mae: 2.9149\n",
      "Epoch 71/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.4370 - mae: 2.8966\n",
      "Epoch 72/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.4439 - mae: 2.9771\n",
      "Epoch 73/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.3799 - mae: 2.8564\n",
      "Epoch 74/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.6902 - mae: 2.9993\n",
      "Epoch 75/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.6282 - mae: 3.0443\n",
      "Epoch 76/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8947 - mae: 2.9353\n",
      "Epoch 77/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8367 - mae: 2.8921\n",
      "Epoch 78/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.2921 - mae: 2.9790\n",
      "Epoch 79/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.5889 - mae: 2.9499\n",
      "Epoch 80/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.5462 - mae: 2.8367\n",
      "Epoch 81/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.5017 - mae: 2.9118\n",
      "Epoch 82/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.5431 - mae: 2.9453\n",
      "Epoch 83/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.6447 - mae: 2.8208\n",
      "Epoch 84/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.6088 - mae: 2.9622\n",
      "Epoch 85/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 18.3412 - mae: 3.0766\n",
      "Epoch 86/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.4122 - mae: 2.8143\n",
      "Epoch 87/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.5824 - mae: 2.9236\n",
      "Epoch 88/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.3154 - mae: 2.8978\n",
      "Epoch 89/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.7144 - mae: 2.8637\n",
      "Epoch 90/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.3819 - mae: 2.8750\n",
      "Epoch 91/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.7901 - mae: 2.9180\n",
      "Epoch 92/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0693 - mae: 2.7565\n",
      "Epoch 93/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.1428 - mae: 2.9639\n",
      "Epoch 94/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5961 - mae: 2.7777\n",
      "Epoch 95/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.5467 - mae: 2.9713\n",
      "Epoch 96/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.1113 - mae: 2.9175\n",
      "Epoch 97/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.6055 - mae: 2.7484\n",
      "Epoch 98/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.2868 - mae: 2.8720\n",
      "Epoch 99/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5727 - mae: 2.8544\n",
      "Epoch 100/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.2184 - mae: 2.7484\n",
      "Epoch 101/500\n",
      "696/696 [==============================] - ETA: 0s - loss: 15.6008 - mae: 2.89 - 3s 4ms/sample - loss: 15.6337 - mae: 2.9005\n",
      "Epoch 102/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.8058 - mae: 2.9524\n",
      "Epoch 103/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4492 - mae: 2.6193\n",
      "Epoch 104/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.2637 - mae: 2.8122\n",
      "Epoch 105/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.5967 - mae: 3.0407\n",
      "Epoch 106/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.1055 - mae: 2.9903\n",
      "Epoch 107/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.5902 - mae: 2.7790\n",
      "Epoch 108/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8275 - mae: 2.6528\n",
      "Epoch 109/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.3359 - mae: 2.8807\n",
      "Epoch 110/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7402 - mae: 2.7585\n",
      "Epoch 111/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9474 - mae: 2.7709\n",
      "Epoch 112/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.4647 - mae: 2.9544\n",
      "Epoch 113/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.3484 - mae: 2.9340\n",
      "Epoch 114/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.4165 - mae: 2.8430\n",
      "Epoch 115/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.9040 - mae: 2.8919\n",
      "Epoch 116/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.5512 - mae: 2.9453\n",
      "Epoch 117/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9564 - mae: 2.7950\n",
      "Epoch 118/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.2744 - mae: 2.8251\n",
      "Epoch 119/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.6976 - mae: 2.8360\n",
      "Epoch 120/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.7782 - mae: 2.9446\n",
      "Epoch 121/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5171 - mae: 2.8816\n",
      "Epoch 122/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.4677 - mae: 2.9809\n",
      "Epoch 123/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0492 - mae: 2.8565\n",
      "Epoch 124/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0041 - mae: 2.7425\n",
      "Epoch 125/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.7673 - mae: 2.8489\n",
      "Epoch 126/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1171 - mae: 2.7955\n",
      "Epoch 127/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3641 - mae: 2.8077\n",
      "Epoch 128/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1808 - mae: 2.8614\n",
      "Epoch 129/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.6503 - mae: 2.8357\n",
      "Epoch 130/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5158 - mae: 2.8101\n",
      "Epoch 131/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1797 - mae: 2.8601\n",
      "Epoch 132/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.3178 - mae: 2.8905\n",
      "Epoch 133/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9784 - mae: 2.7854\n",
      "Epoch 134/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.8318 - mae: 2.6244\n",
      "Epoch 135/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.6797 - mae: 2.8046\n",
      "Epoch 136/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5578 - mae: 2.7058\n",
      "Epoch 137/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7988 - mae: 2.8020\n",
      "Epoch 138/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.0892 - mae: 2.9521\n",
      "Epoch 139/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8611 - mae: 2.9633\n",
      "Epoch 140/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1295 - mae: 2.8465\n",
      "Epoch 141/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.1516 - mae: 2.9373\n",
      "Epoch 142/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.9668 - mae: 2.9119\n",
      "Epoch 143/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3422 - mae: 2.6811\n",
      "Epoch 144/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1771 - mae: 2.7734\n",
      "Epoch 145/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.5648 - mae: 2.8239\n",
      "Epoch 146/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2736 - mae: 2.7862\n",
      "Epoch 147/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.6524 - mae: 2.8228\n",
      "Epoch 148/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5590 - mae: 2.8260\n",
      "Epoch 149/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5487 - mae: 2.8605\n",
      "Epoch 150/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.4195 - mae: 2.8353\n",
      "Epoch 151/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1316 - mae: 2.7603\n",
      "Epoch 152/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.4586 - mae: 2.8324\n",
      "Epoch 153/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3371 - mae: 2.7332\n",
      "Epoch 154/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1239 - mae: 2.6817\n",
      "Epoch 155/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4018 - mae: 2.5852\n",
      "Epoch 156/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8950 - mae: 2.8545\n",
      "Epoch 157/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.6763 - mae: 3.0129\n",
      "Epoch 158/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0602 - mae: 2.8206\n",
      "Epoch 159/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0877 - mae: 2.8284\n",
      "Epoch 160/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.2891 - mae: 2.8048\n",
      "Epoch 161/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0387 - mae: 2.8651\n",
      "Epoch 162/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5679 - mae: 2.8607\n",
      "Epoch 163/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5987 - mae: 2.5426\n",
      "Epoch 164/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0210 - mae: 2.6510\n",
      "Epoch 165/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7388 - mae: 2.6881\n",
      "Epoch 166/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.1601 - mae: 2.9526\n",
      "Epoch 167/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.2156 - mae: 2.8104\n",
      "Epoch 168/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7018 - mae: 2.7886\n",
      "Epoch 169/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9589 - mae: 2.6521\n",
      "Epoch 170/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8112 - mae: 2.8723\n",
      "Epoch 171/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.6238 - mae: 2.7781\n",
      "Epoch 172/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5557 - mae: 2.8350\n",
      "Epoch 173/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3828 - mae: 2.6540\n",
      "Epoch 174/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.5424 - mae: 2.9048\n",
      "Epoch 175/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.6117 - mae: 2.8244\n",
      "Epoch 176/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.5367 - mae: 2.8161\n",
      "Epoch 177/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.8233 - mae: 2.7952\n",
      "Epoch 178/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.4161 - mae: 2.7007\n",
      "Epoch 179/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7847 - mae: 2.7724\n",
      "Epoch 180/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3384 - mae: 2.7101\n",
      "Epoch 181/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3884 - mae: 2.7393\n",
      "Epoch 182/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.0431 - mae: 2.7983\n",
      "Epoch 183/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.6657 - mae: 2.9528\n",
      "Epoch 184/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.3802 - mae: 2.6275\n",
      "Epoch 185/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.8645 - mae: 2.5804\n",
      "Epoch 186/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.1938 - mae: 2.7273\n",
      "Epoch 187/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.1637 - mae: 2.7213\n",
      "Epoch 188/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.6590 - mae: 2.6268\n",
      "Epoch 189/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.9910 - mae: 2.7673\n",
      "Epoch 190/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7496 - mae: 2.5654\n",
      "Epoch 191/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8065 - mae: 2.6979\n",
      "Epoch 192/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.8747 - mae: 2.7346\n",
      "Epoch 193/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.4887 - mae: 2.8329\n",
      "Epoch 194/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6919 - mae: 2.6576\n",
      "Epoch 195/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.0428 - mae: 2.6456\n",
      "Epoch 196/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8448 - mae: 2.6854\n",
      "Epoch 197/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9887 - mae: 2.7480\n",
      "Epoch 198/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3187 - mae: 2.7536\n",
      "Epoch 199/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.8190 - mae: 2.8027\n",
      "Epoch 200/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6199 - mae: 2.6164\n",
      "Epoch 201/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2003 - mae: 2.6695\n",
      "Epoch 202/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.4219 - mae: 2.7862\n",
      "Epoch 203/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2279 - mae: 2.6623\n",
      "Epoch 204/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5561 - mae: 2.8288\n",
      "Epoch 205/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0351 - mae: 2.7423\n",
      "Epoch 206/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6535 - mae: 2.7096\n",
      "Epoch 207/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.6186 - mae: 2.7885\n",
      "Epoch 208/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5490 - mae: 2.7679\n",
      "Epoch 209/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7390 - mae: 2.8186\n",
      "Epoch 210/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.6471 - mae: 2.7611\n",
      "Epoch 211/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0449 - mae: 2.6313\n",
      "Epoch 212/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3992 - mae: 2.7433\n",
      "Epoch 213/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5632 - mae: 2.6638\n",
      "Epoch 214/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.7227 - mae: 2.8382\n",
      "Epoch 215/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3871 - mae: 2.7286\n",
      "Epoch 216/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0545 - mae: 2.6281\n",
      "Epoch 217/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.9260 - mae: 2.9684\n",
      "Epoch 218/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4376 - mae: 2.6289\n",
      "Epoch 219/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.5153 - mae: 2.9442\n",
      "Epoch 220/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.8080 - mae: 2.6761\n",
      "Epoch 221/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5324 - mae: 2.6386\n",
      "Epoch 222/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5885 - mae: 2.5758\n",
      "Epoch 223/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0790 - mae: 2.7629\n",
      "Epoch 224/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1992 - mae: 2.8219\n",
      "Epoch 225/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1029 - mae: 2.7214\n",
      "Epoch 226/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5677 - mae: 2.7346\n",
      "Epoch 227/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2576 - mae: 2.7448\n",
      "Epoch 228/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7318 - mae: 2.7660\n",
      "Epoch 229/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0613 - mae: 2.7181\n",
      "Epoch 230/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0131 - mae: 2.6388\n",
      "Epoch 231/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0330 - mae: 2.7699\n",
      "Epoch 232/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.3561 - mae: 2.9805\n",
      "Epoch 233/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.6294 - mae: 2.7465\n",
      "Epoch 234/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.7600 - mae: 2.8685\n",
      "Epoch 235/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.7921 - mae: 2.5476\n",
      "Epoch 236/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8085 - mae: 2.9406\n",
      "Epoch 237/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5776 - mae: 2.7141\n",
      "Epoch 238/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 23.2639 - mae: 3.3610\n",
      "Epoch 239/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9498 - mae: 2.6103\n",
      "Epoch 240/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7852 - mae: 2.5617\n",
      "Epoch 241/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9298 - mae: 2.7321\n",
      "Epoch 242/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2011 - mae: 2.6738\n",
      "Epoch 243/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.6324 - mae: 2.8964\n",
      "Epoch 244/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3556 - mae: 2.7255\n",
      "Epoch 245/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0773 - mae: 2.7983\n",
      "Epoch 246/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.3286 - mae: 2.8308\n",
      "Epoch 247/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.5885 - mae: 2.7455\n",
      "Epoch 248/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0953 - mae: 2.6225\n",
      "Epoch 249/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.0525 - mae: 2.9622\n",
      "Epoch 250/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6877 - mae: 2.5592\n",
      "Epoch 251/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4091 - mae: 2.5286\n",
      "Epoch 252/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9351 - mae: 2.7568\n",
      "Epoch 253/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1115 - mae: 2.7033\n",
      "Epoch 254/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.4841 - mae: 2.9664\n",
      "Epoch 255/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4153 - mae: 2.5241\n",
      "Epoch 256/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5126 - mae: 2.7158\n",
      "Epoch 257/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6934 - mae: 2.6775\n",
      "Epoch 258/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.4056 - mae: 2.7750\n",
      "Epoch 259/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.4225 - mae: 2.7628\n",
      "Epoch 260/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2042 - mae: 2.7066\n",
      "Epoch 261/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8827 - mae: 2.6694\n",
      "Epoch 262/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5615 - mae: 2.6353\n",
      "Epoch 263/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6471 - mae: 2.7044\n",
      "Epoch 264/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.2232 - mae: 2.8676\n",
      "Epoch 265/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5665 - mae: 2.6605\n",
      "Epoch 266/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2619 - mae: 2.8101\n",
      "Epoch 267/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9155 - mae: 2.4873\n",
      "Epoch 268/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1810 - mae: 2.6332\n",
      "Epoch 269/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0808 - mae: 2.7908\n",
      "Epoch 270/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8314 - mae: 2.8267\n",
      "Epoch 271/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0459 - mae: 2.7911\n",
      "Epoch 272/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9430 - mae: 2.6673\n",
      "Epoch 273/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.5641 - mae: 2.6980\n",
      "Epoch 274/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.3089 - mae: 2.8904\n",
      "Epoch 275/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5274 - mae: 2.5522\n",
      "Epoch 276/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4142 - mae: 2.5274\n",
      "Epoch 277/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.4995 - mae: 2.8775\n",
      "Epoch 278/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7420 - mae: 2.7663\n",
      "Epoch 279/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6390 - mae: 2.6034\n",
      "Epoch 280/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0771 - mae: 2.7252\n",
      "Epoch 281/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3651 - mae: 2.5836\n",
      "Epoch 282/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5481 - mae: 2.5730\n",
      "Epoch 283/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.8616 - mae: 2.7669\n",
      "Epoch 284/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.4622 - mae: 2.8376\n",
      "Epoch 285/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.3388 - mae: 2.7907\n",
      "Epoch 286/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6318 - mae: 2.6749\n",
      "Epoch 287/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8645 - mae: 2.4387\n",
      "Epoch 288/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4344 - mae: 2.6579\n",
      "Epoch 289/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.3942 - mae: 2.7600\n",
      "Epoch 290/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8876 - mae: 2.6871\n",
      "Epoch 291/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7480 - mae: 2.6487\n",
      "Epoch 292/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0103 - mae: 2.6819\n",
      "Epoch 293/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.4075 - mae: 2.6962\n",
      "Epoch 294/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.1695 - mae: 3.0279\n",
      "Epoch 295/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.1645 - mae: 2.6808\n",
      "Epoch 296/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.5045 - mae: 2.7151\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3402 - mae: 2.5945\n",
      "Epoch 298/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4106 - mae: 2.5745\n",
      "Epoch 299/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9098 - mae: 2.8672\n",
      "Epoch 300/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.5995 - mae: 2.8608\n",
      "Epoch 301/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4292 - mae: 2.4091\n",
      "Epoch 302/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1522 - mae: 2.6808\n",
      "Epoch 303/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8524 - mae: 2.6630\n",
      "Epoch 304/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.9817 - mae: 2.3698\n",
      "Epoch 305/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7319 - mae: 2.7490\n",
      "Epoch 306/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3842 - mae: 2.6417\n",
      "Epoch 307/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7020 - mae: 2.6606\n",
      "Epoch 308/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9074 - mae: 2.6835\n",
      "Epoch 309/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5201 - mae: 2.5683\n",
      "Epoch 310/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8793 - mae: 2.8082\n",
      "Epoch 311/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5411 - mae: 2.4643\n",
      "Epoch 312/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4492 - mae: 2.6455\n",
      "Epoch 313/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.8680 - mae: 2.9487\n",
      "Epoch 314/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0348 - mae: 2.7637\n",
      "Epoch 315/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6316 - mae: 2.6519\n",
      "Epoch 316/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9338 - mae: 2.6211\n",
      "Epoch 317/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8016 - mae: 2.4804\n",
      "Epoch 318/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9337 - mae: 2.6261\n",
      "Epoch 319/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3648 - mae: 2.7697\n",
      "Epoch 320/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6588 - mae: 2.5906\n",
      "Epoch 321/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2787 - mae: 2.6270\n",
      "Epoch 322/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4278 - mae: 2.6331\n",
      "Epoch 323/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3356 - mae: 2.7051\n",
      "Epoch 324/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0082 - mae: 2.5306\n",
      "Epoch 325/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7326 - mae: 2.7157\n",
      "Epoch 326/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.8407 - mae: 2.7379\n",
      "Epoch 327/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7685 - mae: 2.7127\n",
      "Epoch 328/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9852 - mae: 2.7000\n",
      "Epoch 329/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.5026 - mae: 2.7548\n",
      "Epoch 330/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8794 - mae: 2.5501\n",
      "Epoch 331/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8335 - mae: 2.5968\n",
      "Epoch 332/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5057 - mae: 2.5029\n",
      "Epoch 333/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4254 - mae: 2.6092\n",
      "Epoch 334/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9857 - mae: 2.6481\n",
      "Epoch 335/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.3162 - mae: 2.8761\n",
      "Epoch 336/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6301 - mae: 2.5369\n",
      "Epoch 337/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2858 - mae: 2.5652\n",
      "Epoch 338/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0684 - mae: 2.5211\n",
      "Epoch 339/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.8409 - mae: 2.8146\n",
      "Epoch 340/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0017 - mae: 2.7146\n",
      "Epoch 341/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2768 - mae: 2.5849\n",
      "Epoch 342/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3229 - mae: 2.6539\n",
      "Epoch 343/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0348 - mae: 2.4224\n",
      "Epoch 344/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0002 - mae: 2.5525\n",
      "Epoch 345/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6631 - mae: 2.6891\n",
      "Epoch 346/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3531 - mae: 2.7649\n",
      "Epoch 347/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5755 - mae: 2.6512\n",
      "Epoch 348/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3018 - mae: 2.5117\n",
      "Epoch 349/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1098 - mae: 2.5610\n",
      "Epoch 350/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3013 - mae: 2.6716\n",
      "Epoch 351/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.4061 - mae: 2.7376\n",
      "Epoch 352/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8805 - mae: 2.5338\n",
      "Epoch 353/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6603 - mae: 2.6893\n",
      "Epoch 354/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0365 - mae: 2.6186\n",
      "Epoch 355/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4856 - mae: 2.4602\n",
      "Epoch 356/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9705 - mae: 2.6120\n",
      "Epoch 357/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.1607 - mae: 2.4493\n",
      "Epoch 358/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0082 - mae: 2.7315\n",
      "Epoch 359/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.9014 - mae: 2.5028\n",
      "Epoch 360/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5658 - mae: 2.6158\n",
      "Epoch 361/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9001 - mae: 2.7508\n",
      "Epoch 362/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0372 - mae: 2.5829\n",
      "Epoch 363/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2296 - mae: 2.6315\n",
      "Epoch 364/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1430 - mae: 2.7238\n",
      "Epoch 365/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0797 - mae: 2.6401\n",
      "Epoch 366/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9299 - mae: 2.5865\n",
      "Epoch 367/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0785 - mae: 2.5922\n",
      "Epoch 368/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2628 - mae: 2.5483\n",
      "Epoch 369/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3112 - mae: 2.6177\n",
      "Epoch 370/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7171 - mae: 2.6980\n",
      "Epoch 371/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1112 - mae: 2.7129\n",
      "Epoch 372/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1976 - mae: 2.7628\n",
      "Epoch 373/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2611 - mae: 2.6408\n",
      "Epoch 374/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9547 - mae: 2.6400\n",
      "Epoch 375/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7797 - mae: 2.5896\n",
      "Epoch 376/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4426 - mae: 2.4774\n",
      "Epoch 377/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3787 - mae: 2.6027\n",
      "Epoch 378/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.1029 - mae: 2.5959\n",
      "Epoch 379/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.0405 - mae: 2.9710\n",
      "Epoch 380/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0381 - mae: 2.5444\n",
      "Epoch 381/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1654 - mae: 2.5137\n",
      "Epoch 382/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9186 - mae: 2.7083\n",
      "Epoch 383/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8282 - mae: 2.5307\n",
      "Epoch 384/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9015 - mae: 2.7008\n",
      "Epoch 385/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6453 - mae: 2.5881\n",
      "Epoch 386/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.2700 - mae: 2.5625\n",
      "Epoch 387/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.7869 - mae: 2.6829\n",
      "Epoch 388/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3312 - mae: 2.6120\n",
      "Epoch 389/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4713 - mae: 2.3853\n",
      "Epoch 390/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 13.7607 - mae: 2.6179\n",
      "Epoch 391/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.9326 - mae: 2.5181\n",
      "Epoch 392/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.5780 - mae: 2.7503\n",
      "Epoch 393/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.1827 - mae: 2.5980\n",
      "Epoch 394/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5781 - mae: 2.6573\n",
      "Epoch 395/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8727 - mae: 2.4570\n",
      "Epoch 396/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.3395 - mae: 2.6726\n",
      "Epoch 397/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.7298 - mae: 2.9011\n",
      "Epoch 398/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.6585 - mae: 2.5233\n",
      "Epoch 399/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.8230 - mae: 2.5617\n",
      "Epoch 400/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.4235 - mae: 2.8662\n",
      "Epoch 401/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.2769 - mae: 2.6694\n",
      "Epoch 402/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.9222 - mae: 2.4594\n",
      "Epoch 403/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.1951 - mae: 2.4868\n",
      "Epoch 404/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.8574 - mae: 2.6008\n",
      "Epoch 405/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.6629 - mae: 2.5936\n",
      "Epoch 406/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.1168 - mae: 2.4367\n",
      "Epoch 407/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.1647 - mae: 2.6423\n",
      "Epoch 408/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.4583 - mae: 2.6670\n",
      "Epoch 409/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 13.5201 - mae: 2.6263\n",
      "Epoch 410/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.8835 - mae: 2.5506\n",
      "Epoch 411/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6072 - mae: 2.4092\n",
      "Epoch 412/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8013 - mae: 2.4792\n",
      "Epoch 413/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4666 - mae: 2.5812\n",
      "Epoch 414/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.0319 - mae: 2.7124\n",
      "Epoch 415/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.5809 - mae: 2.7694\n",
      "Epoch 416/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.9272 - mae: 2.7327\n",
      "Epoch 417/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.9549 - mae: 2.5705\n",
      "Epoch 418/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.7755 - mae: 2.6289\n",
      "Epoch 419/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.7068 - mae: 2.4761\n",
      "Epoch 420/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8294 - mae: 2.5852\n",
      "Epoch 421/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3916 - mae: 2.5495\n",
      "Epoch 422/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.1535 - mae: 2.8877\n",
      "Epoch 423/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2961 - mae: 2.6650\n",
      "Epoch 424/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4048 - mae: 2.5190\n",
      "Epoch 425/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.1978 - mae: 2.5809\n",
      "Epoch 426/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0111 - mae: 2.5609\n",
      "Epoch 427/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8233 - mae: 2.6695\n",
      "Epoch 428/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7544 - mae: 2.6341\n",
      "Epoch 429/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2006 - mae: 2.6010\n",
      "Epoch 430/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.5734 - mae: 2.4805\n",
      "Epoch 431/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1174 - mae: 2.5982\n",
      "Epoch 432/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.9171 - mae: 2.5193\n",
      "Epoch 433/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7782 - mae: 2.6191\n",
      "Epoch 434/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7413 - mae: 2.5448\n",
      "Epoch 435/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3744 - mae: 2.6852\n",
      "Epoch 436/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5919 - mae: 2.5341\n",
      "Epoch 437/500\n",
      "696/696 [==============================] - ETA: 0s - loss: 12.7050 - mae: 2.52 - 2s 3ms/sample - loss: 12.6514 - mae: 2.5216\n",
      "Epoch 438/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.2548 - mae: 2.7710\n",
      "Epoch 439/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8742 - mae: 2.7877\n",
      "Epoch 440/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1781 - mae: 2.7487\n",
      "Epoch 441/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8436 - mae: 2.5647\n",
      "Epoch 442/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5649 - mae: 2.5690\n",
      "Epoch 443/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6830 - mae: 2.5538\n",
      "Epoch 444/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5730 - mae: 2.6750\n",
      "Epoch 445/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5810 - mae: 2.7809\n",
      "Epoch 446/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.5918 - mae: 2.7450\n",
      "Epoch 447/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4848 - mae: 2.6092\n",
      "Epoch 448/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8309 - mae: 2.6142\n",
      "Epoch 449/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3929 - mae: 2.5340\n",
      "Epoch 450/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7113 - mae: 2.5535\n",
      "Epoch 451/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3583 - mae: 2.6125\n",
      "Epoch 452/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.1880 - mae: 2.5716\n",
      "Epoch 453/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5522 - mae: 2.5337\n",
      "Epoch 454/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3397 - mae: 2.6185\n",
      "Epoch 455/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5576 - mae: 2.5437\n",
      "Epoch 456/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7982 - mae: 2.6103\n",
      "Epoch 457/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3675 - mae: 2.6082\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5754 - mae: 2.6093\n",
      "Epoch 459/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5817 - mae: 2.5469\n",
      "Epoch 460/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8539 - mae: 2.6283\n",
      "Epoch 461/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1920 - mae: 2.4829\n",
      "Epoch 462/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2343 - mae: 2.5050\n",
      "Epoch 463/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.0657 - mae: 2.5249\n",
      "Epoch 464/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8525 - mae: 2.5910\n",
      "Epoch 465/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.9362 - mae: 2.8109\n",
      "Epoch 466/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1123 - mae: 2.3899\n",
      "Epoch 467/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.2527 - mae: 2.7486\n",
      "Epoch 468/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0410 - mae: 2.6754\n",
      "Epoch 469/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.5520 - mae: 2.6940\n",
      "Epoch 470/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4898 - mae: 2.4827\n",
      "Epoch 471/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9491 - mae: 2.6602\n",
      "Epoch 472/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.7880 - mae: 2.7258\n",
      "Epoch 473/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1035 - mae: 2.7242\n",
      "Epoch 474/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.0418 - mae: 2.5136\n",
      "Epoch 475/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4907 - mae: 2.5505\n",
      "Epoch 476/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0054 - mae: 2.5905\n",
      "Epoch 477/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5277 - mae: 2.5114\n",
      "Epoch 478/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9102 - mae: 2.6172\n",
      "Epoch 479/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2218 - mae: 2.6121\n",
      "Epoch 480/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7538 - mae: 2.5978\n",
      "Epoch 481/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5762 - mae: 2.5026\n",
      "Epoch 482/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8843 - mae: 2.5249\n",
      "Epoch 483/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8541 - mae: 2.4146\n",
      "Epoch 484/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7996 - mae: 2.5291\n",
      "Epoch 485/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0902 - mae: 2.5549\n",
      "Epoch 486/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1424 - mae: 2.7918\n",
      "Epoch 487/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.4384 - mae: 2.5164\n",
      "Epoch 488/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4568 - mae: 2.6052\n",
      "Epoch 489/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.3747 - mae: 2.3449\n",
      "Epoch 490/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7038 - mae: 2.6763\n",
      "Epoch 491/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.8018 - mae: 2.5687\n",
      "Epoch 492/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 12.0151 - mae: 2.4180\n",
      "Epoch 493/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8027 - mae: 2.4597\n",
      "Epoch 494/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.6087 - mae: 2.6611\n",
      "Epoch 495/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.0459 - mae: 2.4671\n",
      "Epoch 496/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0104 - mae: 2.6383\n",
      "Epoch 497/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5443 - mae: 2.7068\n",
      "Epoch 498/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3343 - mae: 2.5210\n",
      "Epoch 499/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.1944 - mae: 2.4149\n",
      "Epoch 500/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.6592 - mae: 2.7843\n",
      "processing fold #  3\n",
      "Train on 696 samples\n",
      "Epoch 1/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.6945 - mae: 2.9646\n",
      "Epoch 2/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.7545 - mae: 3.0245\n",
      "Epoch 3/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.7110 - mae: 3.0556\n",
      "Epoch 4/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2038 - mae: 2.6860\n",
      "Epoch 5/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.9511 - mae: 2.8985\n",
      "Epoch 6/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.4139 - mae: 2.9255\n",
      "Epoch 7/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 17.4834 - mae: 2.9856\n",
      "Epoch 8/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8997 - mae: 2.8045\n",
      "Epoch 9/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7540 - mae: 2.7325\n",
      "Epoch 10/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8243 - mae: 2.8787\n",
      "Epoch 11/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 18.8805 - mae: 3.0183\n",
      "Epoch 12/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0088 - mae: 2.6238\n",
      "Epoch 13/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8889 - mae: 2.8872\n",
      "Epoch 14/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.6371 - mae: 2.7911\n",
      "Epoch 15/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2051 - mae: 2.7234\n",
      "Epoch 16/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.5485 - mae: 2.8376\n",
      "Epoch 17/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.5648 - mae: 2.8943\n",
      "Epoch 18/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0958 - mae: 2.7216\n",
      "Epoch 19/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0803 - mae: 2.7303\n",
      "Epoch 20/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.9119 - mae: 2.9562\n",
      "Epoch 21/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9042 - mae: 2.7926\n",
      "Epoch 22/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5028 - mae: 2.6062\n",
      "Epoch 23/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.4046 - mae: 2.7743\n",
      "Epoch 24/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1406 - mae: 2.7262\n",
      "Epoch 25/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.8034 - mae: 2.6055\n",
      "Epoch 26/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.0311 - mae: 2.7444\n",
      "Epoch 27/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.3606 - mae: 2.7356\n",
      "Epoch 28/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.9856 - mae: 2.7673\n",
      "Epoch 29/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.9462 - mae: 2.6904\n",
      "Epoch 30/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.9176 - mae: 2.9632\n",
      "Epoch 31/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.8475 - mae: 2.7762\n",
      "Epoch 32/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.1080 - mae: 2.7043\n",
      "Epoch 33/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.9218 - mae: 2.6255\n",
      "Epoch 34/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.5191 - mae: 2.7286\n",
      "Epoch 35/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.9813 - mae: 2.6456\n",
      "Epoch 36/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.7804 - mae: 2.6658\n",
      "Epoch 37/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.8619 - mae: 2.6473\n",
      "Epoch 38/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 16.1096 - mae: 2.8615\n",
      "Epoch 39/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.4286 - mae: 2.7240\n",
      "Epoch 40/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.2609 - mae: 2.7667\n",
      "Epoch 41/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.7891 - mae: 2.8234\n",
      "Epoch 42/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7906 - mae: 2.7292\n",
      "Epoch 43/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3473 - mae: 2.6439\n",
      "Epoch 44/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0169 - mae: 2.6087\n",
      "Epoch 45/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3490 - mae: 2.6298\n",
      "Epoch 46/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6486 - mae: 2.7259\n",
      "Epoch 47/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9759 - mae: 2.7134\n",
      "Epoch 48/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 15.4588 - mae: 2.8389\n",
      "Epoch 49/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 14.5718 - mae: 2.6883\n",
      "Epoch 50/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 13.8122 - mae: 2.6827\n",
      "Epoch 51/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7246 - mae: 2.6533\n",
      "Epoch 52/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.6700 - mae: 2.7101\n",
      "Epoch 53/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0284 - mae: 2.6068\n",
      "Epoch 54/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.0798 - mae: 2.8308\n",
      "Epoch 55/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2097 - mae: 2.7238\n",
      "Epoch 56/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.4995 - mae: 2.7403\n",
      "Epoch 57/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1381 - mae: 2.7841\n",
      "Epoch 58/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1414 - mae: 2.7577\n",
      "Epoch 59/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9561 - mae: 2.5825\n",
      "Epoch 60/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.6162 - mae: 2.6292\n",
      "Epoch 61/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.9690 - mae: 2.5682\n",
      "Epoch 62/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.1441 - mae: 2.6058\n",
      "Epoch 63/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.3591 - mae: 2.6856\n",
      "Epoch 64/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.3803 - mae: 2.6159\n",
      "Epoch 65/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.0736 - mae: 2.6267\n",
      "Epoch 66/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 13.2141 - mae: 2.6119\n",
      "Epoch 67/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9540 - mae: 2.7241\n",
      "Epoch 68/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8617 - mae: 2.6958\n",
      "Epoch 69/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.6876 - mae: 2.6128\n",
      "Epoch 70/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.9890 - mae: 2.5888\n",
      "Epoch 71/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.4018 - mae: 2.6023\n",
      "Epoch 72/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.7223 - mae: 2.5349\n",
      "Epoch 73/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.0796 - mae: 2.7478\n",
      "Epoch 74/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3207 - mae: 2.6769\n",
      "Epoch 75/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2403 - mae: 2.4853\n",
      "Epoch 76/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6381 - mae: 2.7276\n",
      "Epoch 77/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.9018 - mae: 2.5627\n",
      "Epoch 78/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4744 - mae: 2.6053\n",
      "Epoch 79/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.6086 - mae: 2.7369\n",
      "Epoch 80/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9817 - mae: 2.6363\n",
      "Epoch 81/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2954 - mae: 2.6006\n",
      "Epoch 82/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.3470 - mae: 2.5678\n",
      "Epoch 83/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.2945 - mae: 2.5567\n",
      "Epoch 84/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.1271 - mae: 2.4047\n",
      "Epoch 85/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.7016 - mae: 2.5974\n",
      "Epoch 86/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4254 - mae: 2.6636\n",
      "Epoch 87/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1288 - mae: 2.7216\n",
      "Epoch 88/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2990 - mae: 2.5203\n",
      "Epoch 89/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2673 - mae: 2.4582\n",
      "Epoch 90/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.9418 - mae: 2.9057\n",
      "Epoch 91/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.3716 - mae: 2.4469\n",
      "Epoch 92/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9187 - mae: 2.6876\n",
      "Epoch 93/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6689 - mae: 2.6522\n",
      "Epoch 94/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.2115 - mae: 2.7565\n",
      "Epoch 95/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0726 - mae: 2.6178\n",
      "Epoch 96/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7778 - mae: 2.6174\n",
      "Epoch 97/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4493 - mae: 2.5823\n",
      "Epoch 98/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7978 - mae: 2.6408\n",
      "Epoch 99/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3970 - mae: 2.4694\n",
      "Epoch 100/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.7740 - mae: 2.4511\n",
      "Epoch 101/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7144 - mae: 2.5112\n",
      "Epoch 102/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7860 - mae: 2.4762\n",
      "Epoch 103/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6913 - mae: 2.5430\n",
      "Epoch 104/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5295 - mae: 2.5456\n",
      "Epoch 105/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3592 - mae: 2.7423\n",
      "Epoch 106/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8901 - mae: 2.6644\n",
      "Epoch 107/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.9210 - mae: 2.5039\n",
      "Epoch 108/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9799 - mae: 2.4930\n",
      "Epoch 109/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.7733 - mae: 2.7082\n",
      "Epoch 110/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7434 - mae: 2.6456\n",
      "Epoch 111/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0337 - mae: 2.6737\n",
      "Epoch 112/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8681 - mae: 2.5688\n",
      "Epoch 113/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6472 - mae: 2.5653\n",
      "Epoch 114/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.4433 - mae: 2.6944\n",
      "Epoch 115/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.4038 - mae: 2.8010\n",
      "Epoch 116/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4089 - mae: 2.5347\n",
      "Epoch 117/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9250 - mae: 2.6459\n",
      "Epoch 118/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1243 - mae: 2.6024\n",
      "Epoch 119/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2125 - mae: 2.5348\n",
      "Epoch 120/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1425 - mae: 2.4155\n",
      "Epoch 121/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9110 - mae: 2.5683\n",
      "Epoch 122/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.5219 - mae: 2.7362\n",
      "Epoch 123/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 12.6712 - mae: 2.6287\n",
      "Epoch 124/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2794 - mae: 2.6452\n",
      "Epoch 125/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9116 - mae: 2.6109\n",
      "Epoch 126/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2877 - mae: 2.5415\n",
      "Epoch 127/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6042 - mae: 2.4673\n",
      "Epoch 128/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.7839 - mae: 2.6302\n",
      "Epoch 129/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 15.8386 - mae: 2.8541\n",
      "Epoch 130/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.5661 - mae: 2.4508\n",
      "Epoch 131/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.1081 - mae: 2.4582\n",
      "Epoch 132/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.4017 - mae: 2.6244\n",
      "Epoch 133/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.7794 - mae: 2.5420\n",
      "Epoch 134/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2975 - mae: 2.6466\n",
      "Epoch 135/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.3527 - mae: 2.6127\n",
      "Epoch 136/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.3880 - mae: 2.5500\n",
      "Epoch 137/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.1974 - mae: 2.4729\n",
      "Epoch 138/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.6503 - mae: 2.7181\n",
      "Epoch 139/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.1587 - mae: 2.7116\n",
      "Epoch 140/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.6595 - mae: 2.6874\n",
      "Epoch 141/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9100 - mae: 2.6116\n",
      "Epoch 142/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.5354 - mae: 2.7184\n",
      "Epoch 143/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 16.5488 - mae: 2.7614\n",
      "Epoch 144/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0105 - mae: 2.6078\n",
      "Epoch 145/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8776 - mae: 2.6192\n",
      "Epoch 146/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8754 - mae: 2.6738\n",
      "Epoch 147/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0605 - mae: 2.5877\n",
      "Epoch 148/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1708 - mae: 2.4607\n",
      "Epoch 149/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1875 - mae: 2.6340\n",
      "Epoch 150/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6156 - mae: 2.4319\n",
      "Epoch 151/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6191 - mae: 2.5327\n",
      "Epoch 152/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3815 - mae: 2.6294\n",
      "Epoch 153/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7723 - mae: 2.8108\n",
      "Epoch 154/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0247 - mae: 2.5353\n",
      "Epoch 155/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5832 - mae: 2.5066\n",
      "Epoch 156/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7160 - mae: 2.6399\n",
      "Epoch 157/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0514 - mae: 2.5513\n",
      "Epoch 158/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.1417 - mae: 2.6219\n",
      "Epoch 159/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5347 - mae: 2.5545\n",
      "Epoch 160/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9420 - mae: 2.6256\n",
      "Epoch 161/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3372 - mae: 2.5519\n",
      "Epoch 162/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3609 - mae: 2.4811\n",
      "Epoch 163/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.5779 - mae: 2.5672\n",
      "Epoch 164/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5619 - mae: 2.5634\n",
      "Epoch 165/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3377 - mae: 2.4638\n",
      "Epoch 166/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.3089 - mae: 2.7350\n",
      "Epoch 167/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7195 - mae: 2.4975\n",
      "Epoch 168/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.6031 - mae: 2.7967\n",
      "Epoch 169/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6309 - mae: 2.5678\n",
      "Epoch 170/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.1254 - mae: 2.3620\n",
      "Epoch 171/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.5283 - mae: 2.6930\n",
      "Epoch 172/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0277 - mae: 2.4959\n",
      "Epoch 173/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9940 - mae: 2.5704\n",
      "Epoch 174/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6738 - mae: 2.5383\n",
      "Epoch 175/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4535 - mae: 2.5932\n",
      "Epoch 176/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0042 - mae: 2.6076\n",
      "Epoch 177/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0618 - mae: 2.5829\n",
      "Epoch 178/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4336 - mae: 2.5193\n",
      "Epoch 179/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3077 - mae: 2.7360\n",
      "Epoch 180/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1546 - mae: 2.4139\n",
      "Epoch 181/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.9047 - mae: 2.5105\n",
      "Epoch 182/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8349 - mae: 2.4670\n",
      "Epoch 183/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6214 - mae: 2.4777\n",
      "Epoch 184/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9062 - mae: 2.5264\n",
      "Epoch 185/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5137 - mae: 2.5576\n",
      "Epoch 186/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4888 - mae: 2.4768\n",
      "Epoch 187/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5312 - mae: 2.5021\n",
      "Epoch 188/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4574 - mae: 2.4805\n",
      "Epoch 189/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.0820 - mae: 2.3737\n",
      "Epoch 190/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.0041 - mae: 2.4892\n",
      "Epoch 191/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.0946 - mae: 2.5247\n",
      "Epoch 192/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4885 - mae: 2.4624\n",
      "Epoch 193/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6507 - mae: 2.4491\n",
      "Epoch 194/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.8035 - mae: 2.7835\n",
      "Epoch 195/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.2607 - mae: 2.4325\n",
      "Epoch 196/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1168 - mae: 2.6316\n",
      "Epoch 197/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8599 - mae: 2.4144\n",
      "Epoch 198/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2634 - mae: 2.5079\n",
      "Epoch 199/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2454 - mae: 2.4728\n",
      "Epoch 200/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3395 - mae: 2.6449\n",
      "Epoch 201/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.9359 - mae: 2.6970\n",
      "Epoch 202/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3581 - mae: 2.5359\n",
      "Epoch 203/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5094 - mae: 2.4717\n",
      "Epoch 204/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3444 - mae: 2.4425\n",
      "Epoch 205/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2036 - mae: 2.5102\n",
      "Epoch 206/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3160 - mae: 2.6394\n",
      "Epoch 207/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 14.4251 - mae: 2.6276\n",
      "Epoch 208/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.9041 - mae: 2.4467\n",
      "Epoch 209/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.5646 - mae: 2.5408\n",
      "Epoch 210/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4676 - mae: 2.3837\n",
      "Epoch 211/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 11.4719 - mae: 2.4871\n",
      "Epoch 212/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.8837 - mae: 2.7204\n",
      "Epoch 213/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5387 - mae: 2.5216\n",
      "Epoch 214/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7279 - mae: 2.6700\n",
      "Epoch 215/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.7627 - mae: 2.6135\n",
      "Epoch 216/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.1719 - mae: 2.3766\n",
      "Epoch 217/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.1363 - mae: 2.5371\n",
      "Epoch 218/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8305 - mae: 2.4598\n",
      "Epoch 219/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.0581 - mae: 2.3822\n",
      "Epoch 220/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3066 - mae: 2.4463\n",
      "Epoch 221/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4791 - mae: 2.4226\n",
      "Epoch 222/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4321 - mae: 2.6025\n",
      "Epoch 223/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7287 - mae: 2.5552\n",
      "Epoch 224/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8761 - mae: 2.7189\n",
      "Epoch 225/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3744 - mae: 2.5204\n",
      "Epoch 226/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.2923 - mae: 2.7265\n",
      "Epoch 227/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2541 - mae: 2.6511\n",
      "Epoch 228/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.0401 - mae: 2.4571\n",
      "Epoch 229/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.1674 - mae: 2.5971\n",
      "Epoch 230/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8759 - mae: 2.5517\n",
      "Epoch 231/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0304 - mae: 2.5489\n",
      "Epoch 232/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.9139 - mae: 2.4428\n",
      "Epoch 233/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.1384 - mae: 2.3739\n",
      "Epoch 234/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2218 - mae: 2.6344\n",
      "Epoch 235/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 12.7065 - mae: 2.5088\n",
      "Epoch 236/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.5753 - mae: 2.5677\n",
      "Epoch 237/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.8455 - mae: 2.4941\n",
      "Epoch 238/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.6232 - mae: 2.6374\n",
      "Epoch 239/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.8703 - mae: 2.4397\n",
      "Epoch 240/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.6604 - mae: 2.4190\n",
      "Epoch 241/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.7894 - mae: 2.3850\n",
      "Epoch 242/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.7440 - mae: 2.5299\n",
      "Epoch 243/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.9872 - mae: 2.5251\n",
      "Epoch 244/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.4146 - mae: 2.4147\n",
      "Epoch 245/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 10.6590 - mae: 2.2933\n",
      "Epoch 246/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.2084 - mae: 2.3406\n",
      "Epoch 247/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.9604 - mae: 2.5477\n",
      "Epoch 248/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.4478 - mae: 2.6269\n",
      "Epoch 249/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6379 - mae: 2.4452\n",
      "Epoch 250/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2023 - mae: 2.5635\n",
      "Epoch 251/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0586 - mae: 2.6567\n",
      "Epoch 252/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6212 - mae: 2.4307\n",
      "Epoch 253/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4403 - mae: 2.4637\n",
      "Epoch 254/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.5717 - mae: 2.3923\n",
      "Epoch 255/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2178 - mae: 2.4927\n",
      "Epoch 256/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 13.0101 - mae: 2.5104\n",
      "Epoch 257/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 12.7733 - mae: 2.4746\n",
      "Epoch 258/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8616 - mae: 2.4159\n",
      "Epoch 259/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.4894 - mae: 2.5850\n",
      "Epoch 260/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.7322 - mae: 2.3749\n",
      "Epoch 261/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.8701 - mae: 2.3619\n",
      "Epoch 262/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9860 - mae: 2.5458\n",
      "Epoch 263/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3420 - mae: 2.6537\n",
      "Epoch 264/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6094 - mae: 2.3768\n",
      "Epoch 265/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6720 - mae: 2.3720\n",
      "Epoch 266/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.5098 - mae: 2.4294\n",
      "Epoch 267/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0296 - mae: 2.5659\n",
      "Epoch 268/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9135 - mae: 2.5717\n",
      "Epoch 269/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.1124 - mae: 2.3626\n",
      "Epoch 270/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1512 - mae: 2.4622\n",
      "Epoch 271/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6095 - mae: 2.5148\n",
      "Epoch 272/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9261 - mae: 2.5141\n",
      "Epoch 273/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.0037 - mae: 2.2006\n",
      "Epoch 274/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1684 - mae: 2.5054\n",
      "Epoch 275/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.3257 - mae: 2.4275\n",
      "Epoch 276/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5197 - mae: 2.4923\n",
      "Epoch 277/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.1707 - mae: 2.4313\n",
      "Epoch 278/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.6842 - mae: 2.3270\n",
      "Epoch 279/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8149 - mae: 2.4821\n",
      "Epoch 280/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4765 - mae: 2.4784\n",
      "Epoch 281/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6425 - mae: 2.5366\n",
      "Epoch 282/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2821 - mae: 2.5567\n",
      "Epoch 283/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.3479 - mae: 2.3510\n",
      "Epoch 284/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.0111 - mae: 2.4917\n",
      "Epoch 285/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2331 - mae: 2.4802\n",
      "Epoch 286/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.9337 - mae: 2.3507\n",
      "Epoch 287/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6730 - mae: 2.4707\n",
      "Epoch 288/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.2035 - mae: 2.5874\n",
      "Epoch 289/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.2814 - mae: 2.3527\n",
      "Epoch 290/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.2788 - mae: 2.5829\n",
      "Epoch 291/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.0677 - mae: 2.3331\n",
      "Epoch 292/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.4357 - mae: 2.6540\n",
      "Epoch 293/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2167 - mae: 2.4533\n",
      "Epoch 294/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 11.6585 - mae: 2.4072\n",
      "Epoch 295/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.4095 - mae: 2.4054\n",
      "Epoch 296/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.7138 - mae: 2.3605\n",
      "Epoch 297/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.2200 - mae: 2.4122\n",
      "Epoch 298/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8198 - mae: 2.4848\n",
      "Epoch 299/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.8773 - mae: 2.4637\n",
      "Epoch 300/500\n",
      "696/696 [==============================] - 3s 5ms/sample - loss: 12.0512 - mae: 2.4942\n",
      "Epoch 301/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.8665 - mae: 2.4635\n",
      "Epoch 302/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.9499 - mae: 2.3246\n",
      "Epoch 303/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.5078 - mae: 2.4359\n",
      "Epoch 304/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.6573 - mae: 2.4517\n",
      "Epoch 305/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 10.8286 - mae: 2.3974\n",
      "Epoch 306/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 12.1979 - mae: 2.5405\n",
      "Epoch 307/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3338 - mae: 2.4131\n",
      "Epoch 308/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2098 - mae: 2.4450\n",
      "Epoch 309/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.7598 - mae: 2.3661\n",
      "Epoch 310/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.5926 - mae: 2.4262\n",
      "Epoch 311/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6811 - mae: 2.4314\n",
      "Epoch 312/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.4478 - mae: 2.6255\n",
      "Epoch 313/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7589 - mae: 2.4622\n",
      "Epoch 314/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.0714 - mae: 2.3907\n",
      "Epoch 315/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.6094 - mae: 2.6259\n",
      "Epoch 316/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1784 - mae: 2.4393\n",
      "Epoch 317/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3192 - mae: 2.6596\n",
      "Epoch 318/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8928 - mae: 2.4649\n",
      "Epoch 319/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6561 - mae: 2.4753\n",
      "Epoch 320/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5427 - mae: 2.4797\n",
      "Epoch 321/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1570 - mae: 2.4460\n",
      "Epoch 322/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2982 - mae: 2.5255\n",
      "Epoch 323/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2947 - mae: 2.5145\n",
      "Epoch 324/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3848 - mae: 2.3833\n",
      "Epoch 325/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.2346 - mae: 2.3838\n",
      "Epoch 326/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1024 - mae: 2.4188\n",
      "Epoch 327/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4998 - mae: 2.4225\n",
      "Epoch 328/500\n",
      "696/696 [==============================] - ETA: 0s - loss: 12.7169 - mae: 2.48 - 2s 3ms/sample - loss: 12.6584 - mae: 2.4770\n",
      "Epoch 329/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4586 - mae: 2.4671\n",
      "Epoch 330/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9302 - mae: 2.5407\n",
      "Epoch 331/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.9336 - mae: 2.4245\n",
      "Epoch 332/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5716 - mae: 2.3930\n",
      "Epoch 333/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8637 - mae: 2.5488\n",
      "Epoch 334/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.8430 - mae: 2.3282\n",
      "Epoch 335/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.0203 - mae: 2.6608\n",
      "Epoch 336/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.9445 - mae: 2.4606\n",
      "Epoch 337/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.8735 - mae: 2.6680\n",
      "Epoch 338/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.2083 - mae: 2.3860\n",
      "Epoch 339/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3499 - mae: 2.6555\n",
      "Epoch 340/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.3593 - mae: 2.3990\n",
      "Epoch 341/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0102 - mae: 2.5374\n",
      "Epoch 342/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7013 - mae: 2.4406\n",
      "Epoch 343/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.0665 - mae: 2.2765\n",
      "Epoch 344/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1585 - mae: 2.4846\n",
      "Epoch 345/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6910 - mae: 2.4046\n",
      "Epoch 346/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8791 - mae: 2.4182\n",
      "Epoch 347/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7789 - mae: 2.5063\n",
      "Epoch 348/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2833 - mae: 2.4759\n",
      "Epoch 349/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 9.9064 - mae: 2.2529\n",
      "Epoch 350/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4126 - mae: 2.4012\n",
      "Epoch 351/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 11.2610 - mae: 2.3741\n",
      "Epoch 352/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.2174 - mae: 2.3895\n",
      "Epoch 353/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.9208 - mae: 2.4614\n",
      "Epoch 354/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4490 - mae: 2.5010\n",
      "Epoch 355/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.8018 - mae: 2.5722\n",
      "Epoch 356/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6717 - mae: 2.3809\n",
      "Epoch 357/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.9595 - mae: 2.4341\n",
      "Epoch 358/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.9435 - mae: 2.4210\n",
      "Epoch 359/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.3940 - mae: 2.5757\n",
      "Epoch 360/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2420 - mae: 2.4391\n",
      "Epoch 361/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4518 - mae: 2.5741\n",
      "Epoch 362/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.3407 - mae: 2.2741\n",
      "Epoch 363/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.7903 - mae: 2.3568\n",
      "Epoch 364/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7854 - mae: 2.5201\n",
      "Epoch 365/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.8886 - mae: 2.3438\n",
      "Epoch 366/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2950 - mae: 2.4451\n",
      "Epoch 367/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.0312 - mae: 2.1935\n",
      "Epoch 368/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.0317 - mae: 2.4169\n",
      "Epoch 369/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.5998 - mae: 2.4278\n",
      "Epoch 370/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5006 - mae: 2.4285\n",
      "Epoch 371/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 9.7669 - mae: 2.2514\n",
      "Epoch 372/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3928 - mae: 2.6422\n",
      "Epoch 373/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8918 - mae: 2.4926\n",
      "Epoch 374/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3563 - mae: 2.5210\n",
      "Epoch 375/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5037 - mae: 2.4847\n",
      "Epoch 376/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1286 - mae: 2.4364\n",
      "Epoch 377/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4391 - mae: 2.4972\n",
      "Epoch 378/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6319 - mae: 2.5400\n",
      "Epoch 379/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.2971 - mae: 2.4112\n",
      "Epoch 380/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.0594 - mae: 2.3467\n",
      "Epoch 381/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2067 - mae: 2.4704\n",
      "Epoch 382/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.3577 - mae: 2.3943\n",
      "Epoch 383/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 15.1005 - mae: 2.6862\n",
      "Epoch 384/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0811 - mae: 2.5841\n",
      "Epoch 385/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.4638 - mae: 2.5463\n",
      "Epoch 386/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.1419 - mae: 2.5639\n",
      "Epoch 387/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.6659 - mae: 2.4947\n",
      "Epoch 388/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 9.9777 - mae: 2.3110\n",
      "Epoch 389/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 9.8293 - mae: 2.3021\n",
      "Epoch 390/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1209 - mae: 2.3617\n",
      "Epoch 391/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5582 - mae: 2.4947\n",
      "Epoch 392/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.7626 - mae: 2.4735\n",
      "Epoch 393/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.9519 - mae: 2.3698\n",
      "Epoch 394/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8313 - mae: 2.3507\n",
      "Epoch 395/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.8384 - mae: 2.4062\n",
      "Epoch 396/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 13.0316 - mae: 2.4888\n",
      "Epoch 397/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.0184 - mae: 2.4098\n",
      "Epoch 398/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 10.1131 - mae: 2.2380\n",
      "Epoch 399/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 10.6190 - mae: 2.3445\n",
      "Epoch 400/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.5762 - mae: 2.4442\n",
      "Epoch 401/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 11.6719 - mae: 2.4446\n",
      "Epoch 402/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.1158 - mae: 2.4452\n",
      "Epoch 403/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.1892 - mae: 2.5176\n",
      "Epoch 404/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.8234 - mae: 2.3041\n",
      "Epoch 405/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6509 - mae: 2.3654\n",
      "Epoch 406/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.5044 - mae: 2.4316\n",
      "Epoch 407/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.0358 - mae: 2.3271\n",
      "Epoch 408/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.1310 - mae: 2.4659\n",
      "Epoch 409/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.0155 - mae: 2.4467\n",
      "Epoch 410/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8767 - mae: 2.3540\n",
      "Epoch 411/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1901 - mae: 2.4738\n",
      "Epoch 412/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.9367 - mae: 2.4029\n",
      "Epoch 413/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6539 - mae: 2.4482\n",
      "Epoch 414/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8344 - mae: 2.4213\n",
      "Epoch 415/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.3295 - mae: 2.5798\n",
      "Epoch 416/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3040 - mae: 2.3670\n",
      "Epoch 417/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6940 - mae: 2.4550\n",
      "Epoch 418/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.2869 - mae: 2.3340\n",
      "Epoch 419/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.1317 - mae: 2.4750\n",
      "Epoch 420/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.0419 - mae: 2.3578\n",
      "Epoch 421/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6702 - mae: 2.4042\n",
      "Epoch 422/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.0047 - mae: 2.3065\n",
      "Epoch 423/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.7930 - mae: 2.3471\n",
      "Epoch 424/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.8027 - mae: 2.2639\n",
      "Epoch 425/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4267 - mae: 2.4079\n",
      "Epoch 426/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.3190 - mae: 2.4616\n",
      "Epoch 427/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.6617 - mae: 2.4244\n",
      "Epoch 428/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.5364 - mae: 2.7906\n",
      "Epoch 429/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.3354 - mae: 2.2749\n",
      "Epoch 430/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0375 - mae: 2.5035\n",
      "Epoch 431/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.2991 - mae: 2.2667\n",
      "Epoch 432/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.7081 - mae: 2.1848\n",
      "Epoch 433/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.1723 - mae: 2.3467\n",
      "Epoch 434/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.5530 - mae: 2.2480\n",
      "Epoch 435/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 9.8040 - mae: 2.2655\n",
      "Epoch 436/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.0916 - mae: 2.4189\n",
      "Epoch 437/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.2895 - mae: 2.2871\n",
      "Epoch 438/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.9703 - mae: 2.5841\n",
      "Epoch 439/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2516 - mae: 2.3998\n",
      "Epoch 440/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.0017 - mae: 2.3389\n",
      "Epoch 441/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 9.9758 - mae: 2.2024\n",
      "Epoch 442/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.0821 - mae: 2.5603\n",
      "Epoch 443/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.1361 - mae: 2.3403\n",
      "Epoch 444/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.0708 - mae: 2.2901\n",
      "Epoch 445/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.3930 - mae: 2.2007\n",
      "Epoch 446/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7761 - mae: 2.5278\n",
      "Epoch 447/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4976 - mae: 2.6131\n",
      "Epoch 448/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.1282 - mae: 2.3746\n",
      "Epoch 449/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.7509 - mae: 2.4339\n",
      "Epoch 450/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 16.6545 - mae: 2.7640\n",
      "Epoch 451/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 9.4228 - mae: 2.1779\n",
      "Epoch 452/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4580 - mae: 2.3684\n",
      "Epoch 453/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 9.8477 - mae: 2.2496\n",
      "Epoch 454/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 10.9631 - mae: 2.2411\n",
      "Epoch 455/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.2442 - mae: 2.3649\n",
      "Epoch 456/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.2090 - mae: 2.3948\n",
      "Epoch 457/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3083 - mae: 2.4275\n",
      "Epoch 458/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2323 - mae: 2.3964\n",
      "Epoch 459/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 12.9128 - mae: 2.5537\n",
      "Epoch 460/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.7422 - mae: 2.2914\n",
      "Epoch 461/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.3517 - mae: 2.4322\n",
      "Epoch 462/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.6964 - mae: 2.2843\n",
      "Epoch 463/500\n",
      "696/696 [==============================] - ETA: 0s - loss: 10.7641 - mae: 2.3088 ETA: 0s - loss: 11.08 - 2s 3ms/sample - loss: 10.6551 - mae: 2.2962\n",
      "Epoch 464/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.3581 - mae: 2.4463\n",
      "Epoch 465/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.5077 - mae: 2.3066\n",
      "Epoch 466/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1707 - mae: 2.4859\n",
      "Epoch 467/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 13.4482 - mae: 2.5328\n",
      "Epoch 468/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.7115 - mae: 2.3110\n",
      "Epoch 469/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.2311 - mae: 2.3128\n",
      "Epoch 470/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 9.7035 - mae: 2.1733\n",
      "Epoch 471/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.0876 - mae: 2.4047\n",
      "Epoch 472/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.2962 - mae: 2.3707\n",
      "Epoch 473/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.3271 - mae: 2.4244\n",
      "Epoch 474/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4224 - mae: 2.3746\n",
      "Epoch 475/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.9471 - mae: 2.4135\n",
      "Epoch 476/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.7007 - mae: 2.3925\n",
      "Epoch 477/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.9834 - mae: 2.3047\n",
      "Epoch 478/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.1106 - mae: 2.2120\n",
      "Epoch 479/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.8880 - mae: 2.3719\n",
      "Epoch 480/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4628 - mae: 2.4085\n",
      "Epoch 481/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.0139 - mae: 2.3968\n",
      "Epoch 482/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 12.6284 - mae: 2.5100\n",
      "Epoch 483/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 9.9708 - mae: 2.2030\n",
      "Epoch 484/500\n",
      "696/696 [==============================] - 3s 4ms/sample - loss: 11.0126 - mae: 2.2505\n",
      "Epoch 485/500\n",
      "696/696 [==============================] - 2s 4ms/sample - loss: 10.1957 - mae: 2.2236\n",
      "Epoch 486/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.6634 - mae: 2.2594\n",
      "Epoch 487/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 9.3739 - mae: 2.0855\n",
      "Epoch 488/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.1115 - mae: 2.3753\n",
      "Epoch 489/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.5001 - mae: 2.4904\n",
      "Epoch 490/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.0808 - mae: 2.2955\n",
      "Epoch 491/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4712 - mae: 2.3985\n",
      "Epoch 492/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.8618 - mae: 2.5077\n",
      "Epoch 493/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.3600 - mae: 2.2228\n",
      "Epoch 494/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.9599 - mae: 2.4514\n",
      "Epoch 495/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.5494 - mae: 2.4417\n",
      "Epoch 496/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 11.4197 - mae: 2.3065\n",
      "Epoch 497/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 14.1379 - mae: 2.5275\n",
      "Epoch 498/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 12.2816 - mae: 2.4507\n",
      "Epoch 499/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.3476 - mae: 2.2762\n",
      "Epoch 500/500\n",
      "696/696 [==============================] - 2s 3ms/sample - loss: 10.2979 - mae: 2.2893\n",
      "[3.964141, 4.154679, 3.3097515, 3.060323]\n",
      "\n",
      "mae : 3.6222236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "drop   = 0.03\n",
    "fold = 4\n",
    "tuning_model2(epochs,drop,fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
